{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-27T03:22:30.014233Z",
     "start_time": "2023-12-27T03:22:30.000589Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "from hlathena.peptide_dataset_train import PeptideDatasetTrain\n",
    "from hlathena import peptide_nn\n",
    "from hlathena.training_evaluation import TrainingEvaluation\n",
    "\n",
    "import torch.utils.data as torch_data\n",
    "import torch\n",
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "import random\n",
    "\n",
    "\n",
    "def create_config_dict(device, epochs, lr, dr, batch_size, decoy_mul, eval_decoy_ratio, fold, aa_features, featname,\n",
    "                       pepfeats_dict, seed):\n",
    "    return {\n",
    "        'device': str(device),\n",
    "        'epochs': epochs,\n",
    "        'learning_rate': lr,\n",
    "        'batch_size': batch_size,\n",
    "        'dropout_rate': dr,\n",
    "        'decoy_mul': decoy_mul,\n",
    "        'eval_decoy_ratio': eval_decoy_ratio,\n",
    "        'fold #': fold,\n",
    "        'aa_feature_files': aa_features,\n",
    "        'feature_set_name': featname,\n",
    "        'feature_set_cols': pepfeats_dict[featname],\n",
    "        'all_feature_sets': pepfeats_dict,\n",
    "        'seed': seed\n",
    "    }\n",
    "\n",
    "\n",
    "def make_subdir(output_dir, subdir):\n",
    "    subdir_path = os.path.join(output_dir, subdir)\n",
    "    os.makedirs(subdir_path)\n",
    "    return subdir_path\n",
    "\n",
    "\n",
    "def make_output_dirs(output_dir, out_path):\n",
    "    dir_name = '_'.join([get_currtime(), out_path])\n",
    "    model_path = os.path.join(output_dir, dir_name)\n",
    "    os.makedirs(model_path)\n",
    "\n",
    "    models_dir = make_subdir(model_path, 'models')\n",
    "    configs_dir = make_subdir(model_path, 'configs')\n",
    "    eval_dir = make_subdir(model_path, 'eval')\n",
    "    return models_dir, configs_dir, eval_dir\n",
    "\n",
    "\n",
    "def get_currtime():\n",
    "    return str(datetime.datetime.now()).replace(\" \", \"_\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "decoy_mul = 1\n",
    "decoy_ratio = 1\n",
    "# for fold in range(folds):\n",
    "fold=0\n",
    "feat_set = []\n",
    "seed=1\n",
    "folds=5\n",
    "batch_size = 5000\n",
    "epochs = 100\n",
    "learning_rate = 0.01\n",
    "pred_replicates = 10\n",
    "dropout_rate = 0.1 #0.0\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T03:07:02.170256Z",
     "start_time": "2023-12-27T03:07:02.166111Z"
    }
   },
   "id": "b9c9a64eeddf415c",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "test_file = \"/Users/cleoforman/PycharmProjects/hlathenav2/notebooks/input/test_training.csv\"\n",
    "mini_df = pd.read_csv(test_file, index_col=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T03:07:02.178864Z",
     "start_time": "2023-12-27T03:07:02.172179Z"
    }
   },
   "id": "caab2857056226d5",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "              mhc        pep  tgt     src  len  tgt_weight\n0     HLA-A*01:01  KSSFLSSPE    0  bigmhc    9         0.3\n1     HLA-A*01:01  RTEAAFSYY    1  bigmhc    9         1.0\n2     HLA-A*01:01  ASPQTLVLY    1    this    9         1.0\n3     HLA-A*01:01  GVMLDDYIR    0  bigmhc    9         0.3\n5     HLA-A*01:01  CRVDAGPVL    0  bigmhc    9         0.3\n...           ...        ...  ...     ...  ...         ...\n1495  HLA-C*16:01  FLKVSPELK    0  bigmhc    9         0.3\n1496  HLA-C*16:01  VGLVLRYGI    0  bigmhc    9         0.3\n1497  HLA-C*16:01  NATAFFRQH    1  bigmhc    9         1.0\n1498  HLA-C*16:01  FSIVRPRRL    1    this    9         1.0\n1499  HLA-C*16:01  PGAHQFGLT    0  bigmhc    9         0.3\n\n[1450 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mhc</th>\n      <th>pep</th>\n      <th>tgt</th>\n      <th>src</th>\n      <th>len</th>\n      <th>tgt_weight</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>HLA-A*01:01</td>\n      <td>KSSFLSSPE</td>\n      <td>0</td>\n      <td>bigmhc</td>\n      <td>9</td>\n      <td>0.3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>HLA-A*01:01</td>\n      <td>RTEAAFSYY</td>\n      <td>1</td>\n      <td>bigmhc</td>\n      <td>9</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>HLA-A*01:01</td>\n      <td>ASPQTLVLY</td>\n      <td>1</td>\n      <td>this</td>\n      <td>9</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>HLA-A*01:01</td>\n      <td>GVMLDDYIR</td>\n      <td>0</td>\n      <td>bigmhc</td>\n      <td>9</td>\n      <td>0.3</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>HLA-A*01:01</td>\n      <td>CRVDAGPVL</td>\n      <td>0</td>\n      <td>bigmhc</td>\n      <td>9</td>\n      <td>0.3</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1495</th>\n      <td>HLA-C*16:01</td>\n      <td>FLKVSPELK</td>\n      <td>0</td>\n      <td>bigmhc</td>\n      <td>9</td>\n      <td>0.3</td>\n    </tr>\n    <tr>\n      <th>1496</th>\n      <td>HLA-C*16:01</td>\n      <td>VGLVLRYGI</td>\n      <td>0</td>\n      <td>bigmhc</td>\n      <td>9</td>\n      <td>0.3</td>\n    </tr>\n    <tr>\n      <th>1497</th>\n      <td>HLA-C*16:01</td>\n      <td>NATAFFRQH</td>\n      <td>1</td>\n      <td>bigmhc</td>\n      <td>9</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1498</th>\n      <td>HLA-C*16:01</td>\n      <td>FSIVRPRRL</td>\n      <td>1</td>\n      <td>this</td>\n      <td>9</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1499</th>\n      <td>HLA-C*16:01</td>\n      <td>PGAHQFGLT</td>\n      <td>0</td>\n      <td>bigmhc</td>\n      <td>9</td>\n      <td>0.3</td>\n    </tr>\n  </tbody>\n</table>\n<p>1450 rows Ã— 6 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mini_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T03:07:02.206903Z",
     "start_time": "2023-12-27T03:07:02.188410Z"
    }
   },
   "id": "c36eb795216033f6",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "peptide_dataset = PeptideDatasetTrain(mini_df, pep_col_name='pep', allele_col_name='mhc', target_col_name='tgt', folds=5)\n",
    "feature_dims = peptide_dataset.feature_dimensions()\n",
    "# peptide_dataset.set_feat_cols(['len','tgt_weight'])\n",
    "# peptide_dataset.set_feat_cols(['len'])\n",
    "# peptide_dataset.set_feat_cols([])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T03:07:02.292232Z",
     "start_time": "2023-12-27T03:07:02.212148Z"
    }
   },
   "id": "9f1da76d99b7b3c1",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "numpy.ndarray"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# type(peptide_dataset.pep_df.iloc[0][peptide_dataset.peptide_feature_cols].values)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T02:30:32.021919Z",
     "start_time": "2023-12-27T02:30:32.015629Z"
    }
   },
   "id": "6b7eab5a06ff3820",
   "execution_count": 59
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# peptide_dataset.pep_df[peptide_dataset.peptide_feature_cols].iloc[0].values\n",
    "# len(peptide_dataset.pep_df.iloc[0][peptide_dataset.peptide_feature_cols].values)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T02:31:16.266145Z",
     "start_time": "2023-12-27T02:31:16.255732Z"
    }
   },
   "id": "15d54051dc9bbedc",
   "execution_count": 67
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import argparse\n",
    "import random\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from trainer2 import trainer\n",
    "from classes.training_evaluation import TrainingEvaluation\n",
    "from classes.peptide_dataset import PeptideDataset\n",
    "\n",
    "def get_aa_feature_files_from_dir(aa_dir):\n",
    "    # setting the path for joining multiple files\n",
    "    if (not os.path.isdir(aa_dir)):\n",
    "        return []\n",
    "    elif not len(os.listdir(aa_dir)):\n",
    "        print(\"Amino acid feature directory empty.\")\n",
    "        return [] \n",
    "\n",
    "    featurefiles = os.path.join(aa_dir, \"*.txt\")\n",
    "\n",
    "    # list of merged files returned\n",
    "    return glob.glob(featurefiles)\n",
    "\n",
    "def parse_feature_sets(set_file):\n",
    "    with open(set_file,'r') as f:\n",
    "        featuresets = f.read().splitlines()\n",
    "        featureset_dict = {}\n",
    "        for s in featuresets:\n",
    "            name, cols = s.split(\":\")\n",
    "            cols = cols.split(\",\") if cols else []\n",
    "            featureset_dict[name] = cols\n",
    "    return featureset_dict\n",
    "\n",
    "def get_dedup_pep_df(df):\n",
    "    pep_grp = df.groupby(\"features\")\n",
    "    results=[]\n",
    "    index=[]\n",
    "    for p, d in pep_grp:\n",
    "        r = [p] + list(d.mean(axis=0,numeric_only=True)) + list(d.std(axis=0,numeric_only=True))\n",
    "        results.append(r)\n",
    "        index.append(p)\n",
    "    return pd.DataFrame(results, columns=[\"features\", \"mean_auc\", \"mean_prauc\", \"mean_ppv\", \"std_auc\", \"std_prauc\", \"std_ppv\"],index=index)\n",
    "\n",
    "\n",
    "def main():\n",
    "    parser=argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--train_file\", help=\"Peptide HLA train data file\", required=True, type=str, action='store')\n",
    "    parser.add_argument(\"--val_file\", help=\"Peptide HLA validation data file\", required=False, type=str, default=None, action='store')\n",
    "    parser.add_argument(\"--pep_col\", help=\"specify peptide sequence column name for hits and decoys\", type=str, default='pep', action='store')\n",
    "    parser.add_argument(\"--allele_col\", help=\"Allele column name\", type=str, default=\"\", action='store')\n",
    "    parser.add_argument(\"--target_col\", help=\"Target column name\", type=str, action='store')\n",
    "    parser.add_argument(\"--fold_col\", help=\"Fold column name\", type=str, default=None, action='store')\n",
    "    parser.add_argument(\"-kf\", \"--number_folds\", help=\"specify number of cross folds\", type=int, default=5, action='store')\n",
    "    parser.add_argument(\"-e\", \"--epochs\", type=int, default=4000, action=\"store\")\n",
    "    parser.add_argument(\"-lr\", \"--learning_rate\", type=float, default=0.001, action=\"store\")\n",
    "    parser.add_argument(\"-dr\", \"--dropout_rate\", type=float, default=0.1, action=\"store\") #TODO: add default dr\n",
    "    parser.add_argument(\"-b\", \"--batch_size\", type=int, default=32, action=\"store\")\n",
    "    parser.add_argument(\"-pr\", \"--pred_replicates\", type=int, default=100, action='store')\n",
    "    parser.add_argument(\"-dm\", \"--decoy_mul\", help=\"training ratio of hits to decoys e.g. 2.0 means 1:2 ratio of hits:decoys\", type=int, default=1, action='store')\n",
    "    parser.add_argument(\"--decoy_ratio\", help=\"testing ratio of hits to decoys e.g. 2.0 means 1:2 ratio of hits:decoys\", type=int, default=1, action='store')\n",
    "    parser.add_argument(\"-rh\", \"--resample_hits\", type=bool, default=0, action='store')\n",
    "    parser.add_argument(\"--assign_folds\", type=bool, default=True)\n",
    "    parser.add_argument(\"--aa_feature_folder\", help=\"comma-separated list of amino acid feature matrix files\", type=str, default=\"\", action='store')\n",
    "    parser.add_argument(\"--feat_cols\", help=\"peptide-level feature columns to train on e.g. 'exp;clev'\", type=str, default=\"\", action='store')\n",
    "    parser.add_argument(\"--feat_sets\", help=\"path to file containing feature combinations to run, one per row e.g. NAME:feat1,feat2\", type=str, default=\"\", action='store')\n",
    "    parser.add_argument(\"--repetitions\", help=\"number of times to repeat training\", type=int, default=1, action='store')\n",
    "    parser.add_argument(\"--seeds\", help=\"optionally provide seeds for the training reps as comma-delimited list\", type=str, default=None, action='store')\n",
    "    parser.add_argument(\"-o\", \"--outdir\", help=\"where to store\", type=str, default=\"\", action='store')\n",
    "    parser.add_argument(\"-r\", \"--run_name\", help=\"used to name output sub directory\", type=str, default=\"\", action='store')\n",
    "\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    train_file = args.train_file\n",
    "    val_file = args.val_file\n",
    "    pep_col = args.pep_column\n",
    "    allele_col = args.allele_col\n",
    "    tgt_col = args.target_col\n",
    "    fold_col = args.fold_col\n",
    "    folds = args.number_folds\n",
    "    epochs = args.epochs\n",
    "    learning_rate = args.learning_rate\n",
    "    dropout_rate = args.dropout_rate\n",
    "    batch_size = args.batch_size\n",
    "    pred_replicates = args.pred_replicates\n",
    "    reps = args.repetitions\n",
    "    decoy_mul = args.decoy_mul\n",
    "    decoy_ratio = args.decoy_ratio\n",
    "    resampling_hits = args.resample_hits\n",
    "    aa_feature_folder = args.aa_feature_folder\n",
    "    outdir = args.outdir\n",
    "    assign_folds = args.assign_folds\n",
    "    run_name = args.run_name\n",
    "    seeds = args.seeds\n",
    "    pep_feature_cols = [] if len(args.feat_cols) == 0 else args.feat_cols.split(\";\")\n",
    "    pep_feature_sets_dict = {str(pep_feature_cols): [col for col in pep_feature_cols]} if not args.feat_sets \\\n",
    "                                                                                       else parse_feature_sets(args.feat_sets)\n",
    "    # override peptide column input if feature set dict is provided\n",
    "    pep_feature_cols = list({x for f in list(pep_feature_sets_dict.values()) if f for x in f}) if args.feat_sets \\\n",
    "                                                                                         else pep_feature_cols                                                                       \n",
    "    pep_feature_cols.append(pep_col)\n",
    "    \n",
    "    seeds = None if seeds is None else seeds.split(';')\n",
    "\n",
    "    # retrieve list of amino acid feature files\n",
    "    aa_feature_files = get_aa_feature_files_from_dir(aa_feature_folder)\n",
    "    \n",
    "    train_df = pd.read_csv(train_file)\n",
    "\n",
    "    assert(all([np.issubdtype(pep_df[c], np.number) for c in pep_df.columns if c!=pep_col]))\n",
    "    \n",
    "    # decoys_resampled = decoys_df.sample(N, random_state=1)\n",
    "\n",
    "    rep_metrics = []\n",
    "    \n",
    "    peptide_dataset = PeptideDatasetTrain(train_df, \n",
    "                                          pep_col_name=pep_col, \n",
    "                                          allele_col_name=allele_col, \n",
    "                                          target_col_name=tgt_col, \n",
    "                                          fold_col_name=fold_col, \n",
    "                                          folds=folds, \n",
    "                                          aa_feature_files=aa_feature_files)\n",
    "    \n",
    "    if val_file is not None:\n",
    "        val_df = pd.read_csv(val_file)\n",
    "        val_dataset = PeptideDatasetTrain(val_df, \n",
    "                                          pep_col_name=pep_col, \n",
    "                                          allele_col_name=allele_col, \n",
    "                                          target_col_name=tgt_col, \n",
    "                                          fold_col_name=fold_col, \n",
    "                                          folds=folds, \n",
    "                                          aa_feature_files=aa_feature_files)\n",
    "    else:\n",
    "        val_dataset = None\n",
    "        \n",
    "    \n",
    "    for rep in range(1,reps+1):\n",
    "        print(\"\\nTraining rep {} of {} reps...\".format(rep,reps))\n",
    "\n",
    "        rep_outdir = ''.join([outdir,'/rep',str(rep)])\n",
    "        seed = random.randrange(0,100) if seeds is None else int(seeds[rep-1])\n",
    "        print(f\"SEED: {seed}\\n\")\n",
    "        \n",
    "        metrics = trainer(peptide_dataset=peptide_dataset, \n",
    "                          folds=folds, \n",
    "                          epochs=epochs, \n",
    "                          learning_rate=learning_rate, \n",
    "                          dropout_rate=dropout_rate, \n",
    "                          batch_size=batch_size, \n",
    "                          pred_replicates=pred_replicates,\n",
    "                          decoy_mul=decoy_mul, \n",
    "                          decoy_ratio=decoy_ratio, \n",
    "                          resampling_hits=resampling_hits, \n",
    "                          aa_feature_files=aa_feature_files, \n",
    "                          output_dir=outdir, \n",
    "                          featsets_dict=pep_feature_sets_dict,\n",
    "                          run_name=run_name,\n",
    "                          seed=seed,\n",
    "                          reassign_folds=assign_folds,\n",
    "                          val_dataset=val_dataset)\n",
    "        \n",
    "        rep_metrics.extend(metrics)\n",
    "\n",
    "        print(\"Training finished for rep {}. Outputs stored in {}\".format(rep,rep_outdir))\n",
    "    \n",
    "    all_metrics = pd.DataFrame(rep_metrics, columns=[\"features\",\"auc\",\"prauc\",\"ppv\"])\n",
    "    all_metrics.to_csv(os.path.join(outdir,'all_metrics.tsv'),sep='\\t',index=False)\n",
    "    \n",
    "    # create summary plots if running multiple reps\n",
    "    if reps>1:\n",
    "        \n",
    "        summ_metrics = get_dedup_pep_df(all_metrics)\n",
    "        summ_metrics.to_csv(os.path.join(outdir,'summary_metrics.tsv'),sep='\\t',index=False)\n",
    "\n",
    "        TrainingEvaluation.save_feature_comparison_plots(summ_metrics, \"mean_prauc\", \"std_prauc\", outdir, \"prauc_barplot.png\")\n",
    "        TrainingEvaluation.save_feature_comparison_plots(summ_metrics, \"mean_ppv\", \"std_ppv\", outdir, \"ppv_barplot.png\")\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    main()        \n",
    "        "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f30db30ee44050a2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def trainer(peptide_dataset: PeptideDatasetTrain,\n",
    "            folds: int,\n",
    "            epochs: int,\n",
    "            learning_rate: float,\n",
    "            dropout_rate: float,\n",
    "            batch_size: int,\n",
    "            pred_replicates: int,\n",
    "            decoy_mul: int,\n",
    "            decoy_ratio: int,\n",
    "            resampling_hits: bool,\n",
    "            aa_feature_files: List[os.PathLike],\n",
    "            output_dir: os.PathLike,\n",
    "            featsets_dict: Dict[str, List[str]] = {},\n",
    "            run_name: str = \"\", \n",
    "            seed: int = None,\n",
    "            reassign_folds: bool = True,\n",
    "            val_dataset: PeptideDatasetTrain = None):\n",
    "\n",
    "    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "    metric_rows = []\n",
    "\n",
    "    # peptide_dataset = PeptideDataset(hits_df, decoys_df, aa_feature_files)\n",
    "    if reassign_folds:\n",
    "        peptide_dataset.reassign_folds(folds, seed=seed)\n",
    "\n",
    "    for featname in featsets_dict:\n",
    "        print(\"Training feature set {} of {}...\\n\".format(str(featname), str(list(featsets_dict.keys()))))\n",
    "\n",
    "        feat_set = featsets_dict[featname]\n",
    "        run_out_path = '_'.join([run_name, featname]) if run_name else featname\n",
    "\n",
    "        models_dir, configs_dir, eval_dir = make_output_dirs(output_dir=output_dir, out_path=run_out_path)\n",
    "\n",
    "        eval_dict = {\"peptide\": [], \"target\": [], \"pred_mean\": [], \"pred_var\": [], \"fold\": []}\n",
    "        cross_fold_dict = {\"fold\": [], \"ppv\": [], \"prauc\": []}\n",
    "\n",
    "        # peptide_dataset = PeptideDataset(hits_df, decoys_df, aa_feature_files, feat_cols=feat_set, folds=folds)\n",
    "        peptide_dataset.set_feat_cols(feat_set)\n",
    "        feature_dims = peptide_dataset.feature_dimensions()\n",
    "\n",
    "        # hits_df = hits_df.sample(hits_df.shape[0]*decoy_mul, replace=True, random_state=seed, ignore_index=True)\n",
    "        for fold in range(folds):\n",
    "\n",
    "            print(\"Training fold {} of {}...\".format(str(fold + 1), folds))\n",
    "            # resampling_hits = False\n",
    "            train_ids = peptide_dataset.get_train_idxs(fold=fold, decoy_mul=decoy_mul, resampling_hits=resampling_hits,\n",
    "                                                       seed=seed)\n",
    "            test_ids = peptide_dataset.get_test_idxs(fold=fold, decoy_ratio=decoy_ratio, seed=seed)\n",
    "            print(f\"decoy mul: {decoy_mul}\")\n",
    "            print(f\"decoy ratio: {decoy_ratio}\")\n",
    "\n",
    "            # print(f\"Train split:\")\n",
    "            # unique, counts = np.unique(peptide_dataset.binds[train_ids], return_counts=True)\n",
    "            # print(np.asarray((unique, counts)))\n",
    "            # if len(feat_set):\n",
    "            #     print(peptide_dataset.pep_df.iloc[train_ids].groupby('binds')[feat_set].describe())\n",
    "            # print()\n",
    "            # \n",
    "            # print(f\"Test split:\")\n",
    "            # unique, counts = np.unique(peptide_dataset.binds[test_ids], return_counts=True)\n",
    "            # print(np.asarray((unique, counts)))\n",
    "            # if len(feat_set):\n",
    "            #     print(peptide_dataset.pep_df.iloc[test_ids].groupby('binds')[feat_set].describe())\n",
    "            # print()\n",
    "\n",
    "            # Sample elements randomly from a given list of ids, no replacement.\n",
    "            train_subsampler = peptide_nn.PeptideRandomSampler(train_ids, seed)\n",
    "            test_subsampler = peptide_nn.PeptideRandomSampler(test_ids, seed)\n",
    "            # return peptide_dataset, train_subsampler, test_subsampler, train_ids, test_ids\n",
    "            # Define data loaders for training and testing data in this fold\n",
    "            trainloader = torch_data.DataLoader(peptide_dataset, batch_size=batch_size, sampler=train_subsampler)\n",
    "            testloader = torch_data.DataLoader(peptide_dataset, batch_size=batch_size, sampler=test_subsampler)\n",
    "\n",
    "\n",
    "            try:\n",
    "                val_subsampler = peptide_nn.PeptideRandomSampler([i for i in range(len(val_dataset))], seed)\n",
    "                valloader = torch_data.DataLoader(val_dataset, batch_size=batch_size, shuffle=val_subsampler)\n",
    "            except:\n",
    "                valloader = None\n",
    "            \n",
    "            model = peptide_nn.PeptideNN2(feature_dims, dropout_rate)\n",
    "            if torch.cuda.device_count() > 1:\n",
    "                print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "                model = nn.DataParallel(model)\n",
    "            model.to(device)\n",
    "            optimizer_dict = peptide_nn.train(model, trainloader, learning_rate, epochs, device, valloader)\n",
    "            \n",
    "            # Create model and train\n",
    "            model_config = create_config_dict(device=device, epochs=epochs, lr=learning_rate, dr=dropout_rate,\n",
    "                batch_size=batch_size, decoy_mul=decoy_mul, eval_decoy_ratio=decoy_ratio,\n",
    "                fold=fold, aa_features=aa_feature_files,\n",
    "                featname=featname, pepfeats_dict=featsets_dict, seed=seed)\n",
    "\n",
    "            # model = peptide_nn.PeptideNN(feature_dims, dropout_rate).to(device)\n",
    "            # optimizer_dict = peptide_nn.train(model, trainloader, learning_rate, epochs, device)\n",
    "\n",
    "            peptide_nn.save_model(model, fold, models_dir, configs_dir, optimizer_dict, model_config)\n",
    "            \n",
    "            inputs, targets, indices, preds = peptide_nn.evaluate(model, testloader, pred_replicates, device)\n",
    "            inputs = torch.vstack(inputs).cpu()\n",
    "            targets = [t.item() for t in torch.hstack(targets).cpu()]\n",
    "            indices = [i.item() for i in torch.hstack(indices).cpu()]\n",
    "            preds = torch.vstack(preds).cpu()\n",
    "            \n",
    "            input_peps, input_hla = [peptide_dataset.pep_at(i) for i in indices], [peptide_dataset.allele_at(i) for i in indices]\n",
    "            pred_means = preds.mean(dim=-1).numpy()\n",
    "            pred_vars = preds.var(dim=-1).numpy()\n",
    "\n",
    "\n",
    "            for p, t, m, v in zip(input_peps, targets, pred_means, pred_vars):\n",
    "                eval_dict['peptide'].append(p)\n",
    "                eval_dict['target'].append(t)\n",
    "                eval_dict['pred_mean'].append(m)\n",
    "                eval_dict['pred_var'].append(v)\n",
    "                eval_dict['fold'].append(str(fold + 1))\n",
    "\n",
    "        eval_df = pd.DataFrame.from_dict(eval_dict)\n",
    "\n",
    "        ## getting cross-fold metrics\n",
    "        rows = []\n",
    "        for fold, df in eval_df.groupby(\"fold\"):\n",
    "            train_eval = TrainingEvaluation(eval_df=df, decoy_ratio=True)\n",
    "            cross_fold_dict['fold'].append(fold)\n",
    "            cross_fold_dict['ppv'].append(train_eval.get_ppv())\n",
    "            cross_fold_dict['prauc'].append(train_eval.get_prauc())\n",
    "\n",
    "        crossfold_df = pd.DataFrame.from_dict(cross_fold_dict)\n",
    "        crossfold_df.to_csv(os.path.join(eval_dir, \"crossfold_eval.tsv\"), index=False, sep='\\t')\n",
    "\n",
    "        eval_path_name = '{}_{}_eval.txt'.format(run_out_path, get_currtime())\n",
    "        eval_df.to_csv(os.path.join(eval_dir, eval_path_name), index=False, sep='\\t')\n",
    "\n",
    "        train_eval = TrainingEvaluation(eval_df=eval_df, seed=seed, decoy_ratio=True)\n",
    "        auc, prauc, ppv = train_eval.get_auc(), train_eval.get_prauc(), train_eval.get_ppv()\n",
    "\n",
    "        print('\\nTraining and evaluation finished for {run}.\\n \\\n",
    "                 AUC: {auc}\\n \\\n",
    "                 PPV: {ppv}\\n \\\n",
    "                 PRAUC: {prauc}\\n \\\n",
    "            '.format(run=featname, auc=auc, ppv=ppv, prauc=prauc))\n",
    "\n",
    "        metric_rows.append([featname, auc, prauc, ppv])\n",
    "\n",
    "    eval_metrics = pd.DataFrame(metric_rows, columns=['features', 'auc', 'prauc', 'ppv'])\n",
    "    eval_metrics.to_csv(os.path.join(output_dir, 'eval_metrics.tsv'), sep='\\t', index=False)\n",
    "    return metric_rows\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T03:48:58.701831Z",
     "start_time": "2023-12-27T03:48:58.698730Z"
    }
   },
   "id": "eb8725010aa04f72",
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training feature set P of ['P', 'PC']...\n",
      "\n",
      "Training fold 1 of 5...\n",
      "Resampling hits: False\n",
      "decoy mul: 1\n",
      "decoy ratio: 1\n",
      "\tIn Model: input size torch.Size([750, 475]) output size torch.Size([750, 1])\n",
      "Train outside: input size torch.Size([750, 475]) output_size torch.Size([750, 1])\n",
      "\n",
      "Avg. train epoch 0 loss: 0.6942673921585083\n",
      "\tIn Model: input size torch.Size([1450, 475]) output size torch.Size([1450, 1])\n",
      "Eval outside: input size torch.Size([1450, 475]) output_size torch.Size([1450, 1])\n",
      "Avg. validation epoch 0 loss: 0.579961359500885\n",
      "\tIn Model: input size torch.Size([252, 475]) output size torch.Size([252, 1])\n",
      "\tIn Model: input size torch.Size([252, 475]) output size torch.Size([252, 1])\n",
      "\tIn Model: input size torch.Size([252, 475]) output size torch.Size([252, 1])\n",
      "\tIn Model: input size torch.Size([252, 475]) output size torch.Size([252, 1])\n",
      "\tIn Model: input size torch.Size([252, 475]) output size torch.Size([252, 1])\n",
      "\tIn Model: input size torch.Size([252, 475]) output size torch.Size([252, 1])\n",
      "\tIn Model: input size torch.Size([252, 475]) output size torch.Size([252, 1])\n",
      "\tIn Model: input size torch.Size([252, 475]) output size torch.Size([252, 1])\n",
      "\tIn Model: input size torch.Size([252, 475]) output size torch.Size([252, 1])\n",
      "\tIn Model: input size torch.Size([252, 475]) output size torch.Size([252, 1])\n",
      "Training fold 2 of 5...\n",
      "Resampling hits: False\n",
      "decoy mul: 1\n",
      "decoy ratio: 1\n",
      "\tIn Model: input size torch.Size([790, 475]) output size torch.Size([790, 1])\n",
      "Train outside: input size torch.Size([790, 475]) output_size torch.Size([790, 1])\n",
      "\n",
      "Avg. train epoch 0 loss: 0.6958160996437073\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/2_/m2j1vfpd7r367lw9w_n7jlnc0000gn/T/ipykernel_58413/4106975401.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     22\u001B[0m metrics = trainer(peptide_dataset=peptide_dataset, folds=folds, epochs=1, learning_rate=learning_rate, dropout_rate=dropout_rate, batch_size=batch_size, pred_replicates=pred_replicates,\n\u001B[1;32m     23\u001B[0m         \u001B[0mdecoy_mul\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdecoy_mul\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdecoy_ratio\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdecoy_ratio\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mresampling_hits\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maa_feature_files\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0maa_feature_files\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moutput_dir\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m''\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfeatsets_dict\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m{\u001B[0m\u001B[0;34m'P'\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'PC'\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m'tgt_weight'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 24\u001B[0;31m                   val_dataset=peptide_dataset)\n\u001B[0m",
      "\u001B[0;32m/var/folders/2_/m2j1vfpd7r367lw9w_n7jlnc0000gn/T/ipykernel_58413/1206894761.py\u001B[0m in \u001B[0;36mtrainer\u001B[0;34m(peptide_dataset, folds, epochs, learning_rate, dropout_rate, batch_size, pred_replicates, decoy_mul, decoy_ratio, resampling_hits, aa_feature_files, output_dir, featsets_dict, run_name, seed, reassign_folds, val_dataset)\u001B[0m\n\u001B[1;32m     84\u001B[0m                 \u001B[0mmodel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mDataParallel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     85\u001B[0m             \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 86\u001B[0;31m             \u001B[0moptimizer_dict\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpeptide_nn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrainloader\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlearning_rate\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mepochs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalloader\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     87\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     88\u001B[0m             \u001B[0;31m# Create model and train\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/hlathenav2/hlathena/peptide_nn.py\u001B[0m in \u001B[0;36mtrain\u001B[0;34m(model, trainloader, learning_rate, epochs, device, valloader, patience, min_delta)\u001B[0m\n\u001B[1;32m    176\u001B[0m         \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf\"Avg. train epoch {e} loss: {train_epoch_loss}\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    177\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mvalloader\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 178\u001B[0;31m             \u001B[0mval_epoch_loss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0meval_loss\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalloader\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m/\u001B[0m\u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvalloader\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msampler\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    179\u001B[0m             \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf\"Avg. validation epoch {e} loss: {val_epoch_loss}\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    180\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mearly_stopper\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mearly_stop\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mval_epoch_loss\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/hlathenav2/hlathena/peptide_nn.py\u001B[0m in \u001B[0;36meval_loss\u001B[0;34m(model, dataloader, device)\u001B[0m\n\u001B[1;32m    205\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    206\u001B[0m         \u001B[0;31m# Iterate over the test data and generate predictions\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 207\u001B[0;31m         \u001B[0;32mfor\u001B[0m \u001B[0m_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdata\u001B[0m \u001B[0;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdataloader\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;31m# add dataset label to get item tuple?\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    208\u001B[0m             \u001B[0minputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfloat\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    209\u001B[0m             \u001B[0mlabels\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/hlathenav2/venv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001B[0m in \u001B[0;36m__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    626\u001B[0m                 \u001B[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    627\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_reset\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# type: ignore[call-arg]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 628\u001B[0;31m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_next_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    629\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_num_yielded\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    630\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_dataset_kind\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0m_DatasetKind\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mIterable\u001B[0m \u001B[0;32mand\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m\\\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/hlathenav2/venv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001B[0m in \u001B[0;36m_next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    669\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_next_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    670\u001B[0m         \u001B[0mindex\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_next_index\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# may raise StopIteration\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 671\u001B[0;31m         \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_dataset_fetcher\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfetch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mindex\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# may raise StopIteration\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    672\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_pin_memory\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    673\u001B[0m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_utils\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpin_memory\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpin_memory\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_pin_memory_device\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/hlathenav2/venv/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001B[0m in \u001B[0;36mfetch\u001B[0;34m(self, possibly_batched_index)\u001B[0m\n\u001B[1;32m     56\u001B[0m                 \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__getitems__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpossibly_batched_index\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     57\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 58\u001B[0;31m                 \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0midx\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0midx\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mpossibly_batched_index\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     59\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     60\u001B[0m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mpossibly_batched_index\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/hlathenav2/venv/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m     56\u001B[0m                 \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__getitems__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpossibly_batched_index\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     57\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 58\u001B[0;31m                 \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0midx\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0midx\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mpossibly_batched_index\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     59\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     60\u001B[0m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mpossibly_batched_index\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/hlathenav2/hlathena/peptide_dataset_train.py\u001B[0m in \u001B[0;36m__getitem__\u001B[0;34m(self, i)\u001B[0m\n\u001B[1;32m     98\u001B[0m         return (self.PepHLAEncoder.encode(self.pep_at(i),\n\u001B[1;32m     99\u001B[0m                                           \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mallele_at\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 100\u001B[0;31m                                           self.pep_features_at(i)),\n\u001B[0m\u001B[1;32m    101\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtgt_at\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    102\u001B[0m                 i)\n",
      "\u001B[0;32m~/PycharmProjects/hlathenav2/hlathena/peptide_dataset_train.py\u001B[0m in \u001B[0;36mpep_features_at\u001B[0;34m(self, i)\u001B[0m\n\u001B[1;32m    109\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    110\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mpep_features_at\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mint\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mndarray\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 111\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpep_df\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpeptide_feature_cols\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0miloc\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    112\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    113\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mtgt_at\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mint\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mint\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/hlathenav2/venv/lib/python3.7/site-packages/pandas/core/frame.py\u001B[0m in \u001B[0;36m__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3462\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mis_iterator\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3463\u001B[0m                 \u001B[0mkey\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3464\u001B[0;31m             \u001B[0mindexer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mloc\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_get_listlike_indexer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   3465\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3466\u001B[0m         \u001B[0;31m# take() does not accept boolean indexers\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/hlathenav2/venv/lib/python3.7/site-packages/pandas/core/indexing.py\u001B[0m in \u001B[0;36m_get_listlike_indexer\u001B[0;34m(self, key, axis)\u001B[0m\n\u001B[1;32m   1307\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1308\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0max\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_index_as_unique\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1309\u001B[0;31m             \u001B[0mindexer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0max\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_indexer_for\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkeyarr\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1310\u001B[0m             \u001B[0mkeyarr\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0max\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreindex\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkeyarr\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1311\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/hlathenav2/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001B[0m in \u001B[0;36mget_indexer_for\u001B[0;34m(self, target, **kwargs)\u001B[0m\n\u001B[1;32m   5273\u001B[0m         \"\"\"\n\u001B[1;32m   5274\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_index_as_unique\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 5275\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_indexer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtarget\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   5276\u001B[0m         \u001B[0mindexer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_indexer_non_unique\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtarget\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   5277\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mindexer\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/hlathenav2/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001B[0m in \u001B[0;36mget_indexer\u001B[0;34m(self, target, method, limit, tolerance)\u001B[0m\n\u001B[1;32m   3484\u001B[0m             )\n\u001B[1;32m   3485\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3486\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_get_indexer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtarget\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmethod\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlimit\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtolerance\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   3487\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3488\u001B[0m     def _get_indexer(\n",
      "\u001B[0;32m~/PycharmProjects/hlathenav2/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001B[0m in \u001B[0;36m_get_indexer\u001B[0;34m(self, target, method, limit, tolerance)\u001B[0m\n\u001B[1;32m   3500\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3501\u001B[0m             \u001B[0mthis\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mastype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3502\u001B[0;31m             \u001B[0mtarget\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtarget\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mastype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   3503\u001B[0m             return this.get_indexer(\n\u001B[1;32m   3504\u001B[0m                 \u001B[0mtarget\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmethod\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmethod\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlimit\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mlimit\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtolerance\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtolerance\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/hlathenav2/venv/lib/python3.7/site-packages/pandas/core/indexes/numeric.py\u001B[0m in \u001B[0;36mastype\u001B[0;34m(self, dtype, copy)\u001B[0m\n\u001B[1;32m    224\u001B[0m                 \u001B[0;32mreturn\u001B[0m \u001B[0mInt64Index\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0marr\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    225\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 226\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mastype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcopy\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    227\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    228\u001B[0m     \u001B[0;31m# ----------------------------------------------------------------\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/hlathenav2/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001B[0m in \u001B[0;36mastype\u001B[0;34m(self, dtype, copy)\u001B[0m\n\u001B[1;32m    916\u001B[0m                 \u001B[0;34mf\"Cannot cast {type(self).__name__} to dtype {dtype}\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    917\u001B[0m             ) from err\n\u001B[0;32m--> 918\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mIndex\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcasted\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    919\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    920\u001B[0m     _index_shared_docs[\n",
      "\u001B[0;32m~/PycharmProjects/hlathenav2/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001B[0m in \u001B[0;36m__new__\u001B[0;34m(cls, data, dtype, copy, name, tupleize_cols, **kwargs)\u001B[0m\n\u001B[1;32m    466\u001B[0m                         \u001B[0;32mreturn\u001B[0m \u001B[0mcls\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0marr\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcopy\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    467\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 468\u001B[0;31m             \u001B[0mklass\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcls\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_dtype_to_subclass\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0marr\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    469\u001B[0m             \u001B[0marr\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mklass\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_ensure_array\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0marr\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    470\u001B[0m             \u001B[0mdisallow_kwargs\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/hlathenav2/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001B[0m in \u001B[0;36m_dtype_to_subclass\u001B[0;34m(cls, dtype)\u001B[0m\n\u001B[1;32m    562\u001B[0m         \u001B[0;31m# error: Non-overlapping equality check (left operand type: \"dtype[Any]\", right\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    563\u001B[0m         \u001B[0;31m# operand type: \"Type[object]\")\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 564\u001B[0;31m         \u001B[0;32melif\u001B[0m \u001B[0mdtype\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0mobject\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# type: ignore[comparison-overlap]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    565\u001B[0m             \u001B[0;31m# NB: assuming away MultiIndex\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    566\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mIndex\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# def trainer(peptide_dataset: PeptideDatasetTrain,\n",
    "#             folds: int,\n",
    "#             epochs: int,\n",
    "#             learning_rate: float,\n",
    "#             dropout_rate: float,\n",
    "#             batch_size: int,\n",
    "#             pred_replicates: int,\n",
    "#             decoy_mul: int,\n",
    "#             decoy_ratio: int,\n",
    "#             resampling_hits: bool,\n",
    "#             aa_feature_files: List[os.PathLike],\n",
    "#             output_dir: os.PathLike,\n",
    "#             featsets_dict: Dict[str, List[str]] = {},\n",
    "#             run_name: str = \"\", seed: int = None,\n",
    "#             reassign_folds: bool = True):\n",
    "data_dir = '/Users/cleoforman/PycharmProjects/hlathenav2/notebooks/input/'\n",
    "\n",
    "aa_feature_files = [os.path.join(data_dir, 'aafeatmat_KideraFactors.txt')]\n",
    "\n",
    "peptide_dataset = PeptideDatasetTrain(mini_df, pep_col_name='pep', allele_col_name='mhc', target_col_name='tgt', folds=5, aa_feature_files=aa_feature_files)\n",
    "\n",
    "metrics = trainer(peptide_dataset=peptide_dataset, folds=folds, epochs=1, learning_rate=learning_rate, dropout_rate=dropout_rate, batch_size=batch_size, pred_replicates=pred_replicates,\n",
    "        decoy_mul=decoy_mul, decoy_ratio=decoy_ratio, resampling_hits=False, aa_feature_files=aa_feature_files, output_dir='', featsets_dict={'P':[], 'PC': ['tgt_weight']},\n",
    "                  val_dataset=peptide_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T03:49:09.043569Z",
     "start_time": "2023-12-27T03:48:59.414526Z"
    }
   },
   "id": "73996354bb38f902",
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "476"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peptide_dataset.feature_dimensions()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T03:17:01.349990Z",
     "start_time": "2023-12-27T03:17:01.342360Z"
    }
   },
   "id": "9003f4da0ec3e3f4",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[['P', 0.7389055581451867, 0.0059969419286015554, 0.001996007984031936],\n ['PC', 0.8194172672618834, 0.09823998676359039, 0.09181636726546906]]"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T03:23:13.561616Z",
     "start_time": "2023-12-27T03:23:13.558282Z"
    }
   },
   "id": "7e4c2cc86c537589",
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "2d34f1b193aeee5b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "venv",
   "language": "python",
   "display_name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
