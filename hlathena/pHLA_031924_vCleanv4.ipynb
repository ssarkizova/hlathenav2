{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7a9b907",
   "metadata": {},
   "source": [
    "This is the version where I add the ESM Embedding in various formats so we can test them (using ESM + adding our own layers to tune the param more for our purposes): \n",
    "1. (simplest) concatenate the two sequences and encode with ESM only --> positional embedding together --> self attention\n",
    "2. concatenate the two sequences and encode with ESM + 3 linear layers afterwards --> positional embedding together --> self attention\n",
    "3. concatenate the two sequences and encode with ESM (all layers of ESM except the last three are frozen --> model will fine tune the last three layers for transfer learning) --> positional embedding together --> self attention\n",
    "4. encode the two sequences with ESM only separately --> positional embedding separately --> cross attention\n",
    "5. encode the two sequences with ESM + 3 linear layers afterwards separately --> positional embedding separately --> cross attention\n",
    "6. encode the two sequences with ESM separately (all layers of ESM except the last three are frozen --> model will fine tune the last three layers for transfer learning) --> positional embedding separately --> cross attention\n",
    "\n",
    "\n",
    "other sources of optionality: \n",
    "1. for each of the esm models, you can choose between taking the CLS token representation for classification (what wengong had suggested) or mean pooling \n",
    "    1. should we add a way to do it with just taking the raw values as well and projecting it to a dim of 1 before sigmoid (TODO)\n",
    "2. activation function choice when you add 3 linear layers to the ESM embedding (need to add dropout and activation functions if you add three more layers since I have seen that done by convention but also I believe it helps with generalization and preventing the collapsing of the three linear layers into just one overall linear transformation (adding non-linearity to it using the activation functions) + preventing overfitting (adding the dropout in each of these linear layers)\n",
    "    1. \"To determine the best activation function for your model, consider experimenting with different options and evaluating their impact on your model's performance on a validation set. Activation functions can have different effects depending on the overall architecture and the specific characteristics of the data. For example, if you're finding that a significant number of neurons are dying (i.e., outputting zero across all inputs) with ReLU, you might try Leaky ReLU or PReLU. If you're experiencing issues with convergence or if your model benefits from smoother functions, GELU or Swish might offer improvements.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59dea606",
   "metadata": {},
   "source": [
    "https://github.com/facebookresearch/esm/issues/348 and ChatGPT make me feel like the tokenizer and model are both needed for the embedding so I made a HuggingFace version since I think the facebook version we played with was complete but hard for me to see how to best add padding tokens to it (I think <pad> is enough, but wasn't sure so went this route to be safe!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "296b3e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interactive namespace is empty.\n"
     ]
    }
   ],
   "source": [
    "%reset -f\n",
    "%whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f45e3688",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import esm\n",
    "from os.path import exists\n",
    "#import fair_esm\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.functional import log_softmax, pad\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import copy\n",
    "import time\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import re\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "import pandas as pd\n",
    "from torchtext.data.functional import to_map_style_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "import torchtext.datasets as datasets\n",
    "from torch.utils.data import Dataset\n",
    "import spacy\n",
    "import GPUtil\n",
    "import warnings\n",
    "import seaborn\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from transformers import EsmTokenizer, EsmModel\n",
    "from torch.utils.data import dataset\n",
    "seaborn.set_context(context=\"talk\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c214ea40",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "875c8e19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ABCG</th>\n",
       "      <th>length</th>\n",
       "      <th>allele</th>\n",
       "      <th>seed</th>\n",
       "      <th>fold</th>\n",
       "      <th>set</th>\n",
       "      <th>seq</th>\n",
       "      <th>label</th>\n",
       "      <th>boman</th>\n",
       "      <th>hmoment</th>\n",
       "      <th>hydrophobicity</th>\n",
       "      <th>helixbend</th>\n",
       "      <th>sidechain</th>\n",
       "      <th>xstr</th>\n",
       "      <th>partspec</th>\n",
       "      <th>pkc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>10</td>\n",
       "      <td>A0101</td>\n",
       "      <td>123</td>\n",
       "      <td>2</td>\n",
       "      <td>valid</td>\n",
       "      <td>HTDDPLTWDY</td>\n",
       "      <td>1</td>\n",
       "      <td>2.885</td>\n",
       "      <td>0.075970</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.171</td>\n",
       "      <td>-0.391</td>\n",
       "      <td>-0.073</td>\n",
       "      <td>0.113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>10</td>\n",
       "      <td>A0101</td>\n",
       "      <td>123</td>\n",
       "      <td>2</td>\n",
       "      <td>valid</td>\n",
       "      <td>WVDDQRPENY</td>\n",
       "      <td>1</td>\n",
       "      <td>4.512</td>\n",
       "      <td>0.132024</td>\n",
       "      <td>0.329</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.373</td>\n",
       "      <td>-0.248</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>10</td>\n",
       "      <td>A0101</td>\n",
       "      <td>123</td>\n",
       "      <td>2</td>\n",
       "      <td>valid</td>\n",
       "      <td>LSDIGSGIRY</td>\n",
       "      <td>1</td>\n",
       "      <td>1.394</td>\n",
       "      <td>0.550009</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.422</td>\n",
       "      <td>-0.387</td>\n",
       "      <td>0.379</td>\n",
       "      <td>-0.314</td>\n",
       "      <td>-0.255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>10</td>\n",
       "      <td>A0101</td>\n",
       "      <td>123</td>\n",
       "      <td>2</td>\n",
       "      <td>valid</td>\n",
       "      <td>ALTSRRRAQR</td>\n",
       "      <td>0</td>\n",
       "      <td>6.265</td>\n",
       "      <td>0.470852</td>\n",
       "      <td>0.799</td>\n",
       "      <td>-0.268</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.474</td>\n",
       "      <td>-0.140</td>\n",
       "      <td>0.023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>10</td>\n",
       "      <td>A0101</td>\n",
       "      <td>123</td>\n",
       "      <td>2</td>\n",
       "      <td>valid</td>\n",
       "      <td>QASSLRLHQN</td>\n",
       "      <td>0</td>\n",
       "      <td>3.245</td>\n",
       "      <td>0.235895</td>\n",
       "      <td>0.353</td>\n",
       "      <td>-0.201</td>\n",
       "      <td>-0.163</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.272</td>\n",
       "      <td>0.157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2695506</th>\n",
       "      <td>G</td>\n",
       "      <td>10</td>\n",
       "      <td>G0104</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>valid</td>\n",
       "      <td>KPRSSLGMHM</td>\n",
       "      <td>0</td>\n",
       "      <td>2.137</td>\n",
       "      <td>0.086025</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.077</td>\n",
       "      <td>-0.148</td>\n",
       "      <td>-0.128</td>\n",
       "      <td>-0.058</td>\n",
       "      <td>-0.407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2695507</th>\n",
       "      <td>G</td>\n",
       "      <td>10</td>\n",
       "      <td>G0104</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>valid</td>\n",
       "      <td>GVHQYIDADT</td>\n",
       "      <td>0</td>\n",
       "      <td>1.864</td>\n",
       "      <td>0.268986</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.035</td>\n",
       "      <td>-0.340</td>\n",
       "      <td>0.127</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>0.076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2695508</th>\n",
       "      <td>G</td>\n",
       "      <td>10</td>\n",
       "      <td>G0104</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>valid</td>\n",
       "      <td>APGLLPYEPF</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.862</td>\n",
       "      <td>0.059929</td>\n",
       "      <td>-0.570</td>\n",
       "      <td>0.372</td>\n",
       "      <td>-0.197</td>\n",
       "      <td>-0.630</td>\n",
       "      <td>-0.743</td>\n",
       "      <td>0.298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2695509</th>\n",
       "      <td>G</td>\n",
       "      <td>10</td>\n",
       "      <td>G0104</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>valid</td>\n",
       "      <td>VGRYLETKPA</td>\n",
       "      <td>0</td>\n",
       "      <td>1.828</td>\n",
       "      <td>0.351823</td>\n",
       "      <td>0.213</td>\n",
       "      <td>0.025</td>\n",
       "      <td>-0.161</td>\n",
       "      <td>0.099</td>\n",
       "      <td>-0.543</td>\n",
       "      <td>-0.193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2695510</th>\n",
       "      <td>G</td>\n",
       "      <td>10</td>\n",
       "      <td>G0104</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>valid</td>\n",
       "      <td>SHLTKLKEFS</td>\n",
       "      <td>0</td>\n",
       "      <td>1.912</td>\n",
       "      <td>0.316484</td>\n",
       "      <td>0.269</td>\n",
       "      <td>-0.295</td>\n",
       "      <td>0.047</td>\n",
       "      <td>-0.166</td>\n",
       "      <td>-0.739</td>\n",
       "      <td>-0.007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2695511 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ABCG  length allele  seed  fold    set         seq  label  boman  \\\n",
       "0          A      10  A0101   123     2  valid  HTDDPLTWDY      1  2.885   \n",
       "1          A      10  A0101   123     2  valid  WVDDQRPENY      1  4.512   \n",
       "2          A      10  A0101   123     2  valid  LSDIGSGIRY      1  1.394   \n",
       "3          A      10  A0101   123     2  valid  ALTSRRRAQR      0  6.265   \n",
       "4          A      10  A0101   123     2  valid  QASSLRLHQN      0  3.245   \n",
       "...      ...     ...    ...   ...   ...    ...         ...    ...    ...   \n",
       "2695506    G      10  G0104   123     1  valid  KPRSSLGMHM      0  2.137   \n",
       "2695507    G      10  G0104   123     1  valid  GVHQYIDADT      0  1.864   \n",
       "2695508    G      10  G0104   123     1  valid  APGLLPYEPF      0 -0.862   \n",
       "2695509    G      10  G0104   123     1  valid  VGRYLETKPA      0  1.828   \n",
       "2695510    G      10  G0104   123     1  valid  SHLTKLKEFS      0  1.912   \n",
       "\n",
       "          hmoment  hydrophobicity  helixbend  sidechain   xstr  partspec  \\\n",
       "0        0.075970          -0.001      0.455      0.171 -0.391    -0.073   \n",
       "1        0.132024           0.329      0.360      0.373 -0.248     0.075   \n",
       "2        0.550009           0.000      0.422     -0.387  0.379    -0.314   \n",
       "3        0.470852           0.799     -0.268      0.020  0.474    -0.140   \n",
       "4        0.235895           0.353     -0.201     -0.163 -0.002    -0.272   \n",
       "...           ...             ...        ...        ...    ...       ...   \n",
       "2695506  0.086025           0.122      0.077     -0.148 -0.128    -0.058   \n",
       "2695507  0.268986           0.147      0.035     -0.340  0.127    -0.024   \n",
       "2695508  0.059929          -0.570      0.372     -0.197 -0.630    -0.743   \n",
       "2695509  0.351823           0.213      0.025     -0.161  0.099    -0.543   \n",
       "2695510  0.316484           0.269     -0.295      0.047 -0.166    -0.739   \n",
       "\n",
       "           pkc  \n",
       "0        0.113  \n",
       "1        0.040  \n",
       "2       -0.255  \n",
       "3        0.023  \n",
       "4        0.157  \n",
       "...        ...  \n",
       "2695506 -0.407  \n",
       "2695507  0.076  \n",
       "2695508  0.298  \n",
       "2695509 -0.193  \n",
       "2695510 -0.007  \n",
       "\n",
       "[2695511 rows x 16 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pan_len = pd.read_csv(\"/Users/jessikabaral/Downloads/MS_panlen_seed_757_5cv_x10p_train_test_valid.txt\", sep = \" \")\n",
    "peptide_10mer = pd.read_csv(\"/Users/jessikabaral/Downloads/MS10_dat_dummy_seed_757_5cv_x10p_train_test_valid.txt\", sep = \" \")\n",
    "peptide_10mer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d07cee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ABCG</th>\n",
       "      <th>length</th>\n",
       "      <th>allele</th>\n",
       "      <th>seed</th>\n",
       "      <th>fold</th>\n",
       "      <th>set</th>\n",
       "      <th>seq</th>\n",
       "      <th>label</th>\n",
       "      <th>boman</th>\n",
       "      <th>hmoment</th>\n",
       "      <th>hydrophobicity</th>\n",
       "      <th>helixbend</th>\n",
       "      <th>sidechain</th>\n",
       "      <th>xstr</th>\n",
       "      <th>partspec</th>\n",
       "      <th>pkc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9057</th>\n",
       "      <td>B</td>\n",
       "      <td>10</td>\n",
       "      <td>B1503</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>AKCQQLQQEY</td>\n",
       "      <td>1</td>\n",
       "      <td>2.665</td>\n",
       "      <td>0.208262</td>\n",
       "      <td>0.429</td>\n",
       "      <td>-0.477</td>\n",
       "      <td>0.089</td>\n",
       "      <td>-0.152</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7710</th>\n",
       "      <td>B</td>\n",
       "      <td>10</td>\n",
       "      <td>B1503</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>GDWMIEFYAP</td>\n",
       "      <td>0</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.232703</td>\n",
       "      <td>-0.426</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.059</td>\n",
       "      <td>-0.445</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>-0.155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4597</th>\n",
       "      <td>B</td>\n",
       "      <td>10</td>\n",
       "      <td>B1301</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>RLEKNVKEVL</td>\n",
       "      <td>1</td>\n",
       "      <td>2.836</td>\n",
       "      <td>0.737044</td>\n",
       "      <td>0.542</td>\n",
       "      <td>-0.578</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.117</td>\n",
       "      <td>-0.733</td>\n",
       "      <td>-0.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1893</th>\n",
       "      <td>A</td>\n",
       "      <td>10</td>\n",
       "      <td>A7401</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>RVADVYRYCR</td>\n",
       "      <td>1</td>\n",
       "      <td>4.259</td>\n",
       "      <td>0.497503</td>\n",
       "      <td>0.318</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.257</td>\n",
       "      <td>0.769</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6450</th>\n",
       "      <td>B</td>\n",
       "      <td>10</td>\n",
       "      <td>B1510</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>FSALSSAYWS</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>0.197359</td>\n",
       "      <td>-0.352</td>\n",
       "      <td>0.055</td>\n",
       "      <td>-0.310</td>\n",
       "      <td>-0.182</td>\n",
       "      <td>-0.625</td>\n",
       "      <td>-0.365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3062</th>\n",
       "      <td>B</td>\n",
       "      <td>10</td>\n",
       "      <td>B5801</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>HVAPVTSVEW</td>\n",
       "      <td>1</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.047392</td>\n",
       "      <td>-0.129</td>\n",
       "      <td>-0.221</td>\n",
       "      <td>-0.310</td>\n",
       "      <td>0.276</td>\n",
       "      <td>-0.190</td>\n",
       "      <td>-0.348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1133</th>\n",
       "      <td>A</td>\n",
       "      <td>10</td>\n",
       "      <td>A3601</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>VGRKVRRPAG</td>\n",
       "      <td>0</td>\n",
       "      <td>3.854</td>\n",
       "      <td>0.779978</td>\n",
       "      <td>0.517</td>\n",
       "      <td>0.226</td>\n",
       "      <td>-0.271</td>\n",
       "      <td>0.538</td>\n",
       "      <td>-0.331</td>\n",
       "      <td>-0.308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5993</th>\n",
       "      <td>B</td>\n",
       "      <td>10</td>\n",
       "      <td>B3801</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>HHVSPHETYF</td>\n",
       "      <td>1</td>\n",
       "      <td>1.988</td>\n",
       "      <td>0.186321</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7321</th>\n",
       "      <td>A</td>\n",
       "      <td>10</td>\n",
       "      <td>A0205</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>DREPGGVTQQ</td>\n",
       "      <td>0</td>\n",
       "      <td>3.818</td>\n",
       "      <td>0.350469</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.291</td>\n",
       "      <td>-0.394</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.092</td>\n",
       "      <td>-0.302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8399</th>\n",
       "      <td>C</td>\n",
       "      <td>10</td>\n",
       "      <td>C0202</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>KLPEFTKSEY</td>\n",
       "      <td>1</td>\n",
       "      <td>2.293</td>\n",
       "      <td>0.317802</td>\n",
       "      <td>0.295</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>0.237</td>\n",
       "      <td>-0.326</td>\n",
       "      <td>-0.665</td>\n",
       "      <td>-0.034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810</th>\n",
       "      <td>A</td>\n",
       "      <td>10</td>\n",
       "      <td>A6801</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>NIISGSGRPR</td>\n",
       "      <td>1</td>\n",
       "      <td>3.156</td>\n",
       "      <td>0.266899</td>\n",
       "      <td>0.278</td>\n",
       "      <td>0.672</td>\n",
       "      <td>-0.426</td>\n",
       "      <td>0.491</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>-0.164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4670</th>\n",
       "      <td>A</td>\n",
       "      <td>10</td>\n",
       "      <td>A6601</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>DTSNIITVRV</td>\n",
       "      <td>1</td>\n",
       "      <td>2.090</td>\n",
       "      <td>0.163090</td>\n",
       "      <td>0.283</td>\n",
       "      <td>0.033</td>\n",
       "      <td>-0.324</td>\n",
       "      <td>0.991</td>\n",
       "      <td>-0.059</td>\n",
       "      <td>0.040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6642</th>\n",
       "      <td>B</td>\n",
       "      <td>10</td>\n",
       "      <td>B0702</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>CEVFRQRFRQ</td>\n",
       "      <td>0</td>\n",
       "      <td>5.137</td>\n",
       "      <td>0.523024</td>\n",
       "      <td>0.467</td>\n",
       "      <td>-0.277</td>\n",
       "      <td>0.484</td>\n",
       "      <td>0.441</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9225</th>\n",
       "      <td>A</td>\n",
       "      <td>10</td>\n",
       "      <td>A2402</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>RYAKIVEIPF</td>\n",
       "      <td>1</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.451965</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>-0.210</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.347</td>\n",
       "      <td>-0.423</td>\n",
       "      <td>0.287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4671</th>\n",
       "      <td>A</td>\n",
       "      <td>10</td>\n",
       "      <td>A3201</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>valid</td>\n",
       "      <td>WEGIAQGHVM</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>0.190568</td>\n",
       "      <td>-0.151</td>\n",
       "      <td>-0.354</td>\n",
       "      <td>-0.323</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>0.231</td>\n",
       "      <td>-0.573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>C</td>\n",
       "      <td>10</td>\n",
       "      <td>C1202</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>KLPVDQYRKQ</td>\n",
       "      <td>0</td>\n",
       "      <td>3.700</td>\n",
       "      <td>0.372992</td>\n",
       "      <td>0.547</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.092</td>\n",
       "      <td>-0.544</td>\n",
       "      <td>0.065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7770</th>\n",
       "      <td>A</td>\n",
       "      <td>10</td>\n",
       "      <td>A3002</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>KYMPDLTPQY</td>\n",
       "      <td>1</td>\n",
       "      <td>1.539</td>\n",
       "      <td>0.393966</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>0.447</td>\n",
       "      <td>0.262</td>\n",
       "      <td>-0.189</td>\n",
       "      <td>-0.346</td>\n",
       "      <td>0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6523</th>\n",
       "      <td>B</td>\n",
       "      <td>10</td>\n",
       "      <td>B1503</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>HQAACLIQAY</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>0.293592</td>\n",
       "      <td>-0.181</td>\n",
       "      <td>-0.630</td>\n",
       "      <td>-0.358</td>\n",
       "      <td>-0.025</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>0.389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>B</td>\n",
       "      <td>10</td>\n",
       "      <td>B4006</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>REIFDKARQA</td>\n",
       "      <td>1</td>\n",
       "      <td>4.494</td>\n",
       "      <td>0.745221</td>\n",
       "      <td>0.578</td>\n",
       "      <td>-0.530</td>\n",
       "      <td>0.105</td>\n",
       "      <td>-0.112</td>\n",
       "      <td>-0.190</td>\n",
       "      <td>0.315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8348</th>\n",
       "      <td>B</td>\n",
       "      <td>10</td>\n",
       "      <td>B1301</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>KLLKRLFLFS</td>\n",
       "      <td>0</td>\n",
       "      <td>0.378</td>\n",
       "      <td>0.545366</td>\n",
       "      <td>-0.157</td>\n",
       "      <td>-0.423</td>\n",
       "      <td>0.379</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>-1.303</td>\n",
       "      <td>0.352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>A</td>\n",
       "      <td>10</td>\n",
       "      <td>A6601</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>valid</td>\n",
       "      <td>EAAFATKDRL</td>\n",
       "      <td>1</td>\n",
       "      <td>2.524</td>\n",
       "      <td>0.223573</td>\n",
       "      <td>0.284</td>\n",
       "      <td>-0.666</td>\n",
       "      <td>-0.267</td>\n",
       "      <td>-0.435</td>\n",
       "      <td>-0.560</td>\n",
       "      <td>0.239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1537</th>\n",
       "      <td>A</td>\n",
       "      <td>10</td>\n",
       "      <td>A3401</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>QQMRLWTQAR</td>\n",
       "      <td>0</td>\n",
       "      <td>3.762</td>\n",
       "      <td>0.332159</td>\n",
       "      <td>0.400</td>\n",
       "      <td>-0.441</td>\n",
       "      <td>0.317</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.216</td>\n",
       "      <td>-0.310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4143</th>\n",
       "      <td>B</td>\n",
       "      <td>10</td>\n",
       "      <td>B1503</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>HKKQDPDVPF</td>\n",
       "      <td>1</td>\n",
       "      <td>3.172</td>\n",
       "      <td>0.041185</td>\n",
       "      <td>0.307</td>\n",
       "      <td>0.277</td>\n",
       "      <td>0.157</td>\n",
       "      <td>-0.445</td>\n",
       "      <td>-0.386</td>\n",
       "      <td>0.439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8907</th>\n",
       "      <td>A</td>\n",
       "      <td>10</td>\n",
       "      <td>A0205</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>QGTVSLHAPT</td>\n",
       "      <td>0</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.057878</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.063</td>\n",
       "      <td>-0.639</td>\n",
       "      <td>0.182</td>\n",
       "      <td>-0.261</td>\n",
       "      <td>-0.171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5744</th>\n",
       "      <td>A</td>\n",
       "      <td>10</td>\n",
       "      <td>A3601</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>DLLVLRCQAW</td>\n",
       "      <td>0</td>\n",
       "      <td>0.496</td>\n",
       "      <td>0.070091</td>\n",
       "      <td>-0.281</td>\n",
       "      <td>-0.467</td>\n",
       "      <td>0.012</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>-0.356</td>\n",
       "      <td>0.089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9719</th>\n",
       "      <td>C</td>\n",
       "      <td>10</td>\n",
       "      <td>C0602</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>valid</td>\n",
       "      <td>LWPGLAPPHK</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.471</td>\n",
       "      <td>0.299954</td>\n",
       "      <td>-0.447</td>\n",
       "      <td>0.355</td>\n",
       "      <td>-0.118</td>\n",
       "      <td>-0.636</td>\n",
       "      <td>-0.638</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2497</th>\n",
       "      <td>A</td>\n",
       "      <td>10</td>\n",
       "      <td>A3401</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>EGAGAGSGFR</td>\n",
       "      <td>1</td>\n",
       "      <td>1.477</td>\n",
       "      <td>0.280488</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.209</td>\n",
       "      <td>-0.982</td>\n",
       "      <td>-0.330</td>\n",
       "      <td>-0.238</td>\n",
       "      <td>-0.560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2093</th>\n",
       "      <td>B</td>\n",
       "      <td>10</td>\n",
       "      <td>B1801</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>LLLEPGSLYI</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.519</td>\n",
       "      <td>0.202920</td>\n",
       "      <td>-0.505</td>\n",
       "      <td>-0.063</td>\n",
       "      <td>-0.186</td>\n",
       "      <td>-0.120</td>\n",
       "      <td>-0.944</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5363</th>\n",
       "      <td>A</td>\n",
       "      <td>10</td>\n",
       "      <td>A1101</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>RSLDHPNVLK</td>\n",
       "      <td>1</td>\n",
       "      <td>3.001</td>\n",
       "      <td>0.188685</td>\n",
       "      <td>0.254</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.020</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>-0.542</td>\n",
       "      <td>0.295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3068</th>\n",
       "      <td>A</td>\n",
       "      <td>10</td>\n",
       "      <td>A2301</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>valid</td>\n",
       "      <td>KFMTHVASQF</td>\n",
       "      <td>1</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.528492</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>-0.427</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>0.086</td>\n",
       "      <td>-0.193</td>\n",
       "      <td>0.099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3433</th>\n",
       "      <td>B</td>\n",
       "      <td>10</td>\n",
       "      <td>B4601</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>VQFDGTNSAF</td>\n",
       "      <td>1</td>\n",
       "      <td>1.412</td>\n",
       "      <td>0.140639</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.106</td>\n",
       "      <td>-0.421</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>-0.243</td>\n",
       "      <td>0.181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10015</th>\n",
       "      <td>C</td>\n",
       "      <td>10</td>\n",
       "      <td>C0303</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>valid</td>\n",
       "      <td>FAFSPDGKFL</td>\n",
       "      <td>1</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.216423</td>\n",
       "      <td>-0.364</td>\n",
       "      <td>0.134</td>\n",
       "      <td>-0.150</td>\n",
       "      <td>-0.532</td>\n",
       "      <td>-0.772</td>\n",
       "      <td>0.418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6172</th>\n",
       "      <td>A</td>\n",
       "      <td>10</td>\n",
       "      <td>A6601</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>ENGLSLILFG</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.769</td>\n",
       "      <td>0.220722</td>\n",
       "      <td>-0.342</td>\n",
       "      <td>-0.064</td>\n",
       "      <td>-0.406</td>\n",
       "      <td>-0.132</td>\n",
       "      <td>-0.681</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7614</th>\n",
       "      <td>B</td>\n",
       "      <td>10</td>\n",
       "      <td>B2705</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>valid</td>\n",
       "      <td>ARFEQLISRR</td>\n",
       "      <td>1</td>\n",
       "      <td>4.588</td>\n",
       "      <td>0.578567</td>\n",
       "      <td>0.473</td>\n",
       "      <td>-0.399</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.295</td>\n",
       "      <td>-0.167</td>\n",
       "      <td>0.237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10625</th>\n",
       "      <td>C</td>\n",
       "      <td>10</td>\n",
       "      <td>C1203</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>AAAPQLLIVL</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.361</td>\n",
       "      <td>0.158247</td>\n",
       "      <td>-0.493</td>\n",
       "      <td>-0.768</td>\n",
       "      <td>-0.597</td>\n",
       "      <td>-0.088</td>\n",
       "      <td>-0.913</td>\n",
       "      <td>0.289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5502</th>\n",
       "      <td>A</td>\n",
       "      <td>10</td>\n",
       "      <td>A2902</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>valid</td>\n",
       "      <td>NGTYCAPNKV</td>\n",
       "      <td>0</td>\n",
       "      <td>1.347</td>\n",
       "      <td>0.310755</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.492</td>\n",
       "      <td>-0.410</td>\n",
       "      <td>0.168</td>\n",
       "      <td>-0.109</td>\n",
       "      <td>0.107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7491</th>\n",
       "      <td>B</td>\n",
       "      <td>10</td>\n",
       "      <td>B1501</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>SQIFIGPTYY</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.197</td>\n",
       "      <td>0.104148</td>\n",
       "      <td>-0.285</td>\n",
       "      <td>0.521</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>0.488</td>\n",
       "      <td>-0.230</td>\n",
       "      <td>0.045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8371</th>\n",
       "      <td>B</td>\n",
       "      <td>10</td>\n",
       "      <td>B5001</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>IEMVGNILRD</td>\n",
       "      <td>0</td>\n",
       "      <td>1.500</td>\n",
       "      <td>0.690088</td>\n",
       "      <td>0.073</td>\n",
       "      <td>-0.269</td>\n",
       "      <td>-0.164</td>\n",
       "      <td>0.279</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9491</th>\n",
       "      <td>B</td>\n",
       "      <td>10</td>\n",
       "      <td>B5703</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>VSWDEKGMTW</td>\n",
       "      <td>1</td>\n",
       "      <td>1.506</td>\n",
       "      <td>0.179872</td>\n",
       "      <td>0.030</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>0.072</td>\n",
       "      <td>-0.210</td>\n",
       "      <td>0.045</td>\n",
       "      <td>-0.959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5282</th>\n",
       "      <td>C</td>\n",
       "      <td>10</td>\n",
       "      <td>C0802</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>SEKTETGQEL</td>\n",
       "      <td>0</td>\n",
       "      <td>3.420</td>\n",
       "      <td>0.209220</td>\n",
       "      <td>0.673</td>\n",
       "      <td>-0.341</td>\n",
       "      <td>-0.281</td>\n",
       "      <td>-0.288</td>\n",
       "      <td>-0.200</td>\n",
       "      <td>-0.486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10011</th>\n",
       "      <td>A</td>\n",
       "      <td>10</td>\n",
       "      <td>A0301</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>HTRTPPIIHR</td>\n",
       "      <td>1</td>\n",
       "      <td>3.446</td>\n",
       "      <td>0.513634</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2445</th>\n",
       "      <td>C</td>\n",
       "      <td>10</td>\n",
       "      <td>C1203</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>SDESLIACKA</td>\n",
       "      <td>1</td>\n",
       "      <td>1.314</td>\n",
       "      <td>0.117606</td>\n",
       "      <td>0.106</td>\n",
       "      <td>-0.436</td>\n",
       "      <td>-0.576</td>\n",
       "      <td>-0.304</td>\n",
       "      <td>-0.310</td>\n",
       "      <td>0.065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7190</th>\n",
       "      <td>B</td>\n",
       "      <td>10</td>\n",
       "      <td>B3802</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>valid</td>\n",
       "      <td>NPGSAASGTE</td>\n",
       "      <td>0</td>\n",
       "      <td>1.732</td>\n",
       "      <td>0.085226</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.343</td>\n",
       "      <td>-1.033</td>\n",
       "      <td>-0.375</td>\n",
       "      <td>-0.211</td>\n",
       "      <td>-0.391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7807</th>\n",
       "      <td>A</td>\n",
       "      <td>10</td>\n",
       "      <td>A1102</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>GTMDMSITRL</td>\n",
       "      <td>1</td>\n",
       "      <td>1.670</td>\n",
       "      <td>0.359266</td>\n",
       "      <td>0.087</td>\n",
       "      <td>-0.098</td>\n",
       "      <td>-0.319</td>\n",
       "      <td>0.285</td>\n",
       "      <td>0.151</td>\n",
       "      <td>-0.419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5875</th>\n",
       "      <td>B</td>\n",
       "      <td>10</td>\n",
       "      <td>B3801</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>ALKLESCGVT</td>\n",
       "      <td>0</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.258548</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>-0.352</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>0.034</td>\n",
       "      <td>-0.483</td>\n",
       "      <td>-0.224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038</th>\n",
       "      <td>B</td>\n",
       "      <td>10</td>\n",
       "      <td>B1301</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>EEWQCLDTVQ</td>\n",
       "      <td>0</td>\n",
       "      <td>2.342</td>\n",
       "      <td>0.263429</td>\n",
       "      <td>0.186</td>\n",
       "      <td>-0.436</td>\n",
       "      <td>0.044</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>0.246</td>\n",
       "      <td>-0.174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4152</th>\n",
       "      <td>A</td>\n",
       "      <td>10</td>\n",
       "      <td>A2407</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>valid</td>\n",
       "      <td>IYIDASCLTW</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.535</td>\n",
       "      <td>0.029675</td>\n",
       "      <td>-0.423</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>-0.130</td>\n",
       "      <td>0.269</td>\n",
       "      <td>-0.054</td>\n",
       "      <td>-0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6097</th>\n",
       "      <td>B</td>\n",
       "      <td>10</td>\n",
       "      <td>B1301</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>HIMIMSLPSL</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.292</td>\n",
       "      <td>0.168846</td>\n",
       "      <td>-0.483</td>\n",
       "      <td>-0.307</td>\n",
       "      <td>-0.193</td>\n",
       "      <td>0.115</td>\n",
       "      <td>-0.130</td>\n",
       "      <td>-0.039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5057</th>\n",
       "      <td>A</td>\n",
       "      <td>10</td>\n",
       "      <td>A3303</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>EFINEKGVKR</td>\n",
       "      <td>1</td>\n",
       "      <td>3.340</td>\n",
       "      <td>0.252980</td>\n",
       "      <td>0.566</td>\n",
       "      <td>-0.244</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.081</td>\n",
       "      <td>-0.331</td>\n",
       "      <td>-0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1688</th>\n",
       "      <td>A</td>\n",
       "      <td>10</td>\n",
       "      <td>A6601</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>TTDLDFRDRD</td>\n",
       "      <td>0</td>\n",
       "      <td>6.196</td>\n",
       "      <td>0.077009</td>\n",
       "      <td>0.571</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.124</td>\n",
       "      <td>-0.176</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>0.454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>A</td>\n",
       "      <td>10</td>\n",
       "      <td>A0202</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>YLEKGKETLL</td>\n",
       "      <td>1</td>\n",
       "      <td>1.173</td>\n",
       "      <td>0.377312</td>\n",
       "      <td>0.235</td>\n",
       "      <td>-0.360</td>\n",
       "      <td>0.084</td>\n",
       "      <td>-0.262</td>\n",
       "      <td>-0.917</td>\n",
       "      <td>-0.258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10275</th>\n",
       "      <td>B</td>\n",
       "      <td>10</td>\n",
       "      <td>B5501</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>QYPCLWVNVS</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.089</td>\n",
       "      <td>0.221876</td>\n",
       "      <td>-0.350</td>\n",
       "      <td>0.282</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.333</td>\n",
       "      <td>-0.129</td>\n",
       "      <td>-0.085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>B</td>\n",
       "      <td>10</td>\n",
       "      <td>B1502</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>valid</td>\n",
       "      <td>SSCVPACHQR</td>\n",
       "      <td>0</td>\n",
       "      <td>2.351</td>\n",
       "      <td>0.232356</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.096</td>\n",
       "      <td>-0.462</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10775</th>\n",
       "      <td>B</td>\n",
       "      <td>10</td>\n",
       "      <td>B4901</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>FEREVGRQSV</td>\n",
       "      <td>1</td>\n",
       "      <td>4.040</td>\n",
       "      <td>0.515243</td>\n",
       "      <td>0.521</td>\n",
       "      <td>-0.235</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>0.324</td>\n",
       "      <td>-0.066</td>\n",
       "      <td>-0.211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6594</th>\n",
       "      <td>C</td>\n",
       "      <td>10</td>\n",
       "      <td>C0801</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>PNENKTPGVM</td>\n",
       "      <td>0</td>\n",
       "      <td>2.088</td>\n",
       "      <td>0.061269</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.419</td>\n",
       "      <td>-0.298</td>\n",
       "      <td>-0.178</td>\n",
       "      <td>-0.057</td>\n",
       "      <td>-0.110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10704</th>\n",
       "      <td>A</td>\n",
       "      <td>10</td>\n",
       "      <td>A2402</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>RIVILPSLDR</td>\n",
       "      <td>0</td>\n",
       "      <td>1.824</td>\n",
       "      <td>0.121226</td>\n",
       "      <td>0.008</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.531</td>\n",
       "      <td>-0.466</td>\n",
       "      <td>0.275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1181</th>\n",
       "      <td>A</td>\n",
       "      <td>10</td>\n",
       "      <td>A2501</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>EIYTRDGNSY</td>\n",
       "      <td>1</td>\n",
       "      <td>3.748</td>\n",
       "      <td>0.395395</td>\n",
       "      <td>0.366</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.259</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4450</th>\n",
       "      <td>B</td>\n",
       "      <td>10</td>\n",
       "      <td>B5801</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>KSVTADTEMW</td>\n",
       "      <td>1</td>\n",
       "      <td>1.909</td>\n",
       "      <td>0.272435</td>\n",
       "      <td>0.239</td>\n",
       "      <td>-0.328</td>\n",
       "      <td>-0.179</td>\n",
       "      <td>-0.091</td>\n",
       "      <td>-0.058</td>\n",
       "      <td>-0.598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1083</th>\n",
       "      <td>A</td>\n",
       "      <td>10</td>\n",
       "      <td>A3301</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>valid</td>\n",
       "      <td>REFRTWTELN</td>\n",
       "      <td>0</td>\n",
       "      <td>4.501</td>\n",
       "      <td>0.590244</td>\n",
       "      <td>0.405</td>\n",
       "      <td>-0.175</td>\n",
       "      <td>0.453</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.022</td>\n",
       "      <td>-0.040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9917</th>\n",
       "      <td>A</td>\n",
       "      <td>10</td>\n",
       "      <td>A2902</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>valid</td>\n",
       "      <td>IFLDSKGLEY</td>\n",
       "      <td>1</td>\n",
       "      <td>0.594</td>\n",
       "      <td>0.148979</td>\n",
       "      <td>-0.102</td>\n",
       "      <td>-0.058</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.174</td>\n",
       "      <td>-0.717</td>\n",
       "      <td>0.052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2066</th>\n",
       "      <td>A</td>\n",
       "      <td>10</td>\n",
       "      <td>A7401</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>valid</td>\n",
       "      <td>RVSPQPMISR</td>\n",
       "      <td>1</td>\n",
       "      <td>3.087</td>\n",
       "      <td>0.069572</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.284</td>\n",
       "      <td>-0.073</td>\n",
       "      <td>0.424</td>\n",
       "      <td>0.049</td>\n",
       "      <td>-0.110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3154</th>\n",
       "      <td>C</td>\n",
       "      <td>10</td>\n",
       "      <td>C1402</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>TGHEDKVVHA</td>\n",
       "      <td>0</td>\n",
       "      <td>2.214</td>\n",
       "      <td>0.199440</td>\n",
       "      <td>0.364</td>\n",
       "      <td>-0.335</td>\n",
       "      <td>-0.392</td>\n",
       "      <td>0.011</td>\n",
       "      <td>-0.135</td>\n",
       "      <td>-0.074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1386</th>\n",
       "      <td>A</td>\n",
       "      <td>10</td>\n",
       "      <td>A0206</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>PTQEGKLFQL</td>\n",
       "      <td>0</td>\n",
       "      <td>1.225</td>\n",
       "      <td>0.242120</td>\n",
       "      <td>0.116</td>\n",
       "      <td>-0.124</td>\n",
       "      <td>-0.052</td>\n",
       "      <td>-0.271</td>\n",
       "      <td>-0.530</td>\n",
       "      <td>0.024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4104</th>\n",
       "      <td>A</td>\n",
       "      <td>10</td>\n",
       "      <td>A3601</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>HLDEAQRLLY</td>\n",
       "      <td>1</td>\n",
       "      <td>2.422</td>\n",
       "      <td>0.570174</td>\n",
       "      <td>0.110</td>\n",
       "      <td>-0.483</td>\n",
       "      <td>0.181</td>\n",
       "      <td>-0.292</td>\n",
       "      <td>-0.500</td>\n",
       "      <td>0.325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3030</th>\n",
       "      <td>A</td>\n",
       "      <td>10</td>\n",
       "      <td>A3401</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>MVLQVSAAPR</td>\n",
       "      <td>1</td>\n",
       "      <td>0.489</td>\n",
       "      <td>0.314174</td>\n",
       "      <td>-0.053</td>\n",
       "      <td>-0.442</td>\n",
       "      <td>-0.448</td>\n",
       "      <td>0.193</td>\n",
       "      <td>-0.354</td>\n",
       "      <td>-0.135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3488</th>\n",
       "      <td>B</td>\n",
       "      <td>10</td>\n",
       "      <td>B2705</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>GRVGLLGNTY</td>\n",
       "      <td>1</td>\n",
       "      <td>0.757</td>\n",
       "      <td>0.238006</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>0.456</td>\n",
       "      <td>-0.461</td>\n",
       "      <td>0.413</td>\n",
       "      <td>-0.488</td>\n",
       "      <td>-0.382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4675</th>\n",
       "      <td>A</td>\n",
       "      <td>10</td>\n",
       "      <td>A6801</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>ISFSGLPSGR</td>\n",
       "      <td>1</td>\n",
       "      <td>1.042</td>\n",
       "      <td>0.236133</td>\n",
       "      <td>-0.124</td>\n",
       "      <td>0.565</td>\n",
       "      <td>-0.540</td>\n",
       "      <td>0.143</td>\n",
       "      <td>-0.433</td>\n",
       "      <td>-0.244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4848</th>\n",
       "      <td>B</td>\n",
       "      <td>10</td>\n",
       "      <td>B5701</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>GSYVAPKAVW</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.588</td>\n",
       "      <td>0.237493</td>\n",
       "      <td>-0.226</td>\n",
       "      <td>0.107</td>\n",
       "      <td>-0.373</td>\n",
       "      <td>0.077</td>\n",
       "      <td>-0.590</td>\n",
       "      <td>-0.522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8664</th>\n",
       "      <td>A</td>\n",
       "      <td>10</td>\n",
       "      <td>A0206</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>FCLTCLMTFA</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.738</td>\n",
       "      <td>0.192982</td>\n",
       "      <td>-0.690</td>\n",
       "      <td>-0.470</td>\n",
       "      <td>-0.271</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>B</td>\n",
       "      <td>10</td>\n",
       "      <td>B1501</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>QQNKELENKY</td>\n",
       "      <td>1</td>\n",
       "      <td>4.430</td>\n",
       "      <td>0.300399</td>\n",
       "      <td>0.790</td>\n",
       "      <td>-0.190</td>\n",
       "      <td>0.384</td>\n",
       "      <td>-0.322</td>\n",
       "      <td>-0.325</td>\n",
       "      <td>0.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2055</th>\n",
       "      <td>B</td>\n",
       "      <td>10</td>\n",
       "      <td>B4001</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>SEAPPSKMVL</td>\n",
       "      <td>1</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.106895</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>-0.079</td>\n",
       "      <td>-0.401</td>\n",
       "      <td>-0.341</td>\n",
       "      <td>-0.510</td>\n",
       "      <td>-0.236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10386</th>\n",
       "      <td>A</td>\n",
       "      <td>10</td>\n",
       "      <td>A6801</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>valid</td>\n",
       "      <td>EVPSEIEVPR</td>\n",
       "      <td>1</td>\n",
       "      <td>2.575</td>\n",
       "      <td>0.230521</td>\n",
       "      <td>0.273</td>\n",
       "      <td>-0.141</td>\n",
       "      <td>-0.148</td>\n",
       "      <td>0.027</td>\n",
       "      <td>-0.126</td>\n",
       "      <td>-0.057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4328</th>\n",
       "      <td>B</td>\n",
       "      <td>10</td>\n",
       "      <td>B1501</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>valid</td>\n",
       "      <td>KLDPHNHVLY</td>\n",
       "      <td>1</td>\n",
       "      <td>1.649</td>\n",
       "      <td>0.164483</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.201</td>\n",
       "      <td>-0.128</td>\n",
       "      <td>-0.512</td>\n",
       "      <td>0.477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8396</th>\n",
       "      <td>B</td>\n",
       "      <td>10</td>\n",
       "      <td>B5601</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>DRDPPKSSLA</td>\n",
       "      <td>0</td>\n",
       "      <td>3.798</td>\n",
       "      <td>0.224325</td>\n",
       "      <td>0.316</td>\n",
       "      <td>0.418</td>\n",
       "      <td>-0.284</td>\n",
       "      <td>-0.521</td>\n",
       "      <td>-0.545</td>\n",
       "      <td>0.147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1804</th>\n",
       "      <td>A</td>\n",
       "      <td>10</td>\n",
       "      <td>A7401</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>HWLELLATTY</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.215</td>\n",
       "      <td>0.314779</td>\n",
       "      <td>-0.299</td>\n",
       "      <td>-0.434</td>\n",
       "      <td>0.122</td>\n",
       "      <td>-0.108</td>\n",
       "      <td>-0.521</td>\n",
       "      <td>-0.113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>C</td>\n",
       "      <td>10</td>\n",
       "      <td>C1203</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>FVVDHVIKIT</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.344</td>\n",
       "      <td>0.427754</td>\n",
       "      <td>-0.075</td>\n",
       "      <td>-0.380</td>\n",
       "      <td>-0.105</td>\n",
       "      <td>0.846</td>\n",
       "      <td>-0.343</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3937</th>\n",
       "      <td>C</td>\n",
       "      <td>10</td>\n",
       "      <td>C0304</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>LVHPNPPSVL</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.322</td>\n",
       "      <td>0.176092</td>\n",
       "      <td>-0.374</td>\n",
       "      <td>0.416</td>\n",
       "      <td>-0.304</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>-0.612</td>\n",
       "      <td>0.346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10427</th>\n",
       "      <td>C</td>\n",
       "      <td>10</td>\n",
       "      <td>C1402</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>NFYGDLRKAL</td>\n",
       "      <td>1</td>\n",
       "      <td>2.040</td>\n",
       "      <td>0.543770</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.063</td>\n",
       "      <td>-0.180</td>\n",
       "      <td>-0.712</td>\n",
       "      <td>0.272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9860</th>\n",
       "      <td>A</td>\n",
       "      <td>10</td>\n",
       "      <td>A2301</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>VFFKELIQEF</td>\n",
       "      <td>1</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.521994</td>\n",
       "      <td>-0.142</td>\n",
       "      <td>-0.685</td>\n",
       "      <td>0.351</td>\n",
       "      <td>-0.087</td>\n",
       "      <td>-0.549</td>\n",
       "      <td>0.457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3114</th>\n",
       "      <td>G</td>\n",
       "      <td>10</td>\n",
       "      <td>G0104</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>valid</td>\n",
       "      <td>LTQRSYYPLY</td>\n",
       "      <td>0</td>\n",
       "      <td>1.701</td>\n",
       "      <td>0.326617</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>0.494</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0.358</td>\n",
       "      <td>-0.576</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7632</th>\n",
       "      <td>A</td>\n",
       "      <td>10</td>\n",
       "      <td>A0205</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>YSKYYKTIDD</td>\n",
       "      <td>1</td>\n",
       "      <td>3.001</td>\n",
       "      <td>0.561346</td>\n",
       "      <td>0.362</td>\n",
       "      <td>0.496</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.194</td>\n",
       "      <td>-0.517</td>\n",
       "      <td>-0.046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>A</td>\n",
       "      <td>10</td>\n",
       "      <td>A0206</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>valid</td>\n",
       "      <td>VVIPGKVEEV</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.285</td>\n",
       "      <td>0.202720</td>\n",
       "      <td>0.076</td>\n",
       "      <td>-0.341</td>\n",
       "      <td>-0.409</td>\n",
       "      <td>0.512</td>\n",
       "      <td>-0.459</td>\n",
       "      <td>-0.328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9544</th>\n",
       "      <td>A</td>\n",
       "      <td>10</td>\n",
       "      <td>A0101</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>NYDFGSSTET</td>\n",
       "      <td>0</td>\n",
       "      <td>3.033</td>\n",
       "      <td>0.136638</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.504</td>\n",
       "      <td>-0.316</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>-0.112</td>\n",
       "      <td>-0.155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10168</th>\n",
       "      <td>B</td>\n",
       "      <td>10</td>\n",
       "      <td>B5301</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>GSVFLAISQA</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.908</td>\n",
       "      <td>0.274350</td>\n",
       "      <td>-0.246</td>\n",
       "      <td>-0.323</td>\n",
       "      <td>-0.711</td>\n",
       "      <td>0.145</td>\n",
       "      <td>-0.558</td>\n",
       "      <td>-0.085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5829</th>\n",
       "      <td>C</td>\n",
       "      <td>10</td>\n",
       "      <td>C0801</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>KNSISLKEQE</td>\n",
       "      <td>0</td>\n",
       "      <td>3.386</td>\n",
       "      <td>0.101929</td>\n",
       "      <td>0.662</td>\n",
       "      <td>-0.306</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>-0.186</td>\n",
       "      <td>-0.436</td>\n",
       "      <td>-0.142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2171</th>\n",
       "      <td>B</td>\n",
       "      <td>10</td>\n",
       "      <td>B1501</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>KIIETTGVHF</td>\n",
       "      <td>1</td>\n",
       "      <td>0.436</td>\n",
       "      <td>0.390140</td>\n",
       "      <td>0.088</td>\n",
       "      <td>-0.263</td>\n",
       "      <td>-0.188</td>\n",
       "      <td>0.533</td>\n",
       "      <td>-0.146</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10069</th>\n",
       "      <td>A</td>\n",
       "      <td>10</td>\n",
       "      <td>A2601</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>valid</td>\n",
       "      <td>NMHDLHRLLL</td>\n",
       "      <td>0</td>\n",
       "      <td>1.757</td>\n",
       "      <td>0.508158</td>\n",
       "      <td>-0.108</td>\n",
       "      <td>-0.444</td>\n",
       "      <td>0.220</td>\n",
       "      <td>-0.227</td>\n",
       "      <td>-0.368</td>\n",
       "      <td>0.488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5973</th>\n",
       "      <td>A</td>\n",
       "      <td>10</td>\n",
       "      <td>A2601</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>TVVGGLGVAV</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.314</td>\n",
       "      <td>0.198317</td>\n",
       "      <td>-0.282</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>-1.109</td>\n",
       "      <td>0.747</td>\n",
       "      <td>-0.619</td>\n",
       "      <td>-0.672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7595</th>\n",
       "      <td>A</td>\n",
       "      <td>10</td>\n",
       "      <td>A2407</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>HALNSRLFIG</td>\n",
       "      <td>0</td>\n",
       "      <td>0.913</td>\n",
       "      <td>0.082458</td>\n",
       "      <td>-0.145</td>\n",
       "      <td>-0.136</td>\n",
       "      <td>-0.217</td>\n",
       "      <td>0.088</td>\n",
       "      <td>-0.436</td>\n",
       "      <td>0.331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4340</th>\n",
       "      <td>A</td>\n",
       "      <td>10</td>\n",
       "      <td>A0206</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>valid</td>\n",
       "      <td>GLIGVGLINV</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.394</td>\n",
       "      <td>0.124926</td>\n",
       "      <td>-0.421</td>\n",
       "      <td>0.050</td>\n",
       "      <td>-0.769</td>\n",
       "      <td>0.637</td>\n",
       "      <td>-0.562</td>\n",
       "      <td>-0.258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3956</th>\n",
       "      <td>A</td>\n",
       "      <td>10</td>\n",
       "      <td>A2402</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>AYADLVKQAW</td>\n",
       "      <td>1</td>\n",
       "      <td>0.323</td>\n",
       "      <td>0.456646</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>-0.501</td>\n",
       "      <td>-0.130</td>\n",
       "      <td>-0.277</td>\n",
       "      <td>-0.619</td>\n",
       "      <td>-0.148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10436</th>\n",
       "      <td>B</td>\n",
       "      <td>10</td>\n",
       "      <td>B5701</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>EPGEVVTYQW</td>\n",
       "      <td>0</td>\n",
       "      <td>1.052</td>\n",
       "      <td>0.252288</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.061</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>0.084</td>\n",
       "      <td>-0.069</td>\n",
       "      <td>-0.548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10546</th>\n",
       "      <td>B</td>\n",
       "      <td>10</td>\n",
       "      <td>B4901</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>LAEYRETGAL</td>\n",
       "      <td>0</td>\n",
       "      <td>1.685</td>\n",
       "      <td>0.097619</td>\n",
       "      <td>0.138</td>\n",
       "      <td>-0.478</td>\n",
       "      <td>-0.287</td>\n",
       "      <td>-0.249</td>\n",
       "      <td>-0.498</td>\n",
       "      <td>-0.142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3398</th>\n",
       "      <td>B</td>\n",
       "      <td>10</td>\n",
       "      <td>B5502</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>SIANLWLWMN</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.690</td>\n",
       "      <td>0.246100</td>\n",
       "      <td>-0.507</td>\n",
       "      <td>-0.208</td>\n",
       "      <td>0.133</td>\n",
       "      <td>-0.160</td>\n",
       "      <td>-0.188</td>\n",
       "      <td>-0.287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>A</td>\n",
       "      <td>10</td>\n",
       "      <td>A3601</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>LIIKLLYEKG</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.749</td>\n",
       "      <td>0.349351</td>\n",
       "      <td>-0.099</td>\n",
       "      <td>-0.387</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.136</td>\n",
       "      <td>-0.972</td>\n",
       "      <td>-0.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9025</th>\n",
       "      <td>B</td>\n",
       "      <td>10</td>\n",
       "      <td>B1302</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>valid</td>\n",
       "      <td>AAEQVSPAGA</td>\n",
       "      <td>0</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.290840</td>\n",
       "      <td>0.030</td>\n",
       "      <td>-0.457</td>\n",
       "      <td>-1.033</td>\n",
       "      <td>-0.460</td>\n",
       "      <td>-0.393</td>\n",
       "      <td>-0.189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ABCG  length allele  seed  fold    set         seq  label  boman  \\\n",
       "9057     B      10  B1503   123     1  train  AKCQQLQQEY      1  2.665   \n",
       "7710     B      10  B1503   123     1   test  GDWMIEFYAP      0  0.034   \n",
       "4597     B      10  B1301   123     0  train  RLEKNVKEVL      1  2.836   \n",
       "1893     A      10  A7401   123     0  train  RVADVYRYCR      1  4.259   \n",
       "6450     B      10  B1510   123     1  train  FSALSSAYWS      0 -0.011   \n",
       "3062     B      10  B5801   123     0  train  HVAPVTSVEW      1  0.118   \n",
       "1133     A      10  A3601   123     0  train  VGRKVRRPAG      0  3.854   \n",
       "5993     B      10  B3801   123     1  train  HHVSPHETYF      1  1.988   \n",
       "7321     A      10  A0205   123     1  train  DREPGGVTQQ      0  3.818   \n",
       "8399     C      10  C0202   123     1  train  KLPEFTKSEY      1  2.293   \n",
       "810      A      10  A6801   123     0  train  NIISGSGRPR      1  3.156   \n",
       "4670     A      10  A6601   123     0  train  DTSNIITVRV      1  2.090   \n",
       "6642     B      10  B0702   123     1  train  CEVFRQRFRQ      0  5.137   \n",
       "9225     A      10  A2402   123     1  train  RYAKIVEIPF      1  0.875   \n",
       "4671     A      10  A3201   123     0  valid  WEGIAQGHVM      0 -0.032   \n",
       "487      C      10  C1202   123     0  train  KLPVDQYRKQ      0  3.700   \n",
       "7770     A      10  A3002   123     1  train  KYMPDLTPQY      1  1.539   \n",
       "6523     B      10  B1503   123     1  train  HQAACLIQAY      1 -0.067   \n",
       "279      B      10  B4006   123     0  train  REIFDKARQA      1  4.494   \n",
       "8348     B      10  B1301   123     1  train  KLLKRLFLFS      0  0.378   \n",
       "2997     A      10  A6601   123     0  valid  EAAFATKDRL      1  2.524   \n",
       "1537     A      10  A3401   123     0  train  QQMRLWTQAR      0  3.762   \n",
       "4143     B      10  B1503   123     0  train  HKKQDPDVPF      1  3.172   \n",
       "8907     A      10  A0205   123     1   test  QGTVSLHAPT      0  0.703   \n",
       "5744     A      10  A3601   123     1  train  DLLVLRCQAW      0  0.496   \n",
       "9719     C      10  C0602   123     1  valid  LWPGLAPPHK      0 -0.471   \n",
       "2497     A      10  A3401   123     0  train  EGAGAGSGFR      1  1.477   \n",
       "2093     B      10  B1801   123     0   test  LLLEPGSLYI      0 -1.519   \n",
       "5363     A      10  A1101   123     0   test  RSLDHPNVLK      1  3.001   \n",
       "3068     A      10  A2301   123     0  valid  KFMTHVASQF      1  0.756   \n",
       "3433     B      10  B4601   123     0  train  VQFDGTNSAF      1  1.412   \n",
       "10015    C      10  C0303   123     1  valid  FAFSPDGKFL      1  0.106   \n",
       "6172     A      10  A6601   123     1   test  ENGLSLILFG      0 -0.769   \n",
       "7614     B      10  B2705   123     1  valid  ARFEQLISRR      1  4.588   \n",
       "10625    C      10  C1203   123     1  train  AAAPQLLIVL      1 -2.361   \n",
       "5502     A      10  A2902   123     1  valid  NGTYCAPNKV      0  1.347   \n",
       "7491     B      10  B1501   123     1  train  SQIFIGPTYY      1 -0.197   \n",
       "8371     B      10  B5001   123     1  train  IEMVGNILRD      0  1.500   \n",
       "9491     B      10  B5703   123     1  train  VSWDEKGMTW      1  1.506   \n",
       "5282     C      10  C0802   123     0  train  SEKTETGQEL      0  3.420   \n",
       "10011    A      10  A0301   123     1  train  HTRTPPIIHR      1  3.446   \n",
       "2445     C      10  C1203   123     0  train  SDESLIACKA      1  1.314   \n",
       "7190     B      10  B3802   123     1  valid  NPGSAASGTE      0  1.732   \n",
       "7807     A      10  A1102   123     1  train  GTMDMSITRL      1  1.670   \n",
       "5875     B      10  B3801   123     1  train  ALKLESCGVT      0  0.042   \n",
       "1038     B      10  B1301   123     0  train  EEWQCLDTVQ      0  2.342   \n",
       "4152     A      10  A2407   123     0  valid  IYIDASCLTW      1 -0.535   \n",
       "6097     B      10  B1301   123     1  train  HIMIMSLPSL      0 -1.292   \n",
       "5057     A      10  A3303   123     0  train  EFINEKGVKR      1  3.340   \n",
       "1688     A      10  A6601   123     0   test  TTDLDFRDRD      0  6.196   \n",
       "63       A      10  A0202   123     0  train  YLEKGKETLL      1  1.173   \n",
       "10275    B      10  B5501   123     1  train  QYPCLWVNVS      0 -0.089   \n",
       "565      B      10  B1502   123     0  valid  SSCVPACHQR      0  2.351   \n",
       "10775    B      10  B4901   123     1  train  FEREVGRQSV      1  4.040   \n",
       "6594     C      10  C0801   123     1  train  PNENKTPGVM      0  2.088   \n",
       "10704    A      10  A2402   123     1  train  RIVILPSLDR      0  1.824   \n",
       "1181     A      10  A2501   123     0  train  EIYTRDGNSY      1  3.748   \n",
       "4450     B      10  B5801   123     0  train  KSVTADTEMW      1  1.909   \n",
       "1083     A      10  A3301   123     0  valid  REFRTWTELN      0  4.501   \n",
       "9917     A      10  A2902   123     1  valid  IFLDSKGLEY      1  0.594   \n",
       "2066     A      10  A7401   123     0  valid  RVSPQPMISR      1  3.087   \n",
       "3154     C      10  C1402   123     0   test  TGHEDKVVHA      0  2.214   \n",
       "1386     A      10  A0206   123     0  train  PTQEGKLFQL      0  1.225   \n",
       "4104     A      10  A3601   123     0  train  HLDEAQRLLY      1  2.422   \n",
       "3030     A      10  A3401   123     0  train  MVLQVSAAPR      1  0.489   \n",
       "3488     B      10  B2705   123     0  train  GRVGLLGNTY      1  0.757   \n",
       "4675     A      10  A6801   123     0  train  ISFSGLPSGR      1  1.042   \n",
       "4848     B      10  B5701   123     0  train  GSYVAPKAVW      1 -0.588   \n",
       "8664     A      10  A0206   123     1  train  FCLTCLMTFA      0 -1.738   \n",
       "601      B      10  B1501   123     0  train  QQNKELENKY      1  4.430   \n",
       "2055     B      10  B4001   123     0  train  SEAPPSKMVL      1  0.604   \n",
       "10386    A      10  A6801   123     1  valid  EVPSEIEVPR      1  2.575   \n",
       "4328     B      10  B1501   123     0  valid  KLDPHNHVLY      1  1.649   \n",
       "8396     B      10  B5601   123     1  train  DRDPPKSSLA      0  3.798   \n",
       "1804     A      10  A7401   123     0   test  HWLELLATTY      0 -0.215   \n",
       "298      C      10  C1203   123     0  train  FVVDHVIKIT      1 -0.344   \n",
       "3937     C      10  C0304   123     0  train  LVHPNPPSVL      1 -0.322   \n",
       "10427    C      10  C1402   123     1  train  NFYGDLRKAL      1  2.040   \n",
       "9860     A      10  A2301   123     1  train  VFFKELIQEF      1  0.189   \n",
       "3114     G      10  G0104   123     0  valid  LTQRSYYPLY      0  1.701   \n",
       "7632     A      10  A0205   123     1  train  YSKYYKTIDD      1  3.001   \n",
       "475      A      10  A0206   123     0  valid  VVIPGKVEEV      1 -0.285   \n",
       "9544     A      10  A0101   123     1  train  NYDFGSSTET      0  3.033   \n",
       "10168    B      10  B5301   123     1  train  GSVFLAISQA      0 -0.908   \n",
       "5829     C      10  C0801   123     1  train  KNSISLKEQE      0  3.386   \n",
       "2171     B      10  B1501   123     0  train  KIIETTGVHF      1  0.436   \n",
       "10069    A      10  A2601   123     1  valid  NMHDLHRLLL      0  1.757   \n",
       "5973     A      10  A2601   123     1  train  TVVGGLGVAV      0 -2.314   \n",
       "7595     A      10  A2407   123     1  train  HALNSRLFIG      0  0.913   \n",
       "4340     A      10  A0206   123     0  valid  GLIGVGLINV      1 -2.394   \n",
       "3956     A      10  A2402   123     0  train  AYADLVKQAW      1  0.323   \n",
       "10436    B      10  B5701   123     1  train  EPGEVVTYQW      0  1.052   \n",
       "10546    B      10  B4901   123     1  train  LAEYRETGAL      0  1.685   \n",
       "3398     B      10  B5502   123     0  train  SIANLWLWMN      0 -0.690   \n",
       "786      A      10  A3601   123     0   test  LIIKLLYEKG      0 -0.749   \n",
       "9025     B      10  B1302   123     1  valid  AAEQVSPAGA      0  0.353   \n",
       "\n",
       "        hmoment  hydrophobicity  helixbend  sidechain   xstr  partspec    pkc  \n",
       "9057   0.208262           0.429     -0.477      0.089 -0.152     0.004  0.079  \n",
       "7710   0.232703          -0.426      0.043      0.059 -0.445    -0.016 -0.155  \n",
       "4597   0.737044           0.542     -0.578      0.180  0.117    -0.733 -0.035  \n",
       "1893   0.497503           0.318      0.108      0.257  0.769     0.018  0.177  \n",
       "6450   0.197359          -0.352      0.055     -0.310 -0.182    -0.625 -0.365  \n",
       "3062   0.047392          -0.129     -0.221     -0.310  0.276    -0.190 -0.348  \n",
       "1133   0.779978           0.517      0.226     -0.271  0.538    -0.331 -0.308  \n",
       "5993   0.186321          -0.008      0.088      0.139  0.025     0.046  0.345  \n",
       "7321   0.350469           0.521      0.291     -0.394 -0.004     0.092 -0.302  \n",
       "8399   0.317802           0.295     -0.032      0.237 -0.326    -0.665 -0.034  \n",
       "810    0.266899           0.278      0.672     -0.426  0.491    -0.018 -0.164  \n",
       "4670   0.163090           0.283      0.033     -0.324  0.991    -0.059  0.040  \n",
       "6642   0.523024           0.467     -0.277      0.484  0.441     0.294  0.437  \n",
       "9225   0.451965          -0.021     -0.210      0.171  0.347    -0.423  0.287  \n",
       "4671   0.190568          -0.151     -0.354     -0.323 -0.056     0.231 -0.573  \n",
       "487    0.372992           0.547      0.084      0.361  0.092    -0.544  0.065  \n",
       "7770   0.393966          -0.021      0.447      0.262 -0.189    -0.346  0.025  \n",
       "6523   0.293592          -0.181     -0.630     -0.358 -0.025    -0.044  0.389  \n",
       "279    0.745221           0.578     -0.530      0.105 -0.112    -0.190  0.315  \n",
       "8348   0.545366          -0.157     -0.423      0.379 -0.061    -1.303  0.352  \n",
       "2997   0.223573           0.284     -0.666     -0.267 -0.435    -0.560  0.239  \n",
       "1537   0.332159           0.400     -0.441      0.317  0.181     0.216 -0.310  \n",
       "4143   0.041185           0.307      0.277      0.157 -0.445    -0.386  0.439  \n",
       "8907   0.057878           0.038      0.063     -0.639  0.182    -0.261 -0.171  \n",
       "5744   0.070091          -0.281     -0.467      0.012 -0.006    -0.356  0.089  \n",
       "9719   0.299954          -0.447      0.355     -0.118 -0.636    -0.638  0.002  \n",
       "2497   0.280488           0.085      0.209     -0.982 -0.330    -0.238 -0.560  \n",
       "2093   0.202920          -0.505     -0.063     -0.186 -0.120    -0.944  0.017  \n",
       "5363   0.188685           0.254      0.124      0.020 -0.027    -0.542  0.295  \n",
       "3068   0.528492          -0.013     -0.427     -0.044  0.086    -0.193  0.099  \n",
       "3433   0.140639           0.008      0.106     -0.421 -0.014    -0.243  0.181  \n",
       "10015  0.216423          -0.364      0.134     -0.150 -0.532    -0.772  0.418  \n",
       "6172   0.220722          -0.342     -0.064     -0.406 -0.132    -0.681  0.018  \n",
       "7614   0.578567           0.473     -0.399      0.231  0.295    -0.167  0.237  \n",
       "10625  0.158247          -0.493     -0.768     -0.597 -0.088    -0.913  0.289  \n",
       "5502   0.310755           0.076      0.492     -0.410  0.168    -0.109  0.107  \n",
       "7491   0.104148          -0.285      0.521     -0.021  0.488    -0.230  0.045  \n",
       "8371   0.690088           0.073     -0.269     -0.164  0.279    -0.001  0.012  \n",
       "9491   0.179872           0.030     -0.022      0.072 -0.210     0.045 -0.959  \n",
       "5282   0.209220           0.673     -0.341     -0.281 -0.288    -0.200 -0.486  \n",
       "10011  0.513634           0.252      0.280      0.120  0.588     0.252  0.440  \n",
       "2445   0.117606           0.106     -0.436     -0.576 -0.304    -0.310  0.065  \n",
       "7190   0.085226           0.184      0.343     -1.033 -0.375    -0.211 -0.391  \n",
       "7807   0.359266           0.087     -0.098     -0.319  0.285     0.151 -0.419  \n",
       "5875   0.258548          -0.016     -0.352     -0.600  0.034    -0.483 -0.224  \n",
       "1038   0.263429           0.186     -0.436      0.044 -0.192     0.246 -0.174  \n",
       "4152   0.029675          -0.423     -0.061     -0.130  0.269    -0.054 -0.001  \n",
       "6097   0.168846          -0.483     -0.307     -0.193  0.115    -0.130 -0.039  \n",
       "5057   0.252980           0.566     -0.244      0.137  0.081    -0.331 -0.008  \n",
       "1688   0.077009           0.571      0.203      0.124 -0.176    -0.092  0.454  \n",
       "63     0.377312           0.235     -0.360      0.084 -0.262    -0.917 -0.258  \n",
       "10275  0.221876          -0.350      0.282      0.003  0.333    -0.129 -0.085  \n",
       "565    0.232356           0.057      0.096     -0.462  0.230     0.398  0.214  \n",
       "10775  0.515243           0.521     -0.235     -0.032  0.324    -0.066 -0.211  \n",
       "6594   0.061269           0.233      0.419     -0.298 -0.178    -0.057 -0.110  \n",
       "10704  0.121226           0.008     -0.039     -0.012  0.531    -0.466  0.275  \n",
       "1181   0.395395           0.366      0.505      0.023  0.259    -0.028 -0.089  \n",
       "4450   0.272435           0.239     -0.328     -0.179 -0.091    -0.058 -0.598  \n",
       "1083   0.590244           0.405     -0.175      0.453  0.050     0.022 -0.040  \n",
       "9917   0.148979          -0.102     -0.058      0.005 -0.174    -0.717  0.052  \n",
       "2066   0.069572           0.228      0.284     -0.073  0.424     0.049 -0.110  \n",
       "3154   0.199440           0.364     -0.335     -0.392  0.011    -0.135 -0.074  \n",
       "1386   0.242120           0.116     -0.124     -0.052 -0.271    -0.530  0.024  \n",
       "4104   0.570174           0.110     -0.483      0.181 -0.292    -0.500  0.325  \n",
       "3030   0.314174          -0.053     -0.442     -0.448  0.193    -0.354 -0.135  \n",
       "3488   0.238006          -0.033      0.456     -0.461  0.413    -0.488 -0.382  \n",
       "4675   0.236133          -0.124      0.565     -0.540  0.143    -0.433 -0.244  \n",
       "4848   0.237493          -0.226      0.107     -0.373  0.077    -0.590 -0.522  \n",
       "8664   0.192982          -0.690     -0.470     -0.271  0.073     0.026  0.440  \n",
       "601    0.300399           0.790     -0.190      0.384 -0.322    -0.325  0.088  \n",
       "2055   0.106895          -0.029     -0.079     -0.401 -0.341    -0.510 -0.236  \n",
       "10386  0.230521           0.273     -0.141     -0.148  0.027    -0.126 -0.057  \n",
       "4328   0.164483          -0.003      0.118      0.201 -0.128    -0.512  0.477  \n",
       "8396   0.224325           0.316      0.418     -0.284 -0.521    -0.545  0.147  \n",
       "1804   0.314779          -0.299     -0.434      0.122 -0.108    -0.521 -0.113  \n",
       "298    0.427754          -0.075     -0.380     -0.105  0.846    -0.343  0.250  \n",
       "3937   0.176092          -0.374      0.416     -0.304 -0.009    -0.612  0.346  \n",
       "10427  0.543770           0.057      0.059      0.063 -0.180    -0.712  0.272  \n",
       "9860   0.521994          -0.142     -0.685      0.351 -0.087    -0.549  0.457  \n",
       "3114   0.326617          -0.061      0.494      0.384  0.358    -0.576  0.016  \n",
       "7632   0.561346           0.362      0.496      0.370  0.194    -0.517 -0.046  \n",
       "475    0.202720           0.076     -0.341     -0.409  0.512    -0.459 -0.328  \n",
       "9544   0.136638           0.274      0.504     -0.316 -0.036    -0.112 -0.155  \n",
       "10168  0.274350          -0.246     -0.323     -0.711  0.145    -0.558 -0.085  \n",
       "5829   0.101929           0.662     -0.306     -0.013 -0.186    -0.436 -0.142  \n",
       "2171   0.390140           0.088     -0.263     -0.188  0.533    -0.146  0.009  \n",
       "10069  0.508158          -0.108     -0.444      0.220 -0.227    -0.368  0.488  \n",
       "5973   0.198317          -0.282     -0.092     -1.109  0.747    -0.619 -0.672  \n",
       "7595   0.082458          -0.145     -0.136     -0.217  0.088    -0.436  0.331  \n",
       "4340   0.124926          -0.421      0.050     -0.769  0.637    -0.562 -0.258  \n",
       "3956   0.456646          -0.083     -0.501     -0.130 -0.277    -0.619 -0.148  \n",
       "10436  0.252288           0.023      0.061     -0.021  0.084    -0.069 -0.548  \n",
       "10546  0.097619           0.138     -0.478     -0.287 -0.249    -0.498 -0.142  \n",
       "3398   0.246100          -0.507     -0.208      0.133 -0.160    -0.188 -0.287  \n",
       "786    0.349351          -0.099     -0.387      0.103  0.136    -0.972 -0.035  \n",
       "9025   0.290840           0.030     -0.457     -1.033 -0.460    -0.393 -0.189  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peptide_10mer_subset = pd.concat([peptide_10mer[(peptide_10mer['fold'] == 0)].sample(frac=0.01), peptide_10mer[(peptide_10mer['fold'] == 1)].sample(frac=0.01)], ignore_index=True).copy()\n",
    "peptide_10mer_subset = peptide_10mer_subset.sample(n=96)\n",
    "peptide_10mer_subset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc41d5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: CHANGE THE ORIGINAL ONE_HOT DOC TO HAVE BOS B IN IT\n",
    "one_hot = pd.read_csv(\"/Users/jessikabaral/Documents/Documents - Jessikaâ€™s MacBook Pro/HLAthenav2/hlathenav2/hlathena/data/aafeatmat_onehot_ext.txt\", sep = \" \")\n",
    "one_hot = one_hot.rename(index={'.': 'B'}, columns = {'.': 'B'})\n",
    "one_hot_dict = {index: row.tolist() for index, row in one_hot.iterrows()}\n",
    "\n",
    "kf = pd.read_csv(\"/Users/jessikabaral/Documents/Documents - Jessikaâ€™s MacBook Pro/HLAthenav2/hlathenav2/hlathena/data/aafeatmat_KideraFactors.txt\", sep = \" \")\n",
    "\n",
    "pc = pd.read_csv(\"/Users/jessikabaral/Documents/Documents - Jessikaâ€™s MacBook Pro/HLAthenav2/hlathenav2/hlathena/data/aafeatmat_AAPropsPCA3.txt\", sep = \" \")\n",
    "pc.loc[\"B\"] = 0\n",
    "pc_dict = {index: row.tolist() for index, row in pc.iterrows()}\n",
    "\n",
    "hla_full_pc_kf_pseudoseq_wseq = pd.read_csv(\"/Users/jessikabaral/Documents/Documents - Jessikaâ€™s MacBook Pro/HLAthenav2/hlathenav2/JB_Analyses/added_data/ABCG_prot.parsed.clean.updated.ALL.FEATS.txt\", sep = \" \", index_col = 1)\n",
    "\n",
    "hla_seq_df = hla_full_pc_kf_pseudoseq_wseq.seq.copy()\n",
    "hla_seq_df_dict = {index: row.tolist() for index, row in pd.DataFrame(hla_seq_df).iterrows()}\n",
    "\n",
    "amino_acid_mapping = { #B = BOS token\n",
    "    'B': 0, 'A': 1, 'R': 2, 'N': 3, 'D': 4, 'C': 5,\n",
    "    'Q': 6, 'E': 7, 'G': 8, 'H': 9, 'I': 10,\n",
    "    'L': 11, 'K': 12, 'M': 13, 'F': 14, 'P': 15,\n",
    "    'S': 16, 'T': 17, 'W': 18, 'Y': 19, 'V': 20, \"-\":21\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebe6d463",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_padding(sequence, max_len, padding_token = \"-\"):\n",
    "    \"\"\"\n",
    "    Pads the amino acid sequence to a maximum length by adding the necessary number of padding tokens (\"-\") after the fourth amino acid\n",
    "\n",
    "    Parameters: \n",
    "    - sequence (str): input amino acid sequence for peptide\n",
    "    - max_len (int): maximum length you want to pad the sequence to \n",
    "    - padding_token (str): token used for padding\n",
    "    \n",
    "    Returns: \n",
    "    - str: padded amino acid sequence\n",
    "    \"\"\"\n",
    "    difference = max_len - len(sequence)\n",
    "    final_seq = sequence[:4] + padding_token*difference + sequence[4:]\n",
    "    return(final_seq)\n",
    "    \n",
    "def get_param(df, tgt_col, pep_col, hla_col):\n",
    "    y_data = df[tgt_col]\n",
    "    x_data = df[pep_col]\n",
    "    hla_name = df[hla_col]\n",
    "    max_len = max_len = max([len(x) for x in x_data])\n",
    "    return y_data, x_data, hla_name, max_len\n",
    "\n",
    "def initialize_param(model):\n",
    "    for p in model.parameters():\n",
    "        if p.dim() > 1:\n",
    "            nn.init.xavier_uniform_(p)\n",
    "\n",
    "class PositionalEncoding(nn.Module): #from https://pytorch.org/tutorials/beginner/transformer_tutorial.html#:~:text=A%20sequence%20of%20tokens%20are,TransformerEncoderLayer.\n",
    "\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            x: Tensor, shape ``[seq_len, batch_size, embedding_dim]``\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bf3aca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa7ab287",
   "metadata": {},
   "source": [
    "## Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "05b295b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0428,  0.0144, -0.0614,  ..., -0.2851,  0.2332, -0.0849],\n",
       "         [ 0.0453, -0.0352,  0.1409,  ...,  0.2414, -0.0953, -0.0510],\n",
       "         [-0.0402, -0.0428,  0.0304,  ...,  0.0225,  0.0020,  0.0883],\n",
       "         ...,\n",
       "         [-0.0226,  0.0079,  0.1673,  ...,  0.2378, -0.2358,  0.1164],\n",
       "         [-0.0172, -0.0139,  0.1728,  ...,  0.0375, -0.1610, -0.0760],\n",
       "         [-0.0083, -0.0844,  0.1160,  ..., -0.1640,  0.1335, -0.0908]],\n",
       "\n",
       "        [[ 0.0356,  0.0215, -0.0530,  ..., -0.2710,  0.2303, -0.1039],\n",
       "         [-0.0154, -0.0590,  0.1156,  ...,  0.2249, -0.1520, -0.0754],\n",
       "         [-0.0766, -0.0478,  0.0293,  ..., -0.0090, -0.0257,  0.1041],\n",
       "         ...,\n",
       "         [-0.0229,  0.0511,  0.1174,  ...,  0.2288, -0.2029,  0.0457],\n",
       "         [ 0.0053, -0.0584,  0.1315,  ...,  0.0879, -0.1537, -0.0967],\n",
       "         [-0.0095, -0.0565,  0.0971,  ..., -0.1617,  0.1483, -0.0926]],\n",
       "\n",
       "        [[ 0.0352,  0.0223, -0.0546,  ..., -0.2720,  0.2313, -0.1033],\n",
       "         [-0.0167, -0.0667,  0.1203,  ...,  0.2317, -0.1523, -0.0800],\n",
       "         [-0.0819, -0.0504,  0.0316,  ..., -0.0065, -0.0264,  0.1015],\n",
       "         ...,\n",
       "         [-0.0191,  0.0544,  0.1151,  ...,  0.2305, -0.1966,  0.0511],\n",
       "         [ 0.0066, -0.0544,  0.1268,  ...,  0.0818, -0.1539, -0.0962],\n",
       "         [-0.0110, -0.0570,  0.0993,  ..., -0.1672,  0.1543, -0.0938]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.0129,  0.0031, -0.0972,  ..., -0.3202,  0.2688, -0.0947],\n",
       "         [-0.1247,  0.0965, -0.0784,  ...,  0.1014, -0.1272, -0.0305],\n",
       "         [-0.0094,  0.1334, -0.0492,  ...,  0.1642, -0.1036,  0.1814],\n",
       "         ...,\n",
       "         [ 0.0087,  0.0601,  0.1790,  ...,  0.0406, -0.1232, -0.0482],\n",
       "         [-0.0246, -0.0189,  0.1945,  ..., -0.1043, -0.0255, -0.1275],\n",
       "         [-0.0782, -0.0560,  0.1217,  ..., -0.1841,  0.1365, -0.1319]],\n",
       "\n",
       "        [[ 0.0515, -0.0148, -0.0899,  ..., -0.2731,  0.2095, -0.0527],\n",
       "         [-0.0555,  0.0710, -0.2072,  ...,  0.1844, -0.0848,  0.0749],\n",
       "         [-0.1190,  0.1570, -0.0937,  ...,  0.1340, -0.0832,  0.1642],\n",
       "         ...,\n",
       "         [-0.0608, -0.0242, -0.0038,  ..., -0.0108, -0.1108,  0.1404],\n",
       "         [-0.0230, -0.0211,  0.0421,  ...,  0.0299, -0.1393,  0.1321],\n",
       "         [-0.0336, -0.0042,  0.0187,  ...,  0.0269, -0.1234,  0.1241]],\n",
       "\n",
       "        [[ 0.0315, -0.0054, -0.0957,  ..., -0.2624,  0.2093, -0.0584],\n",
       "         [-0.0209,  0.1196, -0.1951,  ...,  0.1853, -0.0668,  0.1092],\n",
       "         [-0.0896,  0.1375, -0.0934,  ...,  0.1350, -0.0848,  0.1608],\n",
       "         ...,\n",
       "         [-0.0657,  0.0347,  0.0324,  ..., -0.0493, -0.1528,  0.1441],\n",
       "         [-0.0766, -0.0270, -0.0106,  ..., -0.0689, -0.1505,  0.1452],\n",
       "         [-0.0005, -0.0142,  0.0578,  ...,  0.0309, -0.1440,  0.1509]]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, alphabet = esm.pretrained.esm2_t33_650M_UR50D()\n",
    "batch_converter = alphabet.get_batch_converter()\n",
    "model.eval()  # disables dropout for deterministic results\n",
    "\n",
    "# Prepare data (first 2 sequences from ESMStructuralSplitDataset superfamily / 4)\n",
    "data = [\n",
    "    (\"protein1\", \"MKTV<pad><pad><pad>LAGG\"),\n",
    "    (\"protein2\", \"MKTV<mask><mask><mask>LAGG\"),\n",
    "    (\"protein25\", \"MKTV---LAGG\"),\n",
    "    (\"protein3\",  \"K A <pad> I S Q\"),\n",
    "    (\"protein4\",  \"KA<pad>ISQ\"),\n",
    "    (\"protein5\",  \"KA<mask>ISQ\"),\n",
    "    (\"protein6\",  \"KAISQ\"),\n",
    "    (\"protein7\",  \"AAAAAA\"),\n",
    "    (\"protein8\",  \"AAA<pad>AAA\"),\n",
    "]\n",
    "batch_labels, batch_strs, batch_tokens = batch_converter(data)\n",
    "batch_lens = (batch_tokens != alphabet.padding_idx).sum(1)\n",
    "\n",
    "# Extract per-residue representations (on CPU)\n",
    "with torch.no_grad():\n",
    "    results = model(batch_tokens, repr_layers=[33], return_contacts=True)\n",
    "token_representations = results[\"representations\"][33]\n",
    "token_representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2ccc8cf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9, 13, 1280])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_representations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641ae38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    (\"protein1\", \"MKTV<pad><pad><pad>LAGG\"),\n",
    "    (\"protein2\", \"MKTV<mask><mask><mask>LAGG\"),\n",
    "    (\"protein25\", \"MKTV---LAGG\"),\n",
    "    (\"protein3\",  \"K A <pad> I S Q\"),\n",
    "    (\"protein4\",  \"KA<pad>ISQ\"),\n",
    "    (\"protein5\",  \"KA<mask>ISQ\"),\n",
    "    (\"protein6\",  \"KAISQ\"),\n",
    "    (\"protein7\",  \"AAAAAA\"),\n",
    "    (\"protein8\",  \"AAA<pad>AAA\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "540be139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0, 20, 15, 11,  7,  1,  1,  1,  4,  5,  6,  6,  2],\n",
       "        [ 0, 20, 15, 11,  7, 32, 32, 32,  4,  5,  6,  6,  2],\n",
       "        [ 0, 20, 15, 11,  7, 30, 30, 30,  4,  5,  6,  6,  2],\n",
       "        [ 0, 15,  5,  1, 12,  8, 16,  2,  1,  1,  1,  1,  1],\n",
       "        [ 0, 15,  5,  1, 12,  8, 16,  2,  1,  1,  1,  1,  1],\n",
       "        [ 0, 15,  5, 32, 12,  8, 16,  2,  1,  1,  1,  1,  1],\n",
       "        [ 0, 15,  5, 12,  8, 16,  2,  1,  1,  1,  1,  1,  1],\n",
       "        [ 0,  5,  5,  5,  5,  5,  5,  2,  1,  1,  1,  1,  1],\n",
       "        [ 0,  5,  5,  5,  1,  5,  5,  5,  2,  1,  1,  1,  1]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "830c761d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphabet.padding_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4732595e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 13, 13,  7,  7,  8,  7,  8,  8])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d6a01fe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([ 0.0356,  0.0058,  0.0975,  ...,  0.1556, -0.1289,  0.0456]),\n",
       " tensor([-0.0023,  0.0042,  0.0851,  ...,  0.1401, -0.1361,  0.0390]),\n",
       " tensor([-0.0032,  0.0068,  0.0855,  ...,  0.1416, -0.1361,  0.0406]),\n",
       " tensor([ 0.0096,  0.1604,  0.0180,  ...,  0.0481, -0.1081,  0.0056]),\n",
       " tensor([ 0.0096,  0.1604,  0.0180,  ...,  0.0481, -0.1081,  0.0056]),\n",
       " tensor([ 0.0084,  0.1425,  0.0506,  ...,  0.0403, -0.1063,  0.0079]),\n",
       " tensor([-0.0032,  0.1404,  0.0281,  ...,  0.0425, -0.1192,  0.0148]),\n",
       " tensor([-0.1254,  0.1185, -0.0388,  ...,  0.0804, -0.0446,  0.0974]),\n",
       " tensor([-0.0812,  0.0932, -0.0362,  ...,  0.0863, -0.0539,  0.1304])]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "997159f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1280])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_representations[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7a4cfec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAacAAAHYCAYAAADpmyeMAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA1FElEQVR4nO3deXRU5eH/8c8khCwEkLAGEBIoFEo1kiCoLFKhKFp3KYqyqNVgPSjWitQNj8VWrfoV+f5UggsoiopYK5UWwVDUVsoSQMUpYUkEMSwCAiGZkGSe3x9855aYSZiZTJhnmPfrnDknuffOM5+EMJ+5d56512WMMQIAwCJxkQ4AAMAPUU4AAOtQTgAA61BOAADrUE4AAOtQTgAA61BOAADrUE4AAOtQTgAA61BOwClo6NChcrlcevjhhyMdBQgJ5YQTOnDggJKSkuRyueRyubR58+agx3C73c79mzVrpkOHDoWUZfHixc44Xbp0kdfrDWkcNK7nnnvO+XcaNGhQyONMmTLFGeeGG24IeZxf/vKXzjgPPPBAyOPg5KGccEKvv/66KioqnO9ffvnloMd46aWXnK/Lyso0f/78kLIc/9g7duzQ0qVLQxoHjev4f6d//vOf+s9//hP0GFVVVXrttdec7xcuXKjvv/8+6HH27dun999/3/l+zpw5qq6uDnocnFyUE07IVyyTJk2SJM2dOzeo/9yVlZXOk4xvjOPLKlB79+7V+++/r/j4eN12220hj4PGtWHDBq1du1atWrXS9ddfLym0FzQffPCBdu3apZ/85Ce64IIL5PF49MYbbwQ9zrx581RRUaGLL75Y3bt3186dO7VkyZKgx8HJRTmhXgUFBVq/fr1OO+00PfHEE+rWrZtKSkr0t7/9LeAxFi1apD179qhXr1764x//qNTUVK1evVpffvllUFlee+01VVZW6uc//7lzuOcvf/mL9u3bF+yPFZDKykotWrQopFfrNsvPz1dxcXGjje97wTB69GjdcsstkqRXX31VVVVVIY0zbtw4jRs3TlLD9trHjRunsWPHhjwOTjID1OPXv/61kWRyc3ONMcZMmzbNSDJXXHFFwGNcfPHFRpL54x//aIwxZvz48UaSmTx5clBZ+vTpYySZ+fPnG2OMOf/8840k88wzzwQ1zomsWrXKTJo0ybRp08ZIMkVFRbW2kWQkmeXLl5uSkhJz++23m4yMDJOYmGjat29vxowZY9xud52P8Z///Mc88cQTZtiwYaZbt24mKSnJNG/e3Jx11lnm/vvvN3v37q03Y1VVlZk5c6bp27evSUlJMa1atTLnn3++WbBggTHmv7+badOm1brv+PHjjcvlMkOGDDGzZ88233//fVC/n/p4PB6TlpZmJJnPPvvMeL1ek5mZaSSZ9957L+Bxvv32W9OkSRMTFxdnvvnmG3P48GHTrFkzI8msX78+4HFWrVplJJmWLVua8vJys23bNuNyuUxCQoLZs2dPKD8iThLKCXUqLy83p512mpFk/vnPfxpjjNm6datxuVymSZMmZteuXScc45tvvjHx8fEmLi7O7NixwxhjTH5+vpFk2rRpYyoqKgLK8tlnnxlJpkWLFqasrMwYY8zLL79sJJkzzjgjxJ/wv4qKisz06dPNj3/8Y6d4JJn09HSze/fuWtv71r/88sumQ4cORpJJTk42qampzrqkpCTzt7/9ze/jde3a1dnO5XKZ0047zbhcLmdZp06dzH/+8x+/9/V4PObCCy90to2Li6tx/3vvvbfecpo2bZqJi4urkXPUqFFm0aJFprKyskG/x/nz5xtJpmfPns6yhx56yEgyl156acDj/PGPfzSSzM9//nNn2bhx44wkM2nSpIDHyc3NNZLMLbfc4iwbMmSIkWSeeuqpgMfByUc5oU7z5s0zksyPfvSjGssHDx5sJJk//elPJxxj+vTpRpIZNmyYs8zr9TpPzr5X+ifyq1/9ykgyN998s7Ps0KFDJiUlxUgyq1evDvCn+q/vv//evPjii2bIkCE1iqF58+Zm/PjxZunSpaa6utrvfX3btmzZ0nTp0sV8+OGHxuv1GmOM+fe//23OOOMMp0x9pXy80aNHm5kzZ5otW7Y4BV1RUWGWLVtm+vfvbySZ7Oxsv4991113OaU2ffp0c/DgQWOMMbt37za33Xabk6uucjLGmJ07d5onn3zS9O3bt0YZt23b1kyaNMmsWrUq2F+nMcaY4cOHG0nm97//vbNsy5YtRpJp0qSJ+fbbbwMap0ePHkaSee2115xlH330kZFk0tLSjMfjOeEYR44cMS1atDCSzCeffOIsf+mll4wk06dPnyB+MpxslBPq9LOf/cxIMo888kiN5bNnzzaSTK9eveq9v9frNd27dzeSzKuvvlpj3f33328kmYsuuuiEOUpLS03z5s2NJPPxxx/XWHf99dcbSWbixIkB/UyVlZVm0aJF5pe//KVJSkpynpQTEhLMpZdeat566y1nz6w+vvs1bdrUfPXVV7XW79692zm89etf/zqgbD6HDx827du3r/WkasyxUmnSpImRZB588EG/97/uuuucfHWV0/G++uorc99995mMjIwaRdWrVy/z6KOPmuLi4oByFxcXG5fLZVwuV637DBw40Egyjz322AnHWbFihZFkUlNTzZEjR5zlXq/XnH766UaSefPNN084zty5c40k07179xrLDx06ZJKTk40ks3LlyoB+Npx8lBP88h2+c7lctd5zOXjwoPOf23e4zx/f4btmzZqZ0tLSGusKCwudQ1L+9iyO5zt8l5mZ6eyd+Hz44YfOnkJ9pbJ69Wpzxx13mLZt29Y4nDZo0CDz/PPPm3379tWb4Yd8Y1x//fV1bnPfffcZSaZ169ZBjW2MMb/85S9rvE/nM2PGDOcQom+P6Yc2bdoUVDn5eL1e88knn5jc3FynWH2/p/PPP9+8+OKL9b4/5Tt8N3To0Frr8vLyah3uq4vv8N2ECRNqrfP9To8/3FcX3+G7hx9+uNa6MWPG1DrcB7tQTvDLt2czZMgQv+t9r86PP8z2Q769mnHjxvldf+6559Y6BOSP71X3Qw89VGtddXW16dy5c61DQMd77LHHauwR/OQnPzGPPvqo34kOgfKN9dJLL9W5zbJly5zttm3bVmu9bw8uMzPTOTz5w9vtt99e4z5jx441kszgwYPrzdepU6egy+l4R48eNe+9954ZNWpUjT3MpKQkv9tXV1ebLl26OO/D/dD333/vjPPDvcHjHTx40Pld5Ofn11rvK964uLh69+g2b97sFOvWrVtrrV+yZIlzCPf4vTPYg6nkqMXr9Wru3LmS5Ezh/aHx48dLkt566y2VlpbWWn/w4EG9++67AY3x8ssvyxjjd5tNmzbpn//8Z53jxMXFOWcOqOszT+Xl5c7XaWlpuvbaazV69GhlZGT43T4YnTp1Cmjdnj17nK+9Xq/GjBmjSy+9VG+//baKiop09OhRtWrVSu3bt1f79u2VlJQkSTpy5EiNMX3j1Pe4ktS5c+egf5bjJSQk6KKLLtK1115b4wwPHo/H7/bLli3T9u3blZKSomuuuabW+pYtW+qKK66QVP9n0958802VlZWpS5cuGjp0aK31PXv21DnnnCOv16s5c+bUOY5vqvjAgQPVrVu3WuuHDx+uTp066fDhw1qwYEGd4yCCIt2OsM/ixYv9voqv6+Zv7+G5554LaoyPPvrIb5YpU6YEPIbL5TJbtmypNca2bdvMlClTnL0J323AgAHm2Wef9Tsb70R8YyxZsqTObdxut7Pd8e9t+A5xxcfHm4ceeshs3ry51sSLG264wUgy48ePr7HcN0vvuuuuqzffgAEDQtpzqq6uNvn5+ebmm292JlX4sl544YVm3rx5fu/nOwwZyK1Zs2bm0KFDfsfxTQYJ5Na1a9dah3mNOTbNvmPHjgGPc6K9UEQG5YRarr766qCKZeDAgbXGyMnJCWoMf+/dVFZWOtO0A73df//9df5c1dXVZunSpWbcuHE1pnz7nnhfffVVc/jw4YB+R/UVs09dh/UuuOACI/33s2P++Ga9/bCcAj2s5zvUGWg5FRQUmLvvvrtWgZ911lnmqaeeMiUlJXXe97vvvjOJiYlB/TvNnj271jhffPFFUGNIMkuXLq01zqJFi4Iep7CwMKDfE04eygk17NmzxyQkJBhJ5p133jGHDx+u8+b7gKOkGh84Xb9+vbN89erV9Y7xzjvvGOnYexkHDhyokeW9994z0rGZdL4PYtZ1e+qpp4x07PNBVVVVJ/w5jxw5YubNm2cuvPBCEx8f7+RNSUkxo0ePNu+//745evRonff3bX/DDTfUuY3vfbu0tLQay33TpF944QW/9zt8+LAzO/GH5XT8hIi69j58k01OVE7btm0z06dPN717967xRN2pUydzzz33mC+++KLO+x7vmWeeMZJMu3btzMGDB+v9d7rzzjuNJHPOOefUGmfy5MlGOjaFvr4xDh8+bK644gojyVx77bW1xvGtu/LKK084TnZ2tpFkpk6dGtDPipOHckINvif5li1bBvQB2V69ehlJ5p577nGWTZo0yUgnnmpuzLEPlPoOH/2///f/aqy79NJLjRTYdPOdO3c6Hyz94IMPTrj98b799lvz5JNPmqysrBpP0mlpaSY3N9fv3pRvm8TERL8flt27d69zhonbbrutxrp+/fr5Xe5z/KHMH5bTN99840wlr6t4fIcE69rm/fffN+edd16NnzU1NdWMGzeu3s921eXMM880UmDT+X0fppZkNm7c6CyvqKhwfl+BTDf3fdg3MTHR7N+/31m+a9cu5/cTyHRz34d909PTA3pRg5OHckINvlME1TXD7ocefPBBI8m0b9/eVFZW1jh9jb/Zdf74DlXl5OQ4y3ynr5H8z/7yx/fh4Kuvvjqg7f35/PPPzT333FPj8FZ9py9q2bKlycjIMEuXLnXe/1i1apVTdM2bNzdff/11jfs+8MADRjr2odRZs2Y5LwJKSkqcvYfWrVv7LSdjjLnjjjuMdGzG2h/+8AdnD2rPnj3m9ttvd3LVVU6+00fFx8ebESNGmNdee63WVP9AHb/37G92nT++WX133323s+ztt992xvE3u+6HSktLnY8zzJw501n+xBNPOHuWgfxMW7dudR530aJFAeXHyUE5wXH8q9pA/6N+/vnnzn3ee+895xWtpIAPC73//vvOfXznTfO9ok1ISKjxyrg+zz77rHOfhp43rbq62nz44Ydm7NixZufOnbXW+/K+9NJLzvtiKSkpNd7LSkxMNH/9619r3ffAgQPOHqevZI4//VBubq5TIP7Kqby83HlPylcyrVq1Cvj0RY899ph58sknAz5bQ318pwdq165dwHsev/nNb4x07GwUvkOnvokex79AOZGrrrrKSMfeF/Px/V6DeYHiO7QXzPki0fgoJzh8pwgK9JCej+89i0svvdR50uzdu3fA96+oqHBe6fvOm+Z7X2bkyJEBj/Ptt986h/Ya+7xpvmI4/sSvXbt2NU2bNjXt2rUz1113nd8zR/js37/fTJ482WRkZJiEhATTpk0b87Of/cw5qW195WTMsckiM2bMMGeddZZJTk42p512mhkyZIh5++23jTH1n/g1XMrKypx/t7oOUfqzcuVK5/e3cOFCs337duff7fHHHw94nDfffNMZZ+3atebTTz91vn/rrbcCHsf3ObhAzxeJk8NlTB0fMAFQJ5fLJUlavny538/jAGgYPoQLALAO5QQAsA7lBACwDuUEALBOk0gHAKIR84iAxsWeEwDAOpQTAMA6lBMAwDoxW07Lly/XL37xC7Vt21bJycnq1auXHnzwwVoXd7PJrl27NG/ePN15550aOHCgUlJS5HK51K9fv0hHq5cxRv/61780depUDRo0SK1bt1ZCQoLatm2rESNG6PXXX7f2PZxFixbp9ttv1znnnKPOnTsrKSlJqamp+ulPf6rJkyfr66+/jnTEgC1evFgul0sulyssF1psLA8//LCTs67bCy+8EOmYJ7R48WJdddVV6tixoxITE9W+fXsNHDhQDzzwgKqqqiIdz1FcXHzC37fvduONN560XDE5IWLmzJm68847ZYxR586ddfrpp+urr77S9OnTtXDhQn366adKS0uLdMxa3nzzTd11112RjhG0/Px8DR8+3Pm+W7duyszMVFFRkZYuXaqlS5dq/vz5WrhwoRITEyOYtLannnpKK1asUEJCgtLT03XGGWfou+++k9vt1saNGzV79mz9+c9/1ogRIyIdtV6HDx/WxIkTIx0jKO3atVOPHj38rktPTz/JaQJXVVWlG2+8UfPmzZN07KrEWVlZ2rdvn9asWeO8UEtNTY1w0mOSkpI0cODAOtd7PB6tXbtWknTeeeedrFiKuXPrrVmzxsTFxRmXy2VmzZrlnEl6586dzgXyrrrqqgin9O+ll14yw4cPN1OnTjXvvPOO+cMf/hD0yTIjYenSpSYzM9PMmDGj1lVnX331VedCdffee2+EEtZt7ty5ZtmyZcbj8dRYvmXLFjNkyBAjybRp0ybks3qfLLfddptzclPp2FVkbTVt2rR6zytoO985KrOyssyqVatqrDty5Ij5y1/+Uu+1wmwzZ84c50zvBw8ePGmPG3PldPnll9d5SYjCwkLnBJQbNmyIQLrgvPLKK1FRTgcPHqz3P+Ojjz7qXD8p2GsJRdKuXbucE40uXrw40nHq9MknnxiXy2WuvPJK52+Gcmoc+fn5RpLp2LGj2bdvX6TjhMXQoUON5P9q1Y0ppt5zKi0t1d///ndJ0q233lprfY8ePXTBBRdIkhYsWHBSs53KWrRooYSEhDrXjxw5UpK0f/9+7d2792TFarD27ds7h3/LysoinMY/j8ejX/3qV0pNTdXMmTMjHeeU9/TTT0uS7rnnHivfGghWcXGxVqxYIUmaMGHCSX3smHrPad26daqoqFBiYqL69+/vd5vBgwdr2bJlWrly5UlOF7s8Ho/zdXJycgSTBMftdmv//v2Ki4tT3759Ix3Hr0ceeUSbNm3SzJkz1alTp0jHCcqGDRs0ZswY7dq1S82bN9eZZ56pa6+9Vn369Il0NL88Ho+WLFkiSbr88su1evVqvfLKK9q8ebOSk5PVr18/3XTTTercuXOEkwZu7ty5MsaoS5cuzgv3k+ak7qdF2IsvvmgkmR49etS5zbx584wkc/rpp5/EZKGJlsN6J+K7rHtWVlako5yQ1+s1u3fvNgsXLjQ/+tGPjCQzZcqUSMfya926daZJkyamf//+zuHSaDqs5+/mcrnM5MmTrbykuu86Vc2aNTNPPPGE8xbB8bfk5GTnmlu283q9plu3bkaSeeCBB07648fUYb39+/dLUr272751Bw4cOCmZYl1BQYEzLXjq1KkRTlO3efPmyeVyKS4uTu3bt9fVV1+tJk2a6PXXX9fjjz8e6Xi1VFdX6+abb5Yk5eXlKS4uev6rd+jQQVOmTNHKlSu1d+9eeTweff7555o4caKMMXrmmWd03333RTpmLSUlJZKkiooKTZkyReedd57Wrl2riooKFRYWatSoUSovL9cNN9ygDRs2RDjtia1YsULbtm2TdPIP6UmKrT2nRx55xEgygwcPrnObjz76yLn0te2ifc9p165dpkuXLkaSufLKKyMdp15LliwxAwcONOeee645/fTTTVxcnImLizMXX3yx2bFjR6Tj1eK7uusP9+qiYc+pPo8//rhz1dqioqJIx6nhtddec/aQ2rRpYw4dOlRjfXV1tTnrrLOMJDNq1KgIpQyc72rM9T1fNqboeTkVBklJSZKko0eP1rlNRUWFpOh67yMaHTx4UCNHjtT27duVk5OjOXPmRDpSvUaMGKFPP/1U//rXv7R9+3Zt3rxZl112mRYvXqxzzjlHBw8ejHREx+bNm/Xwww8rMzNT06ZNi3ScsLr77rvVsWNHVVVVadGiRZGOU4Pv+UU6NuGqefPmNdbHxcU5n1NcsmSJvF7vSc0XjCNHjmjhwoWSIrTXpBg7Q0SrVq0k/ffwnj++db5tEX6lpaW66KKLtG7dOvXp00dLlixRixYtIh0rKN26ddM777yjPn36aOfOnfrf//3fSEdyTJw4UR6PR88//7xSUlIiHSes4uPjNWDAAElSYWFhhNPUdPxzRu/evf1u41t+6NChep+HIm3BggUqLS1VSkqKRo0aFZEMMTVbr2fPnpKk7du3q7Ky0u/05q1bt9bYFuFVVlamSy65RCtXrlTPnj21bNkytW7dOtKxQhIfH6+RI0dq48aNWrNmTaTjONauXSuXy6Xx48fXWldeXi5J2rFjhzp06CBJevfdd0/uJ/8bqGnTppJk1SmAJKlXr17O18fvRR3v+OXV1dWNnilUviMZ11xzTa09wJMlpsopOztbTZs2VUVFhVatWuX3lB2ffPKJJOncc8892fFOeR6PR5dffrk+/vhjZWRk6KOPPnKeIKNVZWWlJFl3iMYYo927d9e53uv1OuvrO8xtoy+//FKSrJuS3alTJ3Xt2lVff/218yL3h3zLExMTrX1RVlRUpI8//lhS5A7pSTF2WC81NVUXXnihpGMzmH5o8+bNys/Pl3TsFQPCp7KyUldffbWWLVumzp07Kz8/37onl2AdPXpUf/3rXyXJqs85ff/99zLHzv5S6/bKK69Ikrp27eosGzp0aGQDB+GDDz7Qxo0bJcnK8xmOHj1a0rHPB/l7wfLyyy9Lks4//3w1aWLnvoHvs00ZGRmR/duIyDSMCFq1apVxuVy1zq337bffOufWu+KKKyKcMjDRMluvqqrKjBo1ykgyHTp0MIWFhZGOFJDVq1ebBx54wG/eTZs2mREjRhhJJjU11XzzzTcRSBg822frffnll+bWW28169evr7G8urravPHGG6ZFixZGkrnkkksilLB+e/bsMS1btjSSzB133GEqKiqMMcc+M/TMM884n9Vavnx5ZIPWwev1mszMTCPJTJs2LaJZYq6cjDHmf/7nf4zL5XI+bNu3b1/n5KM//vGPzd69eyMd0a/t27eb1q1bO7fU1FRnWu3xyx9//PFIR63hjTfecKbYZmRkmIEDB9Z5KygoiHRcx/Lly53cbdu2NdnZ2WbAgAHO9Hf93/kAP/roo0hHDZjt5bRu3boav9u+ffuas88+27Rq1cpZPnjwYHPgwIFIR63T0qVLTXJyspFkWrVqZfr37286dOjgFNOf/vSnSEesk+9v3uVymW3btkU0i537lY1s8uTJOuOMM/TUU0/p3//+t/bs2aOuXbvqmmuu0e9+9ztrTmX/Q9XV1dq3b1+t5VVVVTWW23aeN9/0fOnYubqKi4vr3NamKdlZWVl69tln9Y9//ENffPGFtmzZorKyMrVs2VKDBg3SRRddpNzcXLVp0ybSUU8ZGRkZmj59uj777DO53W5t2bJFHo9HaWlpGjlypMaMGaPrrrtO8fHxkY5ap+HDh2vDhg36wx/+oGXLlmndunVq2bKlLrvsMv3mN7/R+eefH+mIdfJNhBgyZIgyMzMjmsVljKVXeQMAxKyYmhABAIgOlBMAwDqUEwDAOpQTAMA6lBMAwDqUEwDAOpQTAMA6lBMAwDqUEwDAOpQTAMA6MXluvePNmjVLJSUlSk9PV25ubqTjBCVas0drbil6s0drbil6s0drbsmS7BE97awFsrOzjSSTnZ0d6ShBi9bs0ZrbmOjNHq25jYne7NGa2xg7snNYDwBgHcoJAGAdygkAYB3KCQBgHcoJAGAdygkAYB3KCQBgHcoJAGAdygkAYB2XMcZEOsSJZGRkaM+ePUpKSlJmZmZYx3a73SovL1dycrJ69+4d1rEbW7Rmj9bcUvRmj9bcUvRmj9bcUuNmLyoqksfjUbt27VRcXFzndlFRTikpKSovL490DABAmCQnJ6usrKzO9VFx4tekpCSVl5crTvFqphaRjhMUV1z0Hjk13upIRwiRK9IBGsD614qnHleU/r1E6Z/KER2SV9VKSkqqd7uoKKfMzEwdOHBAzdRCA+JHRDpOUOJTm0U6QsiqDx2KdITQxMVHOkHojDfSCWKOq0lCpCOExFRH54vHf1d/qMM6cMK3aKL3ZT0A4JRFOQEArEM5AQCsQzkBAKxDOQEArEM5AQCsQzkBAKxDOQEArEM5AQCsQzkBAKxDOQEArEM5AQCs06ByWr58uX7xi1+obdu2Sk5OVq9evfTggw/qyJEj4coHAIhBIZfTzJkzNWzYMH3wwQdKSkpS7969VVxcrOnTp+vss8/W/v37w5kTABBDQiqntWvXavLkyZKkWbNmafv27SooKNC2bduUk5Mjt9utW265JZw5AQAxJKRy+v3vfy+v16uxY8fq1ltvlev/LtbVsWNHzZ8/X3FxcXr33Xf1+eefhzUsACA2BF1OpaWl+vvf/y5JuvXWW2ut79Gjhy644AJJ0oIFCxoYDwAQi4Iup3Xr1qmiokKJiYnq37+/320GDx4sSVq5cmXD0gEAYlLQ5VRYWChJ6tKlixIS/F/euHv37pKkTZs2NSAaACBWNQn2Dr5ZeGlpaXVu41t34MCBOreZNWuW8vLyAnpMt9sdREIAQLQLupw8Ho8kqWnTpnVuk5iYKEkqLy+vc5uSkhIVFBQE+/AAgBgQdDklJSVJko4ePVrnNhUVFZKk5OTkOrdJT09XdnZ2QI/pdrvrLToAwKkl6HJq1aqVJNX7IVvfOt+2/uTm5io3Nzegx8zJyWEvCwBiSNATInr27ClJ2r59uyorK/1us3Xr1hrbAgAQjKDLKTs7W02bNlVFRYVWrVrld5tPPvlEknTuuec2LB0AICYFXU6pqam68MILJcnvbLvNmzcrPz9fknTNNdc0MB4AIBaFdPqiBx98UC6XS6+99pry8vJkjJF0bAbeddddJ6/XqyuuuEJZWVlhDQsAiA0hldPZZ5+tp59+WtKxiQ1du3ZVdna2MjMztXbtWv34xz/W7NmzwxoUABA7Qr5kxuTJk7V06VKNHDlSR44c0VdffaWuXbvqvvvu05o1a9SmTZtw5gQAxJCgp5Ifb9iwYRo2bFi4sgAAIInLtAMALEQ5AQCsQzkBAKxDOQEArEM5AQCsQzkBAKxDOQEArEM5AQCsQzkBAKxDOQEArEM5AQCsQzkBAKzToBO/nmyuuDjFpzaLdIyguNJOi3SE0JUeiXSC2PN/10bDyWOqKiMdITSuU3vf4tT+6QAAUYlyAgBYh3ICAFiHcgIAWIdyAgBYh3ICAFiHcgIAWIdyAgBYh3ICAFiHcgIAWIdyAgBYh3ICAFiHcgIAWIdyAgBYh3ICAFgnpHLatWuX5s2bpzvvvFMDBw5USkqKXC6X+vXrF+58AIAYFNLFBt98803ddddd4c4CAICkEMupRYsWGj58uPr166d+/fqpsLBQ9913X7izAQBiVEjldNNNN+mmm25yvp8zZ0648gAAwIQIAIB9KCcAgHUoJwCAdUJ6zykcZs2apby8vIC2dbvdjZwGAGCTiJVTSUmJCgoKIvXwAACLRayc0tPTlZ2dHdC2brdb5eXljZwIAGCLiJVTbm6ucnNzA9o2JyeHvSwAiCFMiAAAWIdyAgBYh3ICAFiHcgIAWCekCRE7duxQ3759ne8rKiokSRs2bFCbNm2c5VOmTNGUKVMaGBEAEGtCKqfq6mrt27ev1vKqqqoay8vKykJPBgCIWSGVU0ZGhowx4c4CAIAk3nMCAFiIcgIAWIdyAgBYh3ICAFiHcgIAWIdyAgBYh3ICAFiHcgIAWIdyAgBYh3ICAFiHcgIAWIdyAgBYh3ICAFgnpLOSR4rxVqv60KFIxwhO6ZFIJwjZ2QVHIx0hJKuzm0Y6AqKIq0lCpCOExFRXRzpCo2LPCQBgHcoJAGAdygkAYB3KCQBgHcoJAGAdygkAYB3KCQBgHcoJAGAdygkAYB3KCQBgHcoJAGAdygkAYB3KCQBgHcoJAGAdygkAYJ2gy8kYo3/961+aOnWqBg0apNatWyshIUFt27bViBEj9Prrr8sY0xhZAQAxIuiLDebn52v48OHO9926dVNmZqaKioq0dOlSLV26VPPnz9fChQuVmJgY1rAAgNgQ0p5TZmamZsyYod27d2vr1q1as2aN9u3bp1dffVWJiYn64IMPNG3atMbICwCIAUGXU//+/bVp0ybdcccdateuXY11Y8eO1UMPPSRJmj17trxeb3hSAgBiStDl1KJFCyUkJNS5fuTIkZKk/fv3a+/evaEnAwDErLDP1vN4PM7XycnJ4R4eABADwl5O8+fPlyRlZWWpRYsW4R4eABADgp6tV5+CggK98MILkqSpU6fWu+2sWbOUl5cX0Lhut7vB2QAA0SNs5bR7925deeWVqqys1JVXXqlrr7223u1LSkpUUFAQrocHAJxCwlJOBw8e1MiRI7V9+3bl5ORozpw5J7xPenq6srOzAxrf7XarvLy8gSkBANGiweVUWlqqiy66SOvWrVOfPn20ZMmSgN5rys3NVW5ubkCPkZOTw14WAMSQBk2IKCsr0yWXXKKVK1eqZ8+eWrZsmVq3bh2ubACAGBVyOXk8Hl1++eX6+OOPlZGRoY8++kgdOnQIZzYAQIwKqZwqKyt19dVXa9myZercubPy8/PVuXPncGcDAMSooMupurpa119/vRYvXqwOHTooPz9fmZmZjZENABCjgp4Q8fbbb2vBggWSpKSkJN144411bjtz5kz17ds39HQAgJgUdDlVVFQ4XxcXF6u4uLjObQ8ePBhSKABAbAv6sN6ECRNkjAnoNnTo0EaIDAA41XGZdgCAdSgnAIB1KCcAgHUoJwCAdSgnAIB1KCcAgHUoJwCAdSgnAIB1KCcAgHUoJwCAdSgnAIB1KCcAgHWCPit5ZLmkuPhIh4gZq7ObRjpC7OHv+6Qz1dWRjgA/2HMCAFiHcgIAWIdyAgBYh3ICAFiHcgIAWIdyAgBYh3ICAFiHcgIAWIdyAgBYh3ICAFiHcgIAWIdyAgBYh3ICAFiHcgIAWIdyAgBYJ6RyWrRokW6//Xadc8456ty5s5KSkpSamqqf/vSnmjx5sr7++utw5wQAxJCQyumpp57Sc889p4KCAsXHx+uMM85Q27Zt5Xa7NWPGDP3kJz/Rhx9+GO6sAIAYEVI53XTTTVq2bJkOHz6sr7/+WqtXr1ZRUZEKCws1ZMgQlZWV6frrr9eRI0fCnRcAEANCKqdx48Zp2LBhSkxMrLG8e/fuevvttyVJ3333nT7++OOGJwQAxJywT4ho37690tLSJEllZWXhHh4AEAPCXk5ut1v79+9XXFyc+vbtG+7hAQAxICzlZIzRnj179O677+qyyy6TJP32t79Vt27dwjE8ACDGNGnInefNm6exY8fWWNarVy+9/vrrGjNmTL33nTVrlvLy8gJ6HLfbHXJGAED0aVA5tWvXTgMHDpTX69U333yjnTt3qrCwUK+//rqGDBmizp0713nfkpISFRQUNOThAQCnqAaV04gRIzRixAjn+23btunuu+/We++9p3POOUcbN25Uy5Yt/d43PT1d2dnZAT2O2+1WeXl5Q6ICAKKIyxhjwjlgdXW1srKytHHjRk2fPl33339/g8fMyclRQUGBmquVBsSPOPEdAABW+nf1hzqsA8rOztbatWvr3C7ss/Xi4+M1cuRISdKaNWvCPTwAIAY0yolfKysrJUler7cxhgcAnOLCXk5Hjx7VX//6V0nic04AgJAEXU5r1qzRgw8+qM2bN9daV1hYqEsvvVRbt25VamqqbrnllrCEBADElqBn65WWlmr69OmaPn262rZtq9NPP10JCQkqKSnR9u3bJUlpaWlasGCBOnXqFPbAAIBTX9DllJWVpWeffVb/+Mc/9MUXX2jLli0qKytTy5YtNWjQIF100UXKzc1VmzZtGiMvACAGBF1OrVq10qRJkzRp0qTGyAMAAJdpBwDYh3ICAFiHcgIAWIdyAgBYh3ICAFiHcgIAWIdyAgBYh3ICAFiHcgIAWIdyAgBYh3ICAFiHcgIAWIdyAgBYJ+izkkeWkUyUXfrdmEgniD1x8ZFOELIl36yNdISQXHzmsEhHCFn1d/siHSE0Ufx3Hgj2nAAA1qGcAADWoZwAANahnAAA1qGcAADWoZwAANahnAAA1qGcAADWoZwAANahnAAA1qGcAADWoZwAANahnAAA1qGcAADWoZwAANYJSzktXrxYLpdLLpdLGRkZ4RgSABDDGlxOhw8f1sSJE8ORBQAASWEop3vvvVc7duzQFVdcEYY4AAA0sJw+/fRTvfDCC7ryyit1+eWXhysTACDGhVxOHo9Hv/rVr5SamqqZM2eGMxMAIMY1CfWOjzzyiDZt2qSZM2eqU6dO4cwEAIhxIe05rV+/Xn/605/Uv39//frXvw53JgBAjAt6z6m6ulo333yzJCkvL09xcaEdGZw1a5by8vIC2tbtdof0GACA6BR0OT355JMqKCjQlClTlJWVFfIDl5SUqKCgIOT7AwBOXUGV0+bNm/Xwww8rMzNT06ZNa9ADp6enKzs7O6Bt3W63ysvLG/R4AIDoEVQ5TZw4UR6PR88//7xSUlIa9MC5ubnKzc0NaNucnBz2sgAghgRVTmvXrpXL5dL48eNrrfPt2ezYsUMdOnSQJL377rs677zzwhATABBLgn7PyRij3bt317ne6/U6648ePRp6MgBAzApqqt33338vY4zf2yuvvCJJ6tq1q7Ns6NChjZEZAHCK45IZAADrUE4AAOtQTgAA64StnCZMmCBjjIqLi8M1JAAgRrHnBACwDuUEALAO5QQAsA7lBACwDuUEALAO5QQAsA7lBACwDuUEALAO5QQAsA7lBACwDuUEALAO5QQAsE7QV8IF0HguPnNYpCOEptob6QQhczWJzqdB4zWRjtCo2HMCAFiHcgIAWIdyAgBYh3ICAFiHcgIAWIdyAgBYh3ICAFiHcgIAWIdyAgBYh3ICAFiHcgIAWIdyAgBYh3ICAFiHcgIAWIdyAgBYJ6Ryevjhh+Vyueq9vfDCC+HOCgCIEQ26yla7du3Uo0cPv+vS09MbMjQAIIY1qJxGjhypOXPmhCkKAADH8J4TAMA6lBMAwDoNOqy3YcMGjRkzRrt27VLz5s115pln6tprr1WfPn3ClQ8AEIMaVE7r16/X+vXrne/ff/99Pfroo7rzzjv15JNPKj4+vqH5AAAxKKRy6tChg6ZMmaKrrrpK3bt3V/PmzVVYWKjnnntOL7zwgp555hk1bdpUjz/+eJ1jzJo1S3l5eQE9ntvtDiUmACBKhVROEydOrLXsjDPO0PPPP6/MzEzde++9evrpp3XbbbcpIyPD7xglJSUqKCgI5eEBAKe4Bh3W8+fuu+/WjBkz9O2332rRokWaNGmS3+3S09OVnZ0d0Jhut1vl5eXhjAkAsFjYyyk+Pl4DBgzQn//8ZxUWFta5XW5urnJzcwMaMycnh70sAIghjTKVvGnTppKkqqqqxhgeAHCKa5Ry+vLLLyVJnTt3bozhAQCnuLCX0wcffKCNGzdKkkaMGBHu4QEAMSDoctq4caNyc3O1YcOGGsu9Xq/mz5+vMWPGSJIuueQSnX322eFJCQCIKUFPiKisrFReXp7y8vKUlpamrl27qkmTJtqyZYsOHDggSRo8eLDmzZsX9rAAgNgQdDllZGRo+vTp+uyzz+R2u7VlyxZ5PB6lpaVp5MiRGjNmjK677jrODgEACFnQ5XTaaafp/vvvb4wsAABI4qzkAAALUU4AAOtQTgAA61BOAADrUE4AAOtQTgAA61BOAADrUE4AAOtQTgAA61BOAADrUE4AAOtQTgAA61BOAADrBH1W8ohyueRqkhDpFEExVZWRjhCyaPtd+5jq6khHCFn1d/siHSEkribR9VRyvLjmzSMdISTVBw9FOkKjYs8JAGAdygkAYB3KCQBgHcoJAGAdygkAYB3KCQBgHcoJAGAdygkAYB3KCQBgHcoJAGAdygkAYB3KCQBgHcoJAGAdygkAYB3KCQBgnQaX0+LFi3XVVVepY8eOSkxMVPv27TVw4EA98MADqqqqCkdGAECMCbmcqqqqNHbsWF1yySX685//rPj4eGVlZSk1NVVr1qzRo48+Ko/HE86sAIAYEfLlK2+77TbNmzdPWVlZmj17ts4++2xnXVlZmZYtW6bExMSwhAQAxJaQymn58uV68cUX1bFjR+Xn5ystLa3G+pSUFF122WVhCQgAiD0hHdZ7+umnJUn33HNPrWICAKChgt5z8ng8WrJkiSTp8ssv1+rVq/XKK69o8+bNSk5OVr9+/XTTTTepc+fOYQ8LAIgNQZfThg0bVFlZqWbNmumdd97R1KlT5fV6nfWLFi3SY489prlz52rUqFFhDQsAiA1Bl1NJSYkkqaKiQlOmTNGgQYM0Y8YM/fSnP9XXX3+t+++/XwsWLNANN9ygnj17Kisry+84s2bNUl5eXkCP6Xa7g40JAIhiQZdTaWmppGNTydu0aaPFixerefPmkqQePXrozTff1ObNm7V+/Xo9+uijevvtt/2OU1JSooKCggZEBwCcqoIup6SkJOfrW2+91Skmn7i4ON11110aP368lixZIq/Xq7i42vMu0tPTlZ2dHdBjut1ulZeXBxsVABClgi6nVq1aOV/37t3b7za+5YcOHdL+/fvVpk2bWtvk5uYqNzc3oMfMyclhLwsAYkjQU8l79erlfH38XtTxjl9eXV0dQiwAQCwLupw6deqkrl27SpK2bt3qdxvf8sTERLVu3boB8QAAsSikD+GOHj1akjR37twa08h9Xn75ZUnS+eefryZNQj5DEgAgRoVUTr/97W/VsmVLud1u3XXXXTp69KgkyRijGTNmaNGiRXK5XPrd734X1rAAgNgQUjm1bdtW77zzjpKTk/Xss8+qQ4cOGjBggDp27KjJkyfL5XLpiSee0NChQ8McFwAQC0K+ZMbw4cO1YcMGTZgwQc2aNdO6detUVVWlyy67TMuXL9dvf/vbcOYEAMSQBr0h1KNHD73yyivhygIAgCQu0w4AsBDlBACwDuUEALAO5QQAsA7lBACwDuUEALAO5QQAsA7lBACwDuUEALAO5QQAsA7lBACwDuUEALBOdF0J0Egm2i777ore/o+63/WpIC4+0glCYrwm0hFCVn3wUKQjwI/ofeYEAJyyKCcAgHUoJwCAdSgnAIB1KCcAgHUoJwCAdSgnAIB1KCcAgHUoJwCAdSgnAIB1KCcAgHUoJwCAdSgnAIB1KCcAgHUoJwCAdYIup+LiYrlcroBuN954Y2NkBgCc4oK+2GBSUpIGDhxY53qPx6O1a9dKks4777zQkwEAYlbQ5dShQwd9+umnda6fO3euJkyYoOTkZI0ePbpB4QAAsSns7znNmTNHknTVVVepRYsW4R4eABADwlpOxcXFWrFihSRpwoQJ4RwaABBDwlpOc+fOlTFGXbp00QUXXBDOoQEAMSRs5WSM0auvvipJGjdunOLimKUOAAhN0BMi6rJixQpt27ZNUmCH9GbNmqW8vLyAxna73Q2JBgCIMmErJ99EiMGDB6t79+4n3L6kpEQFBQXhengAwCkkLOV05MgRLVy4UFLgEyHS09OVnZ0d0LZut1vl5eWhxgMARJmwlNOCBQtUWlqqlJQUjRo1KqD75ObmKjc3N6Btc3Jy2MsCgBgSllkLvkN611xzjZo3bx6OIQEAMazB5VRUVKSPP/5YEp9tAgCER4PLyffZpoyMDA0dOjQMkQAAsa5B5XT8Z5vGjx8vl8sVllAAgNjWoHJasWKFioqK5HK5NH78+HBlAgDEuAaVk28ixJAhQ5SZmRmOPAAANLycjDH6xz/+EaY4AABwmXYAgIUoJwCAdSgnAIB1KCcAgHUoJwCAdSgnAIB1KCcAgHUoJwCAdSgnAIB1KCcAgHUoJwCAdSgnAIB1KCcAgHWaRDpAIIqKiiRJVcke7e+9OcJpAAChqnJ7pPL/Pq/XxWWMMScpU8hSUlJUXl4e6RgAgDBJTk5WWVlZneujYs+pXbt22rNnj5KSksJ+UUO3263y8nIlJyerd+/eYR27sUVr9mjNLUVv9mjNLUVv9mjNLTVu9qKiInk8HrVr167+DU2My87ONpJMdnZ2pKMELVqzR2tuY6I3e7TmNiZ6s0drbmPsyM6ECACAdSgnAIB1KCcAgHUoJwCAdSgnAIB1KCcAgHUoJwCAdSgnAIB1KCcAgHUoJwCAdaLi3HqN6dZbb1VJSYnS09MjHSVo0Zo9WnNL0Zs9WnNL0Zs9WnNLdmSPirOSAwBiC4f1AADWoZwAANahnAAA1qGcAADWoZwAANahnAAA1qGcAADW+f9s/jqCzQ+sVgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate per-sequence representations via averaging\n",
    "# NOTE: token 0 is always a beginning-of-sequence token, so the first residue is token 1.\n",
    "sequence_representations = []\n",
    "for i, tokens_len in enumerate(batch_lens):\n",
    "    sequence_representations.append(token_representations[i, 1 : tokens_len - 1].mean(0))\n",
    "\n",
    "# Look at the unsupervised self-attention map contact predictions\n",
    "import matplotlib.pyplot as plt\n",
    "for (_, seq), tokens_len, attention_contacts in zip(data, batch_lens, results[\"contacts\"]):\n",
    "    plt.matshow(attention_contacts[: tokens_len, : tokens_len])\n",
    "    plt.title(seq)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca9b7b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f5123c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "58499179",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_peptide_hla_sep(hla_seq, peptide_seq, max_len, encode_choice=\"embed\"):\n",
    "    padded_seq = add_padding(peptide_seq, max_len, \"-\")\n",
    "    \n",
    "    #converted this code to be for just one peptide since that is what the dataloader needs\n",
    "    if encode_choice == \"embed\":\n",
    "        peptide_processed = torch.tensor([amino_acid_mapping[aa] for aa in padded_seq])\n",
    "        hla_processed = torch.tensor([amino_acid_mapping[aa] for aa in hla_seq])\n",
    "        padding_mask = (peptide_processed != amino_acid_mapping[\"-\"]).unsqueeze(1)\n",
    "        \n",
    "    elif encode_choice == \"esm\":\n",
    "        padded_seq = add_padding(peptide_seq, max_len, \"<pad>\")\n",
    "        peptide_input = [(\"Peptide_Input\", padded_seq)]\n",
    "        hla_input = [(\"HLA_Input\", hla_seq)]\n",
    "        \n",
    "        peptide_batch_labels, peptide_batch_strs, peptide_batch_tokens = esm_batch_converter(peptide_input)\n",
    "        hla_batch_labels, hla_batch_strs, hla_batch_tokens = esm_batch_converter(hla_input)\n",
    "\n",
    "        # Extract per-residue representations (on CPU)\n",
    "        with torch.no_grad():\n",
    "            peptide_results = esm_model(peptide_batch_tokens, repr_layers=[33], return_contacts=True)\n",
    "            hla_results = esm_model(hla_batch_tokens, repr_layers=[33], return_contacts=True)\n",
    "        \n",
    "        peptide_processed = peptide_results[\"representations\"][33]\n",
    "        hla_processed = hla_results[\"representations\"][33]\n",
    "        \n",
    "        #this is the padding mask for the transformer (padding for the esm model has already been incorporated into the <pad> token for esm_model to deal with - double check! TODO)\n",
    "        padding_mask = (peptide_batch_tokens == esm_alphabet.padding_idx).unsqueeze(1) #QUESTION/TODO: Do I need to unsqueeze this? this is currently [batch_size, seq_length]\n",
    "        \n",
    "    elif encode_choice == \"one_hot\":\n",
    "        peptide_processed = torch.tensor([one_hot_dict[aa] for aa in padded_seq])\n",
    "        hla_processed = torch.tensor([one_hot_dict[aa] for aa in hla_seq])\n",
    "        padding_bool = [aa != \"-\" for aa in padded_seq]\n",
    "        padding_mask = torch.tensor(padding_bool).unsqueeze(1)\n",
    "\n",
    "    elif encode_choice == \"pc\":\n",
    "        peptide_processed = torch.tensor([pc_dict[aa] for aa in padded_seq])\n",
    "        hla_processed = torch.tensor([pc_dict[aa] for aa in hla_seq])\n",
    "        padding_bool = [aa != \"-\" for aa in padded_seq]\n",
    "        padding_mask = torch.tensor(padding_bool).unsqueeze(1)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported encoding choice: {encode_choice}. Must be 'one_hot', 'esm', embed', or 'pc'\")\n",
    "    \n",
    "    return hla_processed, peptide_processed, padding_mask\n",
    "\n",
    "#-----------------------------------------------------------\n",
    "#before using esm, need to define esm_model and esm_batch_converter: \n",
    "#esm_model, esm_alphabet = esm.pretrained.esm2_t33_650M_UR50D()\n",
    "#esm_batch_converter = esm_alphabet.get_batch_converter()\n",
    "#TODO: according to https://github.com/facebookresearch/esm/blob/main/esm/constants.py#L7, \"-\" is recognized by the model as <unk>, not <pad> so I might make that more explicit somehow --> TODO\n",
    "#NOTE: according to https://github.com/search?q=repo%3Afacebookresearch%2Fesm%20%3Cpad%3E&type=code, \"<pad>\" is used to get the padding_idx (and in the above, you see that it corresponds to 1 and the padded parts also correspond to 1 at the end of the seq)\n",
    "#NOTE: changed this such that aa == \"-\" is used for padding mask instead of aa != \"-\" since usually True means ignore the position and False means don't ignroe the position\n",
    "def transform_peptide_hla_concat(hla_seq, peptide_seq, max_len, encode_choice=\"embed\", esm_model = None, esm_batch_converter = None, esm_alphabet = None):\n",
    "    padded_seq = add_padding(peptide_seq, max_len, \"-\")\n",
    "    concat_seq = padded_seq + hla_seq\n",
    "    \n",
    "    #TODO: for all of these, check that it should be unsqueeze(1)\n",
    "    #converted this code to be for just one peptide since that is what the dataloader needs\n",
    "    if encode_choice == \"embed\":\n",
    "        concat_processed = torch.tensor([amino_acid_mapping[aa] for aa in concat_seq])\n",
    "        padding_mask = (concat_processed == amino_acid_mapping[\"-\"]).unsqueeze(1)\n",
    "        \n",
    "    #TODO: check if this is correctly implemented for a one peptide at a time basis \n",
    "    elif encode_choice == \"esm\":\n",
    "        padded_seq = add_padding(peptide_seq, max_len, \"<pad>\")\n",
    "        concat_seq = padded_seq + hla_seq\n",
    "        concat_input = [(\"Concat_Input\", concat_seq)]\n",
    "        concat_batch_labels, concat_batch_strs, concat_batch_tokens = esm_batch_converter(concat_input)\n",
    "        #concat_batch_lens = (concat_batch_tokens != esm_alphabet.padding_idx).sum(1) #only need this if you want to later use the means instead of the token representations for each amino acid\n",
    "        \n",
    "        # Extract per-residue representations (on CPU)\n",
    "        with torch.no_grad():\n",
    "            concat_results = esm_model(concat_batch_tokens, repr_layers=[33], return_contacts=True)\n",
    "        concat_processed = concat_results[\"representations\"][33]\n",
    "        #this is the padding mask for the transformer (padding for the esm model has already been incorporated into the <pad> token for esm_model to deal with - double check! TODO)\n",
    "        padding_mask = (concat_batch_tokens == esm_alphabet.padding_idx).unsqueeze(1) #QUESTION/TODO: Do I need to unsqueeze this? this is currently [batch_size, seq_length]\n",
    "        \n",
    "    elif encode_choice == \"one_hot\":\n",
    "        concat_processed = torch.tensor([one_hot_dict[aa] for aa in concat_seq])\n",
    "        padding_bool = [aa == \"-\" for aa in concat_seq]\n",
    "        padding_mask = torch.tensor(padding_bool).unsqueeze(1)\n",
    "\n",
    "    elif encode_choice == \"pc\":\n",
    "        concat_processed = torch.tensor([pc_dict[aa] for aa in concat_seq])\n",
    "        padding_bool = [aa == \"-\" for aa in concat_seq]\n",
    "        padding_mask = torch.tensor(padding_bool).unsqueeze(1)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported encoding choice: {encode_choice}. Must be 'one_hot', 'esm', embed', or 'pc'\")\n",
    "    \n",
    "    return concat_processed, padding_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "fe0d402b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use this if you want to create the train dataset automatically and can input the whole original file (no need to separate out the train and validation from each other beforehand)\n",
    "class PeptideHLADataset_Training_Validation(Dataset):\n",
    "    def __init__(self, input_df, hla_seq_df, tgt_col, pep_col, hla_col, fold_num_val, train_or_val, max_len, encode_choice = \"embed\", transform=None):\n",
    "        self.input_df = input_df\n",
    "        self.hla_seq_df = hla_seq_df\n",
    "        self.tgt_col = tgt_col\n",
    "        self.pep_col = pep_col\n",
    "        self.hla_col = hla_col\n",
    "        self.max_len = max_len\n",
    "        self.fold_num_val = fold_num_val\n",
    "        self.train_or_val = train_or_val\n",
    "        self.encode_choice = encode_choice\n",
    "        self.transform = transform\n",
    "        self.train_df = input_df[input_df['fold'] != fold_num_val]\n",
    "        self.val_df = input_df[input_df['fold'] == fold_num_val]\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.train_or_val == \"train\":\n",
    "            return len(self.train_df)\n",
    "        elif self.train_or_val == \"validation\":\n",
    "            return len(self.val_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #print(idx)\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "            \n",
    "        if self.train_or_val == \"train\":\n",
    "            sample = self.train_df.iloc[idx]\n",
    "        elif self.train_or_val == \"validation\":\n",
    "            sample = self.val_df.iloc[idx]\n",
    "            \n",
    "        peptide = sample[self.pep_col]\n",
    "        hla_name = sample[self.hla_col]\n",
    "        label = sample[self.tgt_col]\n",
    "        #label = torch.tensor(sample[self.tgt_col]).unsqueeze(1) #TODO: i added the unsqueeze here -- is that right?\n",
    "                \n",
    "        #hla_name_processed = re.sub(r'[\\*:]', '', hla_name.split(\"-\")[1]) #not needed since the input data has hla in the correct format now\n",
    "        #hla_sequence = self.hla_seq_df[hla_name_processed].values[0]    \n",
    "        hla_sequence = self.hla_seq_df[hla_name]\n",
    "\n",
    "        if self.transform:\n",
    "            #why doesn't this work if you add the self.max_len into it?\n",
    "            hla_sequence, peptide, padding_mask = self.transform(hla_sequence, peptide, self.max_len, self.encode_choice)\n",
    "        else: \n",
    "            raise RuntimeError(\"Transform function is not defined. Please define it.\")\n",
    "            \n",
    "        return hla_sequence, peptide, padding_mask, label\n",
    "    \n",
    "def get_data_loaders(input_df, hla_seq_df, tgt_col, pep_col, hla_col, fold_num_val, max_len, batch_size = 32, encode_choice = 'embed', concat_sep = \"concat\"):\n",
    "    if concat_sep == \"concat\":\n",
    "        transform_function = lambda h_seq, p_seq, max_len, encode_choice: transform_peptide_hla_concat(h_seq, p_seq, max_len, encode_choice)\n",
    "    elif concat_sep == \"sep\":\n",
    "        transform_function = lambda h_seq, p_seq, max_len, encode_choice: transform_peptide_hla_sep(h_seq, p_seq, max_len, encode_choice)\n",
    "    else:\n",
    "        raise ValueError(\"concat_sep argument must be either 'concat' or 'sep'\")\n",
    "        \n",
    "    train_dataset = PeptideHLADataset_Training_Validation(input_df, hla_seq_df, tgt_col, pep_col, hla_col, fold_num_val, \"train\", max_len = max_len, transform = transform_function, encode_choice = encode_choice)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    val_dataset = PeptideHLADataset_Training_Validation(input_df, hla_seq_df, tgt_col, pep_col, hla_col, fold_num_val, \"validation\", max_len = max_len, transform = transform_function, encode_choice = encode_choice)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    return train_loader, val_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "de4f0bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sure to have model.train() right before using this function\n",
    "def train_model(model, train_loader, model_type, optimizer, criterion, epoch, concat_sep):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    if concat_sep == \"concat\":\n",
    "        for batch_idx, (concat_processed, padding_mask, labels) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(concat_processed.long(), padding_mask, model_type).squeeze() #(reduce a dim so it matches the dim of the labels [32] instead of [32, 1])\n",
    "            loss = criterion(outputs, labels.float())\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            if batch_idx % 10 == 9:  #Print average loss every 10 mini-batches\n",
    "                print(f'Training Epoch: {epoch + 1}, Batch: {batch_idx + 1}, Loss: {running_loss / 10:.4f}')\n",
    "                running_loss = 0.0\n",
    "    elif concat_sep == \"sep\":\n",
    "        for batch_idx, (hla_processed, peptide_processed, padding_mask, labels) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(hla_processed.long(), peptide_processed.long(), padding_mask, model_type).squeeze() #(reduce a dim so it matches the dim of the labels [32] instead of [32, 1])\n",
    "            loss = criterion(outputs, labels.float())\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            if batch_idx % 10 == 9:  #Print average loss every 10 mini-batches\n",
    "                print(f'Training Epoch: {epoch + 1}, Batch: {batch_idx + 1}, Loss: {running_loss / 10:.4f}')\n",
    "                running_loss = 0.0\n",
    "    else:\n",
    "        raise ValueError(\"concat_sep argument must be either 'concat' or 'sep'\")\n",
    "    \n",
    "def eval_model(model, val_loader, model_type, threshold, criterion, concat_sep):\n",
    "    model.eval()\n",
    "    total_correct, total_samples = 0, 0\n",
    "    \n",
    "    if concat_sep == \"concat\":\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (concat_processed, padding_mask, labels) in enumerate(val_loader):\n",
    "                #IMPT: only have the squeeze here if you are doing binary classification w sigmoid classification! if you use softmax for 2 classes, take this out\n",
    "                output = model(concat_processed.long(), padding_mask, model_type).squeeze()\n",
    "                #predicted = torch.argmax(output, dim=1) #for softmax\n",
    "                predicted = (output >= threshold).long() #for sigmoid\n",
    "                total_correct += (predicted == labels).sum().item()\n",
    "                total_samples += labels.size(0)\n",
    "    elif concat_sep == \"sep\":\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (hla_processed, peptide_processed, padding_mask, labels) in enumerate(val_loader):\n",
    "                #IMPT: only have the squeeze here if you are doing binary classification w sigmoid classification! if you use softmax for 2 classes, take this out\n",
    "                output = model(hla_processed.long(), peptide_processed.long(), padding_mask, model_type).squeeze()\n",
    "                #predicted = torch.argmax(output, dim=1) #for softmax\n",
    "                predicted = (output >= threshold).long() #for sigmoid\n",
    "                total_correct += (predicted == labels).sum().item()\n",
    "                total_samples += labels.size(0)\n",
    "    else:\n",
    "        raise ValueError(\"concat_sep argument must be either 'concat' or 'sep'\")\n",
    "            \n",
    "    accuracy = total_correct / total_samples\n",
    "    return accuracy\n",
    "\n",
    "def train_and_eval(model, train_loader, val_loader, model_type, threshold, criterion, optimizer, epochs=10, concat_sep = \"concat\"):\n",
    "    if optimizer == \"Adam\":\n",
    "        optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "    for epoch in range(epochs):\n",
    "        # training\n",
    "        train_model(model, train_loader, model_type, optimizer, criterion, epoch, concat_sep)\n",
    "        # eval\n",
    "        accuracy = eval_model(model, val_loader, model_type, threshold, criterion, concat_sep)\n",
    "        print(f'Eval Epoch: {epoch + 1}, Validation Accuracy: {accuracy:.4f}')\n",
    "    print('Finished Training and Evaluation')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1aae59fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Concat_Input 10138',\n",
       "  'TYIIPRSVLFGSHSMRYFSTSVSRPGRGEPRFIAVGYVDDTQFVRFDSDAASQRMEPRAPWIEQEGPEYWDEETGKVKAHSQTDRENLRIALRYYNQSEAGSHTLQMMFGCDVGSDGRFLRGYHQYAYDGKDYIALKEDLRSWTAADMAAQITKRKWEAAHVAEQQRAYLEGTCVDGLRRYLENGKETLQRT'),\n",
       " ('Concat_Input 5584',\n",
       "  'RYYKNIGLGFGSHSMRYFSTSVSRPGRGEPRFIAVGYVDDTQFVRFDSDAASQRMEPRAPWIEQEGPEYWDEETGKVKAHSQTDRENLRIALRYYNQSEAGSHTLQMMFGCDVGSDGRFLRGYHQYAYDGKDYIALKEDLRSWTAADMAAQITQRKWEAARVAEQLRAYLEGTCVDGLRRYLENGKETLQRT'),\n",
       " ('Concat_Input 9558',\n",
       "  'FTVKWLRRSRGSHSMRYFYTAMSRPGRGEPRFITVGYVDDTLFVRFDSDATSPRKEPRAPWIEQEGPEYWDRETQISKTNTQTYRENLRTALRYYNQSEAGSHIIQRMYGCDVGPDGRLLRGYDQDAYDGKDYIALNEDLSSWTAADTAAQITQRKWEAARVAEQDRAYLEGLCVESLRRYLENGKETLQRA'),\n",
       " ('Concat_Input 331',\n",
       "  'KQLEIAHEKLGSHSMRYFYTAMSRPGRGEPRFITVGYVDDTQFVRFDSDATSPRMAPRAPWIEQEGPEYWDRETQISKTNTQTYRENLRTALRYYNQSEAGSHIIQRMYGCDLGPDGRLLRGHNQLAYDGKDYIALNEDLSSWTAADTAAQITQLKWEAARVAEQLRAYLEGECVEWLRRYLENGKETLQRA'),\n",
       " ('Concat_Input 5958',\n",
       "  'RTLSDYNIQKGSHSMRYFFTSVSRPGRGEPRFIAVGYVDDTQFVRFDSDAASQRMEPRAPWIEQEGPEYWDQETRNVKAQSQTDRVDLGTLRGYYNQSEAGSHTIQIMYGCDVGSDGRFLRGYRQDAYDGKDYIALNEDLRSWTAADMAAQITKRKWEAAHEAEQLRAYLDGTCVEWLRRYLENGKETLQRT'),\n",
       " ('Concat_Input 2312',\n",
       "  'PAALYGFPSTGSHSMRYFYTSVSRPGRGEPRFISVGYVDDTQFVRFDSDAASPREEPRAPWIEQEGPEYWDRNTQIYKAQAQTDRESLRNLRGYYNQSEAGSHTLQSMYGCDVGPDGRLLRGHNQYAYDGKDYIALNEDLRSWTAADTAAQITQRKWEAARVAEQDRAYLEGTCVEWLRRYLENGKDTLERA'),\n",
       " ('Concat_Input 8760',\n",
       "  'DTAARLSYQNGSHSMRYFYTAMSRPGRGEPRFIAVGYVDDTQFVRFDSDAASPREEPRAPWIEQEGPEYWDRNTQIYKAQAQTDRESLRNLRGYYNQSEAGSHTWQTMYGCDLGPDGRLLRGHNQLAYDGKDYIALNEDLSSWTAADTAAQITQRKWEAAREAEQLRAYLEGTCVEWLRRYLENGKETLQRA'),\n",
       " ('Concat_Input 5976',\n",
       "  'LHNFEEMVKVCSHSMRYFYTAVSRPGRGEPRFIAVGYVDDTQFVRFDSDAASPRGEPRAPWVEQEGPEYWDRETQKYKRQAQTDRVSLRNLRGYYNQSEAGSHTLQWMYGCDLGPDGRLLRGYDQSAYDGKDYIALNEDLRSWTAADTAAQITQRKWEAARAAEQQRAYLEGTCVEWLRRYLENGKETLQRA'),\n",
       " ('Concat_Input 1472',\n",
       "  'TLIEDEIATIGSHSMRYFFTSVSRPGRGEPRFIAVGYVDDTQFVRFDSDAASQRMEPRAPWIEQEGPEYWDGETRKVKAHSQTHRVDLGTLRGYYNQSEAGSHTVQRMYGCDVGSDWRFLRGYHQYAYDGKDYIALKEDLRSWTAADMAAQTTKHKWETAHEAEQWRAYLEGTCVEWLRRYLENGKETLQRT'),\n",
       " ('Concat_Input 8184',\n",
       "  'WHIYSEEEYLGSHSMRYFYTSVSRPGRGEPRFISVGYVDDTQFVRFDSDAASPREEPRAPWIEQEGPEYWDRNTQICKTNTQTYRENLRTALRYYNQSEAGSHTLQRMYGCDVGPDGRLLRGHNQFAYDGKDYIALNEDLSSWTAADTAAQITQRKWEAARVAEQLRTYLEGTCVEWLRRYLENGKETLQRA')]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TODO: can delete the peptide only and hla only parts later if we confirm we don't need them! (just keep concat parts)\n",
    "concat_input = []\n",
    "peptide_esm_input = []\n",
    "hla_esm_input = []\n",
    "\n",
    "for index, row in peptide_10mer_subset.iterrows():\n",
    "    concat_input.append((\"Concat_Input \" + str(index), row.seq + hla_seq_df_dict[row.allele][0]))\n",
    "    peptide_esm_input.append((\"Peptide \" + str(index), row.seq))\n",
    "    hla_esm_input.append((\"HLA \" + str(index), hla_seq_df_dict[row.allele][0]))\n",
    "\n",
    "concat_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "236eea35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('HLA 10138',\n",
       "  'GSHSMRYFSTSVSRPGRGEPRFIAVGYVDDTQFVRFDSDAASQRMEPRAPWIEQEGPEYWDEETGKVKAHSQTDRENLRIALRYYNQSEAGSHTLQMMFGCDVGSDGRFLRGYHQYAYDGKDYIALKEDLRSWTAADMAAQITKRKWEAAHVAEQQRAYLEGTCVDGLRRYLENGKETLQRT'),\n",
       " ('HLA 5584',\n",
       "  'GSHSMRYFSTSVSRPGRGEPRFIAVGYVDDTQFVRFDSDAASQRMEPRAPWIEQEGPEYWDEETGKVKAHSQTDRENLRIALRYYNQSEAGSHTLQMMFGCDVGSDGRFLRGYHQYAYDGKDYIALKEDLRSWTAADMAAQITQRKWEAARVAEQLRAYLEGTCVDGLRRYLENGKETLQRT'),\n",
       " ('HLA 9558',\n",
       "  'GSHSMRYFYTAMSRPGRGEPRFITVGYVDDTLFVRFDSDATSPRKEPRAPWIEQEGPEYWDRETQISKTNTQTYRENLRTALRYYNQSEAGSHIIQRMYGCDVGPDGRLLRGYDQDAYDGKDYIALNEDLSSWTAADTAAQITQRKWEAARVAEQDRAYLEGLCVESLRRYLENGKETLQRA'),\n",
       " ('HLA 331',\n",
       "  'GSHSMRYFYTAMSRPGRGEPRFITVGYVDDTQFVRFDSDATSPRMAPRAPWIEQEGPEYWDRETQISKTNTQTYRENLRTALRYYNQSEAGSHIIQRMYGCDLGPDGRLLRGHNQLAYDGKDYIALNEDLSSWTAADTAAQITQLKWEAARVAEQLRAYLEGECVEWLRRYLENGKETLQRA'),\n",
       " ('HLA 5958',\n",
       "  'GSHSMRYFFTSVSRPGRGEPRFIAVGYVDDTQFVRFDSDAASQRMEPRAPWIEQEGPEYWDQETRNVKAQSQTDRVDLGTLRGYYNQSEAGSHTIQIMYGCDVGSDGRFLRGYRQDAYDGKDYIALNEDLRSWTAADMAAQITKRKWEAAHEAEQLRAYLDGTCVEWLRRYLENGKETLQRT'),\n",
       " ('HLA 2312',\n",
       "  'GSHSMRYFYTSVSRPGRGEPRFISVGYVDDTQFVRFDSDAASPREEPRAPWIEQEGPEYWDRNTQIYKAQAQTDRESLRNLRGYYNQSEAGSHTLQSMYGCDVGPDGRLLRGHNQYAYDGKDYIALNEDLRSWTAADTAAQITQRKWEAARVAEQDRAYLEGTCVEWLRRYLENGKDTLERA'),\n",
       " ('HLA 8760',\n",
       "  'GSHSMRYFYTAMSRPGRGEPRFIAVGYVDDTQFVRFDSDAASPREEPRAPWIEQEGPEYWDRNTQIYKAQAQTDRESLRNLRGYYNQSEAGSHTWQTMYGCDLGPDGRLLRGHNQLAYDGKDYIALNEDLSSWTAADTAAQITQRKWEAAREAEQLRAYLEGTCVEWLRRYLENGKETLQRA'),\n",
       " ('HLA 5976',\n",
       "  'CSHSMRYFYTAVSRPGRGEPRFIAVGYVDDTQFVRFDSDAASPRGEPRAPWVEQEGPEYWDRETQKYKRQAQTDRVSLRNLRGYYNQSEAGSHTLQWMYGCDLGPDGRLLRGYDQSAYDGKDYIALNEDLRSWTAADTAAQITQRKWEAARAAEQQRAYLEGTCVEWLRRYLENGKETLQRA'),\n",
       " ('HLA 1472',\n",
       "  'GSHSMRYFFTSVSRPGRGEPRFIAVGYVDDTQFVRFDSDAASQRMEPRAPWIEQEGPEYWDGETRKVKAHSQTHRVDLGTLRGYYNQSEAGSHTVQRMYGCDVGSDWRFLRGYHQYAYDGKDYIALKEDLRSWTAADMAAQTTKHKWETAHEAEQWRAYLEGTCVEWLRRYLENGKETLQRT'),\n",
       " ('HLA 8184',\n",
       "  'GSHSMRYFYTSVSRPGRGEPRFISVGYVDDTQFVRFDSDAASPREEPRAPWIEQEGPEYWDRNTQICKTNTQTYRENLRTALRYYNQSEAGSHTLQRMYGCDVGPDGRLLRGHNQFAYDGKDYIALNEDLSSWTAADTAAQITQRKWEAARVAEQLRTYLEGTCVEWLRRYLENGKETLQRA')]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hla_esm_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "40687447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Peptide 10138', 'TYIIPRSVLF'),\n",
       " ('Peptide 5584', 'RYYKNIGLGF'),\n",
       " ('Peptide 9558', 'FTVKWLRRSR'),\n",
       " ('Peptide 331', 'KQLEIAHEKL'),\n",
       " ('Peptide 5958', 'RTLSDYNIQK'),\n",
       " ('Peptide 2312', 'PAALYGFPST'),\n",
       " ('Peptide 8760', 'DTAARLSYQN'),\n",
       " ('Peptide 5976', 'LHNFEEMVKV'),\n",
       " ('Peptide 1472', 'TLIEDEIATI'),\n",
       " ('Peptide 8184', 'WHIYSEEEYL')]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peptide_esm_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9fb104",
   "metadata": {},
   "source": [
    "## Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b0c760f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 194, 1280])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get esm embeddings for your data\n",
    "model, alphabet = esm.pretrained.esm2_t33_650M_UR50D()\n",
    "batch_converter = alphabet.get_batch_converter()\n",
    "#model.eval()  # disables dropout for deterministic results\n",
    "\n",
    "concat_data = concat_input\n",
    "concat_batch_labels, concat_batch_strs, concat_batch_tokens = batch_converter(concat_data)\n",
    "concat_batch_lens = (concat_batch_tokens != alphabet.padding_idx).sum(1)\n",
    "\n",
    "# Extract per-residue representations (on CPU)\n",
    "with torch.no_grad():\n",
    "    concat_results = model(concat_batch_tokens, repr_layers=[33], return_contacts=True)\n",
    "concat_token_representations = concat_results[\"representations\"][33]\n",
    "\n",
    "concat_token_representations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b321dfee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(\"KNQRALKLGTGSHSMRYFYTAMSRPVRGEPRFIAVGYVDDTQFVRFDSDAASPRTEPRAPWIEQEGPEYWDRNTQIFKTNTQTYRESLRNLRGYYNQSEAGSHIIQRMYGCDLGPDGRLLRGHDQSAYDGKDYIALNEDLSSWTAADTAAQITQRKWEAARVAEQLRAYLEGLCVEWLRRYLENGKETLQRA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3bb54a06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5a2622",
   "metadata": {},
   "source": [
    "**Note on why you need the additional linear layer at the end of the transformer and before the sigmoid** (I was confused about this at first!): after you go through the transformer encoder, the output is in the shape of [seq_len, batch_size, input_dim] --> when you apply pooling strategy (mean or cls versions), you reduce seq length dim so now you have a dim of [batch_size, input_dim] --> classifier layer then serves to map this high-dim vector of dim = input_dum to a single value that represents probability that input seq is a binder or non-binder (aka classifier layer project the high dim encoded representation per peptide seq in batch down to a single scalar value for each peptide seq in the batch so it can go through binary classification) --> then you put that final value through the sigmoid activation function. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4825d81",
   "metadata": {},
   "source": [
    "**src_mask vs src_key_padding_mask**:\n",
    "1. src_mask: prevents model from paying attention to certain positions in the input seq (useful if you want causal/autoregressive masking where you want the model to only be able to look at amino acids up to a ceratin position (i.e. if you are predicting which amino acid came next based on previous amino acids or something). you can also use this mask to exclude certain tokens that should not be paid attention to (special tokens or something)\n",
    "    1. dim = [seq_len, seq_len] (matches dim of the attention scores)\n",
    "2. src_key_padding_mask: don't pay attention to padding tokens for self-attention calculations (what we will use here)\n",
    "    2. dim = [batch_size, seq_len]; each element in the mask is a boolean indicating whether the corresponding token is a padding token (True) or not (False)\n",
    "    \n",
    "3. aka src_mask is used for specifying which tokens should not be attended to by any other token, while src_key_padding_mask is specifically for indicating padding tokens that should be ignored by the attention mechanism\n",
    "    1. \"Dimensions: src_mask has dimensions [seq_len, seq_len], allowing it to specify attention restrictions at the token level for the entire sequence. src_key_padding_mask has dimensions [batch_size, seq_len], indicating padding tokens across different sequences in a batch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b423117d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#works\n",
    "'''class TransformerEncoderClassifier_Model1(nn.Module):\n",
    "    def __init__(self, input_dim, num_layers, num_heads, d_ff, dropout=0.1):\n",
    "        super(TransformerEncoderClassifier_Model1, self).__init__()\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=input_dim,\n",
    "            nhead=num_heads,\n",
    "            dim_feedforward=d_ff,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=num_layers)\n",
    "        self.classifier = nn.Linear(input_dim, 1) #bring it back to dim 1 for sigmoid classifier (if using softmax, change this to 2)\n",
    "\n",
    "    def forward(self, src, pooling_strat = \"mean\", src_mask=None, src_key_padding_mask=None):\n",
    "        #change src (input) shape from [batch_size, seq_len, input_dim] to [seq_len, batch_size, input_dim] (latter is more common for pytorch built-in implementations)\n",
    "        src = src.permute(1, 0, 2)\n",
    "        \n",
    "        #run model\n",
    "        encoded_interim = self.transformer_encoder(src, mask=src_mask, src_key_padding_mask=src_key_padding_mask)\n",
    "        \n",
    "        ## Three ways to do this: take the representation of the [CLS] token, take the mean pooling strategy, \n",
    "        # or take the raw values themselves (unsure if the last one is actually used in practice!!)\n",
    "        if pooling_strat == \"mean\":\n",
    "            encoded = encoded_interim.mean(dim=0)\n",
    "        elif pooling_strat == \"CLS\":\n",
    "            #assuming CLS is the first token at position 0 (assuming it is the same as SOS token for our purposes - check with Wengong [TODO])\n",
    "            encoded = encoded_interim[0]\n",
    "        #run classifier (bring it down to one neuron then use sigmoid classifier)\n",
    "        logits = self.classifier(encoded)\n",
    "        return torch.sigmoid(logits)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcff4d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#works \n",
    "'''class TransformerEncoderClassifier_Model1(nn.Module):\n",
    "    def __init__(self, input_dim, num_layers, num_heads, d_ff, dropout=0.1):\n",
    "        super(TransformerEncoderClassifier_Model1, self).__init__()\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=input_dim,\n",
    "            nhead=num_heads,\n",
    "            dim_feedforward=d_ff,\n",
    "            dropout=dropout,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=num_layers)\n",
    "        self.classifier = nn.Linear(input_dim, 1) #bring it back to dim 1 for sigmoid classifier (if using softmax, change this to 2)\n",
    "\n",
    "    def forward(self, src, pooling_strat = \"mean\", model_type = \"esm\", src_mask=None, src_key_padding_mask=None):\n",
    "        #change src (input) shape from [batch_size, seq_len, input_dim] to [seq_len, batch_size, input_dim] (latter is more common for pytorch built-in implementations)\n",
    "        #src = src.permute(1, 0, 2) -- added batch_first=True so do not need this anymore\n",
    "        \n",
    "        #run model\n",
    "        encoded_interim = self.transformer_encoder(src, src_key_padding_mask=src_key_padding_mask)\n",
    "        \n",
    "        ## Three ways to do this: take the representation of the [CLS] token, take the mean pooling strategy, \n",
    "        # or take the raw values themselves (unsure if the last one is actually used in practice!!)\n",
    "        if pooling_strat == \"mean\":\n",
    "            encoded = encoded_interim.mean(dim=1) #changed dim = 0 to dim = 1 since that is now the seq_len dim\n",
    "        elif pooling_strat == \"CLS\":\n",
    "            #assuming CLS is the first token at position 0 (assuming it is the same as SOS token for our purposes - check with Wengong [TODO])\n",
    "            # With batch_first=True, the CLS token for each sequence is at position 0 along the seq_len dimension, but since we're iterating over batch, index over each item in the batch.\n",
    "            encoded = encoded_interim[:, 0, :]\n",
    "        #run classifier (bring it down to one neuron then use sigmoid classifier)\n",
    "        logits = self.classifier(encoded)\n",
    "        return torch.sigmoid(logits)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a5f5a813",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoderClassifier_Model1(nn.Module):\n",
    "    def __init__(self, ntoken: int, d_model: int, nhead: int, d_hid: int, nlayers: int, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.embedding = nn.Embedding(ntoken, d_model) #not used in esm model!\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "        encoder_layers = TransformerEncoderLayer(d_model, nhead, d_hid, dropout, batch_first=True)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.linear = nn.Linear(d_model, 1) #bring it back to dim 1 for sigmoid classifier (if using softmax, change this to 2)\n",
    "\n",
    "    def forward(self, src, pooling_strat = \"mean\", model_type = \"esm\", src_mask=None, src_key_padding_mask=None) -> Tensor:\n",
    "        #change src (input) shape from [batch_size, seq_len, input_dim] to [seq_len, batch_size, input_dim] (latter is more common for pytorch built-in implementations)\n",
    "        #src = src.permute(1, 0, 2) -- added batch_first=True so do not need this anymore\n",
    "        \n",
    "        if model_type == \"esm\": \n",
    "            #src = self.embedding(src) #add this back in when you generalize the model for other types\n",
    "            src = self.pos_encoder(src)\n",
    "        else:\n",
    "            src = self.embedding(src) #add this back in when you generalize the model for other types\n",
    "            src = self.pos_encoder(src)\n",
    "        \n",
    "        #run model\n",
    "        encoded_interim = self.transformer_encoder(src, src_key_padding_mask=src_key_padding_mask)\n",
    "        \n",
    "        ## Three ways to do this: take the representation of the [CLS] token, take the mean pooling strategy, \n",
    "        # or take the raw values themselves (unsure if the last one is actually used in practice!!)\n",
    "        if pooling_strat == \"mean\":\n",
    "            encoded = encoded_interim.mean(dim=1) #changed dim = 0 to dim = 1 since that is now the seq_len dim\n",
    "        elif pooling_strat == \"CLS\":\n",
    "            #assuming CLS is the first token at position 0 (assuming it is the same as SOS token for our purposes - check with Wengong [TODO])\n",
    "            # With batch_first=True, the CLS token for each sequence is at position 0 along the seq_len dimension, but since we're iterating over batch, index over each item in the batch.\n",
    "            encoded = encoded_interim[:, 0, :]\n",
    "        #run classifier (bring it down to one neuron then use sigmoid classifier)\n",
    "        logits = self.linear(encoded)\n",
    "        return torch.sigmoid(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b5dd9054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: tensor([[0.7686],\n",
      "        [0.7043],\n",
      "        [0.7189],\n",
      "        [0.6996],\n",
      "        [0.7461],\n",
      "        [0.7802],\n",
      "        [0.8281],\n",
      "        [0.7967],\n",
      "        [0.7769],\n",
      "        [0.7186]], grad_fn=<SigmoidBackward0>)\n",
      "Loss: 0.7985034584999084\n"
     ]
    }
   ],
   "source": [
    "###TEST IT ON A MINI SET\n",
    "input_dim = concat_token_representations.shape[2]\n",
    "num_layers = 6 #can change\n",
    "num_heads = 8 #can change\n",
    "d_ff = 2048\n",
    "#CHANGE THIS TO MATCH WHAT YOU NEED WHEN YOU ADD PADDING\n",
    "padding_mask = torch.zeros(10, 194, dtype=torch.bool)\n",
    "\n",
    "\n",
    "model = TransformerEncoderClassifier_Model1(ntoken = 22, \n",
    "                                            d_model = input_dim, \n",
    "                                            nhead = num_heads, \n",
    "                                            d_hid = d_ff, \n",
    "                                            nlayers = num_layers, \n",
    "                                            dropout = 0.1)\n",
    "initialize_param(model)\n",
    "labels = torch.tensor(peptide_10mer_subset.label.values).unsqueeze(1).float()\n",
    "output = model(concat_token_representations, model_type = \"esm\", src_key_padding_mask = padding_mask)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "loss = criterion(output, labels)\n",
    "\n",
    "print(\"Output:\", output)\n",
    "print(\"Loss:\", loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efeec4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = transform_peptide_hla_concat(hla_seq, peptide_seq, max_len, encode_choice=\"embed\", esm_model = None, esm_batch_converter = None, esm_alphabet = None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "cfa79117",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[103], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m initialize_param(model)\n\u001b[1;32m     18\u001b[0m train_loader, val_loader \u001b[38;5;241m=\u001b[39m get_data_loaders(peptide_10mer_subset, hla_seq_df, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallele\u001b[39m\u001b[38;5;124m\"\u001b[39m, val_fold_num, max_len, batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m, encode_choice \u001b[38;5;241m=\u001b[39m encode_choice, concat_sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconcat\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 19\u001b[0m train_and_eval(\n\u001b[1;32m     20\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel, \n\u001b[1;32m     21\u001b[0m     train_loader\u001b[38;5;241m=\u001b[39mtrain_loader, \n\u001b[1;32m     22\u001b[0m     val_loader\u001b[38;5;241m=\u001b[39mval_loader, \n\u001b[1;32m     23\u001b[0m     model_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mesm\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m     24\u001b[0m     threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, \n\u001b[1;32m     25\u001b[0m     criterion\u001b[38;5;241m=\u001b[39mcriterion, \n\u001b[1;32m     26\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAdam\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m     27\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, \n\u001b[1;32m     28\u001b[0m     concat_sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconcat\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     29\u001b[0m )\n",
      "Cell \u001b[0;32mIn[85], line 67\u001b[0m, in \u001b[0;36mtrain_and_eval\u001b[0;34m(model, train_loader, val_loader, threshold, criterion, optimizer, model_type, epochs, concat_sep)\u001b[0m\n\u001b[1;32m     64\u001b[0m     optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m)\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;66;03m# training\u001b[39;00m\n\u001b[0;32m---> 67\u001b[0m     train_model(model, train_loader, model_type, optimizer, criterion, epoch, concat_sep)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# eval\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     accuracy \u001b[38;5;241m=\u001b[39m eval_model(model, val_loader, model_type, threshold, criterion, concat_sep)\n",
      "Cell \u001b[0;32mIn[85], line 6\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, model_type, optimizer, criterion, epoch, concat_sep)\u001b[0m\n\u001b[1;32m      4\u001b[0m running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m concat_sep \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconcat\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m----> 6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (concat_processed, padding_mask, labels) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m      7\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m      8\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m model(concat_processed\u001b[38;5;241m.\u001b[39mlong(), padding_mask, model_type)\u001b[38;5;241m.\u001b[39msqueeze() \u001b[38;5;66;03m#(reduce a dim so it matches the dim of the labels [32] instead of [32, 1])\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[83], line 44\u001b[0m, in \u001b[0;36mPeptideHLADataset_Training_Validation.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     40\u001b[0m hla_sequence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhla_seq_df[hla_name]\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;66;03m#why doesn't this work if you add the self.max_len into it?\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m     hla_sequence, peptide, padding_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(hla_sequence, peptide, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_len, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode_choice)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m: \n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTransform function is not defined. Please define it.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[83], line 52\u001b[0m, in \u001b[0;36mget_data_loaders.<locals>.<lambda>\u001b[0;34m(h_seq, p_seq, max_len, encode_choice)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_data_loaders\u001b[39m(input_df, hla_seq_df, tgt_col, pep_col, hla_col, fold_num_val, max_len, batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m, encode_choice \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124membed\u001b[39m\u001b[38;5;124m'\u001b[39m, concat_sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconcat\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m concat_sep \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconcat\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 52\u001b[0m         transform_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m h_seq, p_seq, max_len, encode_choice: transform_peptide_hla_concat(h_seq, p_seq, max_len, encode_choice)\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m concat_sep \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msep\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     54\u001b[0m         transform_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m h_seq, p_seq, max_len, encode_choice: transform_peptide_hla_sep(h_seq, p_seq, max_len, encode_choice)\n",
      "Cell \u001b[0;32mIn[61], line 67\u001b[0m, in \u001b[0;36mtransform_peptide_hla_concat\u001b[0;34m(hla_seq, peptide_seq, max_len, encode_choice, esm_model, esm_batch_converter, esm_alphabet)\u001b[0m\n\u001b[1;32m     65\u001b[0m concat_seq \u001b[38;5;241m=\u001b[39m padded_seq \u001b[38;5;241m+\u001b[39m hla_seq\n\u001b[1;32m     66\u001b[0m concat_input \u001b[38;5;241m=\u001b[39m [(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConcat_Input\u001b[39m\u001b[38;5;124m\"\u001b[39m, concat_seq)]\n\u001b[0;32m---> 67\u001b[0m concat_batch_labels, concat_batch_strs, concat_batch_tokens \u001b[38;5;241m=\u001b[39m esm_batch_converter(concat_input)\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m#concat_batch_lens = (concat_batch_tokens != esm_alphabet.padding_idx).sum(1) #only need this if you want to later use the means instead of the token representations for each amino acid\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# Extract per-residue representations (on CPU)\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "max_len = max([len(x) for x in peptide_10mer_subset.seq])\n",
    "input_dim = concat_token_representations.shape[2] #1280\n",
    "num_layers = 6 #can change\n",
    "num_heads = 8 #can change\n",
    "d_ff = 2048\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "fold_values = [0, 1] #!!!! CHANGE/TODO: alter if needed (this is just for the subset; the whole thing has 0 - 4)\n",
    "\n",
    "for val_fold_num in fold_values:\n",
    "    model = TransformerEncoderClassifier_Model1(ntoken = 22, \n",
    "                                            d_model = input_dim, \n",
    "                                            nhead = num_heads, \n",
    "                                            d_hid = d_ff, \n",
    "                                            nlayers = num_layers, \n",
    "                                            dropout = 0.1)\n",
    "    initialize_param(model)\n",
    "    train_loader, val_loader = get_data_loaders(peptide_10mer_subset, hla_seq_df, \"label\", \"seq\", \"allele\", val_fold_num, max_len, batch_size = 32, encode_choice = encode_choice, concat_sep = \"concat\")\n",
    "    train_and_eval(\n",
    "        model=model, \n",
    "        train_loader=train_loader, \n",
    "        val_loader=val_loader, \n",
    "        model_type=\"esm\", \n",
    "        threshold=0.5, \n",
    "        criterion=criterion, \n",
    "        optimizer=\"Adam\", \n",
    "        epochs=10, \n",
    "        concat_sep=\"concat\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "9ce9f6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = max([len(x) for x in peptide_10mer_subset.seq])\n",
    "encode_choice = \"esm\"\n",
    "criterion = nn.BCELoss()\n",
    "train_loader, val_loader = get_data_loaders(peptide_10mer_subset, hla_seq_df, \"label\", \"seq\", \"allele\", 1, max_len, batch_size = 32, encode_choice = encode_choice)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "1d22ba01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.PeptideHLADataset_Training_Validation at 0x17ff59150>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = PeptideHLADataset_Training_Validation(peptide_10mer_subset, hla_seq_df, \"label\", \"seq\", \"allele\", 0, \"train\", max_len = max_len, transform = transform_peptide_hla_concat, encode_choice = \"esm\")\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89d56b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9930673c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f343835",
   "metadata": {},
   "source": [
    "## Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "125018e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoderClassifier_Model2(nn.Module):\n",
    "    def __init__(self, ntoken: int, d_model: int, nhead: int, d_hid: int, nlayers: int, dropout: float = 0.1, fine_tune_dim1: int = 512, fine_tune_dim2: int = 512):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.embedding = nn.Embedding(ntoken, d_model) #not used in esm model!\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "        \n",
    "        # Adding 3 linear layers for fine-tuning ESM embeddings\n",
    "        self.linear1 = nn.Linear(input_dim, fine_tune_dim1)\n",
    "        self.linear2 = nn.Linear(fine_tune_dim1, fine_tune_dim2)\n",
    "        self.linear3 = nn.Linear(fine_tune_dim2, input_dim)\n",
    "        \n",
    "        # Add dropout since you added the linear layers \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # Variety of activation functions to choose from since we added 3 linear layers \n",
    "        self.relu = nn.ReLU()\n",
    "        self.swish = nn.SiLU()\n",
    "        self.leakyrelu = nn.LeakyReLU()\n",
    "        self.prelu = nn.PReLU()\n",
    "        self.elu = nn.ELU()\n",
    "        self.selu = nn.SELU()\n",
    "        self.gelu = nn.GELU()\n",
    "\n",
    "        encoder_layers = TransformerEncoderLayer(d_model, nhead, d_hid, dropout, batch_first=True)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.linear = nn.Linear(d_model, 1) #bring it back to dim 1 for sigmoid classifier (if using softmax, change this to 2)\n",
    "\n",
    "    def forward(self, src, pooling_strat = \"mean\", model_type = \"esm\", activ_fn = \"ReLU\", src_mask=None, src_key_padding_mask=None):\n",
    "        \n",
    "        if activ_fn == \"ReLU\":\n",
    "            src = self.dropout(self.relu(self.linear1(src)))\n",
    "            src = self.dropout(self.relu(self.linear2(src)))\n",
    "            src = self.dropout(self.relu(self.linear3(src)))\n",
    "        elif activ_fn == \"Swish\":\n",
    "            src = self.dropout(self.swish(self.linear1(src)))\n",
    "            src = self.dropout(self.swish(self.linear2(src)))\n",
    "            src = self.dropout(self.swish(self.linear3(src)))\n",
    "        elif activ_fn == \"LeakyReLU\":\n",
    "            src = self.dropout(self.leakyrelu(self.linear1(src)))\n",
    "            src = self.dropout(self.leakyrelu(self.linear2(src)))\n",
    "            src = self.dropout(self.leakyrelu(self.linear3(src)))\n",
    "        elif activ_fn == \"PReLU\":\n",
    "            src = self.dropout(self.prelu(self.linear1(src)))\n",
    "            src = self.dropout(self.prelu(self.linear2(src)))\n",
    "            src = self.dropout(self.prelu(self.linear3(src)))\n",
    "        elif activ_fn == \"ELU\":\n",
    "            src = self.dropout(self.elu(self.linear1(src)))\n",
    "            src = self.dropout(self.elu(self.linear2(src)))\n",
    "            src = self.dropout(self.elu(self.linear3(src)))\n",
    "        elif activ_fn == \"SELU\":\n",
    "            src = self.dropout(self.selu(self.linear1(src)))\n",
    "            src = self.dropout(self.selu(self.linear2(src)))\n",
    "            src = self.dropout(self.selu(self.linear3(src)))\n",
    "        elif activ_fn == \"GELU\":\n",
    "            src = self.dropout(self.gelu(self.linear1(src)))\n",
    "            src = self.dropout(self.gelu(self.linear2(src)))\n",
    "            src = self.dropout(self.gelu(self.linear3(src)))\n",
    "        \n",
    "        if model_type == \"esm\": \n",
    "            #src = self.embedding(src) #add this back in when you generalize the model for other types\n",
    "            src = self.pos_encoder(src)\n",
    "        else:\n",
    "            src = self.embedding(src) #add this back in when you generalize the model for other types\n",
    "            src = self.pos_encoder(src)\n",
    "            \n",
    "        #run model\n",
    "        encoded_interim = self.transformer_encoder(src, src_key_padding_mask=src_key_padding_mask)\n",
    "        \n",
    "        ## Three ways to do this: take the representation of the [CLS] token, take the mean pooling strategy, \n",
    "        # or take the raw values themselves (unsure if the last one is actually used in practice!!)\n",
    "        if pooling_strat == \"mean\":\n",
    "            encoded = encoded_interim.mean(dim=1) #changed dim = 0 to dim = 1 since that is now the seq_len dim\n",
    "        elif pooling_strat == \"CLS\":\n",
    "            #assuming CLS is the first token at position 0 (assuming it is the same as SOS token for our purposes - check with Wengong [TODO])\n",
    "            # With batch_first=True, the CLS token for each sequence is at position 0 along the seq_len dimension, but since we're iterating over batch, index over each item in the batch.\n",
    "            encoded = encoded_interim[:, 0, :]\n",
    "        #run classifier (bring it down to one neuron then use sigmoid classifier)\n",
    "        logits = self.linear(encoded)\n",
    "        return torch.sigmoid(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "088fae51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get esm embeddings for your data\n",
    "model, alphabet = esm.pretrained.esm2_t33_650M_UR50D()\n",
    "batch_converter = alphabet.get_batch_converter()\n",
    "#model.eval()  # disables dropout for deterministic results\n",
    "\n",
    "concat_data = concat_input\n",
    "concat_batch_labels, concat_batch_strs, concat_batch_tokens = batch_converter(concat_data)\n",
    "concat_batch_lens = (concat_batch_tokens != alphabet.padding_idx).sum(1)\n",
    "\n",
    "# Extract per-residue representations (on CPU)\n",
    "with torch.no_grad():\n",
    "    concat_results = model(concat_batch_tokens, repr_layers=[33], return_contacts=True)\n",
    "concat_token_representations = concat_results[\"representations\"][33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "49b8b113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: tensor([[0.7599],\n",
      "        [0.7747],\n",
      "        [0.7649],\n",
      "        [0.6982],\n",
      "        [0.6300],\n",
      "        [0.5979],\n",
      "        [0.6186],\n",
      "        [0.7100],\n",
      "        [0.7094],\n",
      "        [0.7093]], grad_fn=<SigmoidBackward0>)\n",
      "Loss: 0.6598116159439087\n"
     ]
    }
   ],
   "source": [
    "###TEST IT ON A MINI SET\n",
    "input_dim = concat_token_representations.shape[2]\n",
    "num_layers = 6 #can change\n",
    "num_heads = 8 #can change\n",
    "d_ff = 2048\n",
    "#CHANGE THIS TO MATCH WHAT YOU NEED WHEN YOU ADD PADDING\n",
    "padding_mask = torch.zeros(10, 194, dtype=torch.bool)\n",
    "\n",
    "\n",
    "model = TransformerEncoderClassifier_Model2(ntoken = 22, \n",
    "                                            d_model = input_dim, \n",
    "                                            nhead = num_heads, \n",
    "                                            d_hid = d_ff, \n",
    "                                            nlayers = num_layers, \n",
    "                                            dropout = 0.1,\n",
    "                                            fine_tune_dim1 = 512, \n",
    "                                            fine_tune_dim2 = 512)\n",
    "    \n",
    "initialize_param(model)\n",
    "labels = torch.tensor(peptide_10mer_subset.label.values).unsqueeze(1).float()\n",
    "output = model(concat_token_representations, model_type = \"esm\", src_key_padding_mask = padding_mask)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "loss = criterion(output, labels)\n",
    "\n",
    "print(\"Output:\", output)\n",
    "print(\"Loss:\", loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccda7cea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8c8d8dad",
   "metadata": {},
   "source": [
    "## Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "83321e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "esm_model, esm_alphabet = esm.pretrained.esm2_t33_650M_UR50D()\n",
    "esm_batch_converter = esm_alphabet.get_batch_converter()\n",
    "\n",
    "concat_data = concat_input\n",
    "concat_batch_labels, concat_batch_strs, concat_batch_tokens = esm_batch_converter(concat_data)\n",
    "concat_batch_lens = (concat_batch_tokens != esm_alphabet.padding_idx).sum(1)\n",
    "\n",
    "with torch.no_grad():\n",
    "    concat_results = esm_model(concat_batch_tokens, repr_layers=[33], return_contacts=True)\n",
    "concat_token_representations = concat_results[\"representations\"][33]\n",
    "\n",
    "#####\n",
    "# Freeze all layers\n",
    "for param in esm_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Unfreeze the last three layers\n",
    "num_layers_to_unfreeze = 3\n",
    "layers_to_unfreeze = list(esm_model.layers[-num_layers_to_unfreeze:].parameters())\n",
    "for param in layers_to_unfreeze:\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf224e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoderClassifier_Model1(nn.Module):\n",
    "    def __init__(self, ntoken: int, d_model: int, nhead: int, d_hid: int, nlayers: int, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.embedding = nn.Embedding(ntoken, d_model) #not used in esm model!\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "        encoder_layers = TransformerEncoderLayer(d_model, nhead, d_hid, dropout, batch_first=True)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.linear = nn.Linear(d_model, 1) #bring it back to dim 1 for sigmoid classifier (if using softmax, change this to 2)\n",
    "\n",
    "    def forward(self, src, pooling_strat = \"mean\", model_type = \"esm\", src_mask=None, src_key_padding_mask=None) -> Tensor:\n",
    "        #change src (input) shape from [batch_size, seq_len, input_dim] to [seq_len, batch_size, input_dim] (latter is more common for pytorch built-in implementations)\n",
    "        #src = src.permute(1, 0, 2) -- added batch_first=True so do not need this anymore\n",
    "        \n",
    "        if model_type == \"esm\": \n",
    "            #src = self.embedding(src) #add this back in when you generalize the model for other types\n",
    "            src = self.pos_encoder(src)\n",
    "        else:\n",
    "            src = self.embedding(src) #add this back in when you generalize the model for other types\n",
    "            src = self.pos_encoder(src)\n",
    "        \n",
    "        #run model\n",
    "        encoded_interim = self.transformer_encoder(src, src_key_padding_mask=src_key_padding_mask)\n",
    "        \n",
    "        ## Three ways to do this: take the representation of the [CLS] token, take the mean pooling strategy, \n",
    "        # or take the raw values themselves (unsure if the last one is actually used in practice!!)\n",
    "        if pooling_strat == \"mean\":\n",
    "            encoded = encoded_interim.mean(dim=1) #changed dim = 0 to dim = 1 since that is now the seq_len dim\n",
    "        elif pooling_strat == \"CLS\":\n",
    "            #assuming CLS is the first token at position 0 (assuming it is the same as SOS token for our purposes - check with Wengong [TODO])\n",
    "            # With batch_first=True, the CLS token for each sequence is at position 0 along the seq_len dimension, but since we're iterating over batch, index over each item in the batch.\n",
    "            encoded = encoded_interim[:, 0, :]\n",
    "        #run classifier (bring it down to one neuron then use sigmoid classifier)\n",
    "        logits = self.linear(encoded)\n",
    "        return torch.sigmoid(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e964949",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedESMTransformerModel(nn.Module):\n",
    "    def __init__(self, esm_model, transformer_classifier_model):\n",
    "        super().__init__()\n",
    "        self.esm_model = esm_model\n",
    "        self.transformer_classifier_model = transformer_classifier_model\n",
    "        \n",
    "    def forward(self, src, pooling_strat=\"mean\", model_type=\"esm\", src_key_padding_mask=None):\n",
    "        # Assuming src is already in the correct format for the ESM model\n",
    "        with torch.no_grad():  # We only want to fine-tune certain layers, not all\n",
    "            esm_embeddings = self.esm_model(src)[\"representations\"][33]  # Adjust based on your ESM model structure\n",
    "        \n",
    "        # Now, pass these embeddings to your transformer classifier\n",
    "        logits = self.transformer_classifier_model(esm_embeddings, pooling_strat=pooling_strat, model_type=model_type, src_key_padding_mask=src_key_padding_mask)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab64e16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c5edefae",
   "metadata": {},
   "source": [
    "## Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "18b3d652",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoderClassifier_Model4(nn.Module):\n",
    "    def __init__(self, ntoken: int, d_model: int, nhead: int, d_hid: int, nlayers: int, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.embedding = nn.Embedding(ntoken, d_model) #not used in esm model!\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "        self.multihead_attn = nn.MultiheadAttention(d_model, nhead, batch_first=True) # batch_first=True for consistency\n",
    "        encoder_layers = TransformerEncoderLayer(d_model, nhead, d_hid, dropout, batch_first=True)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.linear = nn.Linear(d_model, 1) #bring it back to dim 1 for sigmoid classifier (if using softmax, change this to 2)\n",
    "\n",
    "    def forward(self, hla, peptide, pooling_strat=\"mean\", model_type=\"esm\", src_mask=None, peptide_key_padding_mask=None) -> Tensor:\n",
    "        #positional encoding\n",
    "        if model_type == \"esm\": \n",
    "            #positionally encode them separately\n",
    "            hla = self.pos_encoder(hla)\n",
    "            peptide = self.pos_encoder(peptide)\n",
    "            print(hla.shape)\n",
    "            print(peptide.shape)\n",
    "            print(peptide_key_padding_mask.shape)\n",
    "        else:\n",
    "            hla = self.embedding(hla) #add this back in when you generalize the model for other types\n",
    "            hla = self.pos_encoder(hla)\n",
    "            peptide = self.embedding(peptide)\n",
    "            peptide = self.pos_encoder(peptide)\n",
    "\n",
    "        #cross-attention: hla as query, peptide as key and value\n",
    "        #https://stackoverflow.com/questions/62629644/what-the-difference-between-att-mask-and-key-padding-mask-in-multiheadattnetion\n",
    "        attn_output, attn_output_weights = self.multihead_attn(query=hla, key=peptide, value=peptide, key_padding_mask=peptide_key_padding_mask)\n",
    "        #attn_output, attn_output_weights = self.multihead_attn(query=peptide, key=hla, value=hla, key_padding_mask=peptide_key_padding_mask)\n",
    "        \n",
    "        print(attn_output.shape)\n",
    "        \n",
    "        ##encoder - CHECK/TODO: I am directly passing attn_output to the encoder but there might be other ways to do this like adding \n",
    "        #a residual layer where I add back the peptide and hla embeddings back in as well to prevent loss of details\n",
    "        ##steps taken - CHECK/TODO: compute cross-attention between HLA and peptide sequences, where output represents the peptide seq in the context of the HLA seq. Feed the cross-attention output into the encoder stack. \n",
    "        #encoder layers will perform self-attention on the already combined HLA-peptide context rather than the original separate sequences --> is that okay?\n",
    "        \n",
    "        #TODO: ask wengong: what is the mask supposed to be here? It is supposed to cover the peptides only, but 1) that was masked in the multihead attention above and 2)the dim here are of the hla only so idk what to mask anymore in this combined representation that is the attn_output\n",
    "        encoded_interim = self.transformer_encoder(attn_output, src_key_padding_mask=None)\n",
    "    \n",
    "        if pooling_strat == \"mean\":\n",
    "            encoded = encoded_interim.mean(dim=1)\n",
    "        elif pooling_strat == \"CLS\":\n",
    "            #assuming CLS is the first token at position 0 (assuming it is the same as SOS token for our purposes - check with Wengong [TODO])\n",
    "            encoded = encoded_interim[:, 0, :]\n",
    "        #run classifier\n",
    "        logits = self.linear(encoded)\n",
    "        return torch.sigmoid(logits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "0c6e3310",
   "metadata": {},
   "outputs": [],
   "source": [
    "peptide_esm_input = []\n",
    "hla_esm_input = []\n",
    "max_len = 12 #dummy var for now\n",
    "\n",
    "for index, row in peptide_10mer_subset.iterrows():\n",
    "    peptide_esm_input.append((\"Peptide \" + str(index), add_padding(row.seq, max_len, \"<pad>\")))\n",
    "    hla_esm_input.append((\"HLA \" + str(index), hla_seq_df_dict[row.allele][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "ed407816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Peptide 10138', 'TYII<pad><pad>PRSVLF'),\n",
       " ('Peptide 5584', 'RYYK<pad><pad>NIGLGF'),\n",
       " ('Peptide 9558', 'FTVK<pad><pad>WLRRSR'),\n",
       " ('Peptide 331', 'KQLE<pad><pad>IAHEKL'),\n",
       " ('Peptide 5958', 'RTLS<pad><pad>DYNIQK'),\n",
       " ('Peptide 2312', 'PAAL<pad><pad>YGFPST'),\n",
       " ('Peptide 8760', 'DTAA<pad><pad>RLSYQN'),\n",
       " ('Peptide 5976', 'LHNF<pad><pad>EEMVKV'),\n",
       " ('Peptide 1472', 'TLIE<pad><pad>DEIATI'),\n",
       " ('Peptide 8184', 'WHIY<pad><pad>SEEEYL')]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peptide_esm_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "1e516ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get esm embeddings for your data\n",
    "esm_model, esm_alphabet = esm.pretrained.esm2_t33_650M_UR50D()\n",
    "esm_batch_converter = esm_alphabet.get_batch_converter()\n",
    "#model.eval()  # disables dropout for deterministic results\n",
    "\n",
    "peptide_batch_labels, peptide_batch_strs, peptide_batch_tokens = esm_batch_converter(peptide_esm_input)\n",
    "hla_batch_labels, hla_batch_strs, hla_batch_tokens = esm_batch_converter(hla_esm_input)\n",
    "\n",
    "# Extract per-residue representations (on CPU)\n",
    "with torch.no_grad():\n",
    "    peptide_results = esm_model(peptide_batch_tokens, repr_layers=[33], return_contacts=True)\n",
    "    hla_results = esm_model(hla_batch_tokens, repr_layers=[33], return_contacts=True)\n",
    "\n",
    "peptide_token_representations = peptide_results[\"representations\"][33]\n",
    "hla_token_representations = hla_results[\"representations\"][33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "85f30f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 184, 1280])\n",
      "torch.Size([10, 14, 1280])\n",
      "torch.Size([10, 14])\n",
      "torch.Size([10, 184, 1280])\n",
      "Output: tensor([[0.1916],\n",
      "        [0.1786],\n",
      "        [0.1775],\n",
      "        [0.1167],\n",
      "        [0.0999],\n",
      "        [0.0897],\n",
      "        [0.1112],\n",
      "        [0.1316],\n",
      "        [0.1635],\n",
      "        [0.2235]], grad_fn=<SigmoidBackward0>)\n",
      "Loss: 1.1684224605560303\n"
     ]
    }
   ],
   "source": [
    "###TEST IT ON A MINI SET\n",
    "input_dim = concat_token_representations.shape[2]\n",
    "num_layers = 6 #can change\n",
    "num_heads = 8 #can change\n",
    "d_ff = 2048\n",
    "padding_mask = (peptide_batch_tokens == esm_alphabet.padding_idx)\n",
    "\n",
    "\n",
    "model = TransformerEncoderClassifier_Model4(ntoken = 22, \n",
    "                                            d_model = input_dim, \n",
    "                                            nhead = num_heads, \n",
    "                                            d_hid = d_ff, \n",
    "                                            nlayers = num_layers, \n",
    "                                            dropout = 0.1)\n",
    "    \n",
    "initialize_param(model)\n",
    "labels = torch.tensor(peptide_10mer_subset.label.values).unsqueeze(1).float()\n",
    "output = model(hla_token_representations, peptide_token_representations, pooling_strat=\"mean\", model_type = \"esm\", peptide_key_padding_mask = padding_mask)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "loss = criterion(output, labels)\n",
    "\n",
    "print(\"Output:\", output)\n",
    "print(\"Loss:\", loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ac63ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823da014",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ba5ace7a",
   "metadata": {},
   "source": [
    "## Model 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "6943932d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoderClassifier_Model5(nn.Module):\n",
    "    def __init__(self, ntoken: int, d_model: int, nhead: int, d_hid: int, nlayers: int, dropout: float = 0.1, fine_tune_dim1: int = 512, fine_tune_dim2: int = 512):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.embedding = nn.Embedding(ntoken, d_model) #not used in esm model!\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "         \n",
    "        # Adding 3 linear layers for fine-tuning ESM embeddings\n",
    "        self.linear1_pep = nn.Linear(input_dim, fine_tune_dim1)\n",
    "        self.linear2_pep = nn.Linear(fine_tune_dim1, fine_tune_dim2)\n",
    "        self.linear3_pep = nn.Linear(fine_tune_dim2, input_dim)\n",
    "        \n",
    "        self.linear1_hla = nn.Linear(input_dim, fine_tune_dim1)\n",
    "        self.linear2_hla = nn.Linear(fine_tune_dim1, fine_tune_dim2)\n",
    "        self.linear3_hla = nn.Linear(fine_tune_dim2, input_dim)\n",
    "        \n",
    "        # Add dropout since you added the linear layers \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # Variety of activation functions to choose from since we added 3 linear layers \n",
    "        self.relu = nn.ReLU()\n",
    "        self.swish = nn.SiLU()\n",
    "        self.leakyrelu = nn.LeakyReLU()\n",
    "        self.prelu = nn.PReLU()\n",
    "        self.elu = nn.ELU()\n",
    "        self.selu = nn.SELU()\n",
    "        self.gelu = nn.GELU()\n",
    "        \n",
    "        self.multihead_attn = nn.MultiheadAttention(d_model, nhead, batch_first=True) # batch_first=True for consistency\n",
    "        encoder_layers = TransformerEncoderLayer(d_model, nhead, d_hid, dropout, batch_first=True)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.linear = nn.Linear(d_model, 1) #bring it back to dim 1 for sigmoid classifier (if using softmax, change this to 2)\n",
    "\n",
    "    def forward(self, hla, peptide, pooling_strat=\"mean\", model_type=\"esm\", activ_fn = \"ReLU\", src_mask=None, peptide_key_padding_mask=None) -> Tensor:\n",
    "        \n",
    "        #run the three linear layers SEPARATELY for each hla or peptide \n",
    "        if activ_fn == \"ReLU\":\n",
    "            activation_fn = self.relu\n",
    "        elif activ_fn == \"Swish\":\n",
    "            activation_fn = self.swish\n",
    "        elif activ_fn == \"LeakyReLU\":\n",
    "            activation_fn = self.leakyrelu\n",
    "        elif activ_fn == \"PReLU\":\n",
    "            activation_fn = self.prelu\n",
    "        elif activ_fn == \"ELU\":\n",
    "            activation_fn = self.elu\n",
    "        elif activ_fn == \"SELU\":\n",
    "            activation_fn = self.selu\n",
    "        elif activ_fn == \"GELU\":\n",
    "            activation_fn = self.gelu\n",
    "            \n",
    "        hla = self.dropout(activation_fn(self.linear1_hla(hla)))\n",
    "        hla = self.dropout(activation_fn(self.linear2_hla(hla)))\n",
    "        hla = self.dropout(activation_fn(self.linear3_hla(hla)))\n",
    "        \n",
    "        peptide = self.dropout(activation_fn(self.linear1_pep(peptide)))\n",
    "        peptide = self.dropout(activation_fn(self.linear2_pep(peptide)))\n",
    "        peptide = self.dropout(activation_fn(self.linear3_pep(peptide)))\n",
    "            \n",
    "        #positional encoding\n",
    "        if model_type == \"esm\": \n",
    "            #positionally encode them separately\n",
    "            hla = self.pos_encoder(hla)\n",
    "            peptide = self.pos_encoder(peptide)\n",
    "            print(hla.shape)\n",
    "            print(peptide.shape)\n",
    "            print(peptide_key_padding_mask.shape)\n",
    "        else:\n",
    "            hla = self.embedding(hla) #add this back in when you generalize the model for other types\n",
    "            hla = self.pos_encoder(hla)\n",
    "            peptide = self.embedding(peptide)\n",
    "            peptide = self.pos_encoder(peptide)\n",
    "\n",
    "        #cross-attention: hla as query, peptide as key and value\n",
    "        #https://stackoverflow.com/questions/62629644/what-the-difference-between-att-mask-and-key-padding-mask-in-multiheadattnetion\n",
    "        attn_output, attn_output_weights = self.multihead_attn(query=hla, key=peptide, value=peptide, key_padding_mask=peptide_key_padding_mask)\n",
    "        #attn_output, attn_output_weights = self.multihead_attn(query=peptide, key=hla, value=hla, key_padding_mask=peptide_key_padding_mask)\n",
    "\n",
    "        ##encoder - CHECK/TODO: I am directly passing attn_output to the encoder but there might be other ways to do this like adding \n",
    "        #a residual layer where I add back the peptide and hla embeddings back in as well to prevent loss of details\n",
    "        ##steps taken - CHECK/TODO: compute cross-attention between HLA and peptide sequences, where output represents the peptide seq in the context of the HLA seq. Feed the cross-attention output into the encoder stack. \n",
    "        #encoder layers will perform self-attention on the already combined HLA-peptide context rather than the original separate sequences --> is that okay?\n",
    "        #TODO: ask wengong: what is the mask supposed to be here? It is supposed to cover the peptides only, but 1) that was masked in the multihead attention above and 2)the dim here are of the hla only so idk what to mask anymore in this combined representation that is the attn_output\n",
    "        encoded_interim = self.transformer_encoder(attn_output, src_key_padding_mask=None)\n",
    "    \n",
    "        if pooling_strat == \"mean\":\n",
    "            encoded = encoded_interim.mean(dim=1)\n",
    "        elif pooling_strat == \"CLS\":\n",
    "            #assuming CLS is the first token at position 0 (assuming it is the same as SOS token for our purposes - check with Wengong [TODO])\n",
    "            encoded = encoded_interim[:, 0, :]\n",
    "        #run classifier\n",
    "        logits = self.linear(encoded)\n",
    "        return torch.sigmoid(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "84d47de1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Peptide 10138', 'TYII<pad><pad>PRSVLF'),\n",
       " ('Peptide 5584', 'RYYK<pad><pad>NIGLGF'),\n",
       " ('Peptide 9558', 'FTVK<pad><pad>WLRRSR'),\n",
       " ('Peptide 331', 'KQLE<pad><pad>IAHEKL'),\n",
       " ('Peptide 5958', 'RTLS<pad><pad>DYNIQK'),\n",
       " ('Peptide 2312', 'PAAL<pad><pad>YGFPST'),\n",
       " ('Peptide 8760', 'DTAA<pad><pad>RLSYQN'),\n",
       " ('Peptide 5976', 'LHNF<pad><pad>EEMVKV'),\n",
       " ('Peptide 1472', 'TLIE<pad><pad>DEIATI'),\n",
       " ('Peptide 8184', 'WHIY<pad><pad>SEEEYL')]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peptide_esm_input = []\n",
    "hla_esm_input = []\n",
    "max_len = 12 #dummy var for now\n",
    "\n",
    "for index, row in peptide_10mer_subset.iterrows():\n",
    "    peptide_esm_input.append((\"Peptide \" + str(index), add_padding(row.seq, max_len, \"<pad>\")))\n",
    "    hla_esm_input.append((\"HLA \" + str(index), hla_seq_df_dict[row.allele][0]))\n",
    "    \n",
    "peptide_esm_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "f7333829",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get esm embeddings for your data\n",
    "esm_model, esm_alphabet = esm.pretrained.esm2_t33_650M_UR50D()\n",
    "esm_batch_converter = esm_alphabet.get_batch_converter()\n",
    "#model.eval()  # disables dropout for deterministic results\n",
    "\n",
    "peptide_batch_labels, peptide_batch_strs, peptide_batch_tokens = esm_batch_converter(peptide_esm_input)\n",
    "hla_batch_labels, hla_batch_strs, hla_batch_tokens = esm_batch_converter(hla_esm_input)\n",
    "\n",
    "# Extract per-residue representations (on CPU)\n",
    "with torch.no_grad():\n",
    "    peptide_results = esm_model(peptide_batch_tokens, repr_layers=[33], return_contacts=True)\n",
    "    hla_results = esm_model(hla_batch_tokens, repr_layers=[33], return_contacts=True)\n",
    "\n",
    "peptide_token_representations = peptide_results[\"representations\"][33]\n",
    "hla_token_representations = hla_results[\"representations\"][33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "56cd9a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 184, 1280])\n",
      "torch.Size([10, 14, 1280])\n",
      "torch.Size([10, 14])\n",
      "Output: tensor([[0.4662],\n",
      "        [0.4628],\n",
      "        [0.5037],\n",
      "        [0.4847],\n",
      "        [0.5615],\n",
      "        [0.6735],\n",
      "        [0.6944],\n",
      "        [0.6303],\n",
      "        [0.6052],\n",
      "        [0.4610]], grad_fn=<SigmoidBackward0>)\n",
      "Loss: 0.8111757040023804\n"
     ]
    }
   ],
   "source": [
    "###TEST IT ON A MINI SET\n",
    "input_dim = concat_token_representations.shape[2]\n",
    "num_layers = 6 #can change\n",
    "num_heads = 8 #can change\n",
    "d_ff = 2048\n",
    "padding_mask = (peptide_batch_tokens == esm_alphabet.padding_idx)\n",
    "\n",
    "\n",
    "model = TransformerEncoderClassifier_Model5(ntoken = 22, \n",
    "                                            d_model = input_dim, \n",
    "                                            nhead = num_heads, \n",
    "                                            d_hid = d_ff, \n",
    "                                            nlayers = num_layers, \n",
    "                                            dropout = 0.1,\n",
    "                                            fine_tune_dim1 = 512,\n",
    "                                            fine_tune_dim2 = 512)\n",
    "    \n",
    "initialize_param(model)\n",
    "labels = torch.tensor(peptide_10mer_subset.label.values).unsqueeze(1).float()\n",
    "output = model(hla_token_representations, peptide_token_representations, pooling_strat=\"mean\", activ_fn = \"ReLU\", model_type = \"esm\", peptide_key_padding_mask = padding_mask)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "loss = criterion(output, labels)\n",
    "\n",
    "print(\"Output:\", output)\n",
    "print(\"Loss:\", loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91840eae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2109581d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea091ea7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
