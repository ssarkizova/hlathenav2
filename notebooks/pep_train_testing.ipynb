{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fad87c79-db34-45fe-b527-0528b00163db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-18 15:44:30.702904: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-18 15:44:32.996104: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /n/app/python/3.7.4/lib:/n/app/openblas/0.2.19/lib:/n/app/gcc/6.2.0/lib64:/n/app/gcc/6.2.0/lib\n",
      "2023-12-18 15:44:32.996283: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /n/app/python/3.7.4/lib:/n/app/openblas/0.2.19/lib:/n/app/gcc/6.2.0/lib64:/n/app/gcc/6.2.0/lib\n",
      "2023-12-18 15:44:32.996298: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from hlathena import PeptideDatasetTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0fb2a48-2c00-49fc-b8c6-7bc1c3701020",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5612e043-407f-4d2f-9fdf-0ba2b72eb74f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mini_df = pd.read_csv(\"../../notebooks/input/test_training.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e7d55c2-19c0-485d-863d-2c41c5f8529f",
   "metadata": {},
   "outputs": [],
   "source": [
    "peptide_dataset = PeptideDatasetTrain(mini_df, allele_col_name='mhc', target_col_name='tgt', feat_cols=['tgt_weight'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcb715f7-b5c7-4a22-9893-55a11ba26a5e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch.utils.data as torch_data\n",
    "import torch\n",
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "import random\n",
    "\n",
    "from hlathena import peptide_nn\n",
    "from hlathena.training_evaluation import TrainingEvaluation\n",
    "\n",
    "decoy_mul = 1\n",
    "decoy_ratio = 1\n",
    "# for fold in range(folds):\n",
    "fold=0\n",
    "feat_set = []\n",
    "seed=1\n",
    "folds=5\n",
    "batch_size = 5000\n",
    "epochs = 100\n",
    "learning_rate = 0.01\n",
    "pred_replicates = 10\n",
    "dropout_rate = 0.1 #0.0\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17b3fd1e-8edf-4541-909a-5cdaffc3de1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_dims = peptide_dataset.feature_dimensions()\n",
    "\n",
    "peptide_dataset.reassign_folds(folds, seed=seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3a86f09-ea19-4221-8a8c-a6bb9d49ea5c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1 of 5...\n",
      "Resampling hits: False\n",
      "decoy mul: 1\n",
      "decoy ratio: 1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 4, got 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31610/3953465344.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m# t.start()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpeptide_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_replicates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 4, got 3)"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "# t = Timer()\n",
    "# t.start()\n",
    "eval_dict = {\"peptide\":[], \"hla\":[], \"target\":[], \"pred_mean\":[], \"pred_var\":[], \"fold\":[]}\n",
    "            \n",
    "print(\"Training fold {} of {}...\".format(str(fold+1), folds))\n",
    "resampling_hits=False\n",
    "train_ids = peptide_dataset.get_train_idxs(fold=fold, decoy_mul=decoy_mul, resampling_hits=resampling_hits, seed=seed)\n",
    "test_ids = peptide_dataset.get_test_idxs(fold=fold, decoy_ratio=decoy_ratio, seed=seed)\n",
    "print(f\"decoy mul: {decoy_mul}\")\n",
    "print(f\"decoy ratio: {decoy_ratio}\")\n",
    "\n",
    "\n",
    "# Sample elements randomly from a given list of ids, no replacement.\n",
    "train_subsampler = peptide_nn.PeptideRandomSampler(train_ids, seed) # TODO: can replace with SubsetRandomSampler and a torch generator\n",
    "test_subsampler = peptide_nn.PeptideRandomSampler(test_ids, seed)\n",
    "# return peptide_dataset, train_subsampler, test_subsampler, train_ids, test_ids\n",
    "# Define data loaders for training and testing data in this fold\n",
    "trainloader = torch_data.DataLoader(peptide_dataset, batch_size=batch_size, sampler=train_subsampler)\n",
    "testloader = torch_data.DataLoader(peptide_dataset, batch_size=batch_size, sampler=test_subsampler)\n",
    "\n",
    "try:\n",
    "    val_subsampler = peptide_nn.PeptideRandomSampler([i for i in range(len(val_dataset))], seed)\n",
    "    valloader = torch_data.DataLoader(val_dataset, batch_size=batch_size, shuffle=val_subsampler)\n",
    "except:\n",
    "    valloader = None\n",
    "# t.stop(\"setup time\")\n",
    "\n",
    "# t.start()\n",
    "model = peptide_nn.PeptideNN(feature_dims, dropout_rate)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    model = nn.DataParallel(model)\n",
    "model.to(device)\n",
    "optimizer_dict = peptide_nn.train(model, trainloader, learning_rate, epochs, device)#, valloader)\n",
    "# t.stop(\"train time\")\n",
    "\n",
    "# # peptide_nn.save_model(model, fold, models_dir, configs_dir, optimizer_dict, model_config)\n",
    "\n",
    "# t.start()\n",
    "inputs, targets, indices, preds = peptide_nn.evaluate(model, testloader, pred_replicates, device)\n",
    "inputs = torch.vstack(inputs).cpu()\n",
    "targets = [t.item() for t in torch.hstack(targets).cpu()]\n",
    "indices = [i.item() for i in torch.hstack(indices).cpu()]\n",
    "preds = torch.vstack(preds).cpu()\n",
    "\n",
    "# input_peps = [peptide_dataset.decode(p) for p in inputs]\n",
    "input_peps, input_hla = [peptide_dataset.peptides[i] for i in indices], [peptide_dataset.hla[i] for i in indices]\n",
    "pred_means = preds.mean(dim=-1).numpy()\n",
    "pred_vars = preds.var(dim=-1).numpy()\n",
    "\n",
    "for p, h, t, m, v in zip(input_peps, input_hla, targets, pred_means, pred_vars):\n",
    "    eval_dict['peptide'].append(p)\n",
    "    eval_dict['hla'].append(h)\n",
    "    eval_dict['target'].append(t)\n",
    "    eval_dict['pred_mean'].append(m)\n",
    "    eval_dict['pred_var'].append(v)\n",
    "    eval_dict['fold'].append(str(fold+1))\n",
    "\n",
    "eval_df_nn2 = pd.DataFrame.from_dict(eval_dict)\n",
    "# eval_df_nn2.to_csv('bigmhc/pephla_10allele_nn2_evaldf.csv',index=None)\n",
    "# t.stop(\"eval time\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5158d1-ae24-4631-bde4-2fc54bf50682",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
